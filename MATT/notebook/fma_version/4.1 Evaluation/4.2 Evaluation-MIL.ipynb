{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "\n",
    "from kddirkit.metrics import metric\n",
    "%matplotlib inline\n",
    "\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import os\n",
    "import sys\n",
    "import sklearn as skl\n",
    "import sklearn.utils, sklearn.preprocessing, sklearn.decomposition, sklearn.svm\n",
    "from sklearn.metrics import average_precision_score\n",
    "from ast import literal_eval\n",
    "\n",
    "\"\"\n",
    "sns.set_context(\"notebook\", font_scale=1.5)\n",
    "plt.rcParams['figure.figsize'] = (17, 5)\n",
    "\n",
    "import platform\n",
    "if 'Windows' in platform.platform():\n",
    "    ROOT_PATH = \"D:/PycharmProjects/HMAN\"\n",
    "else:\n",
    "    ROOT_PATH = \"/home/xkliu/PycharmProjects/HMAN\"\n",
    "RAW_DATA_PATH = ROOT_PATH  + \"/raw_data\"\n",
    "DATA_PATH = ROOT_PATH + \"/data\"\n",
    "os.chdir(ROOT_PATH)\n",
    "sys.path.append(\"./\")\n",
    "\n",
    "from kddirkit.utils import utils\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "import logging\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from kddirkit.networks.encoders import SentenceEncoder\n",
    "from kddirkit.networks.models import BaselineModel\n",
    "from kddirkit.config import *\n",
    "# from kddirkit.dataloaders import LoadNYT, LoadHierData\n",
    "from kddirkit.frameworks import Trainer\n",
    "from kddirkit.losses.FocalLoss import FocalLoss\n",
    "\n",
    "project_name = 'HMAN'\n",
    "\n",
    "logger = logging.getLogger(project_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "track_dtype = {'track_id': int, 'album_id': int, 'album_type': str, 'artist_id': int, 'set_split': str,\n",
    "               'set_subset': str, 'track_genre_top': str, 'track_genres': str, 'track_genres_all': str,\n",
    "               'track_title': str}\n",
    "genres_converters = {'track_genres': literal_eval, 'track_genres_all': literal_eval}\n",
    "medium_data = pd.read_csv(RAW_DATA_PATH + '/medium_data.csv', converters=genres_converters)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "medium_data_train = pd.read_csv(RAW_DATA_PATH + '/medium_data_train.csv', converters=genres_converters)\n",
    "medium_data_test = pd.read_csv(RAW_DATA_PATH + '/medium_data_test.csv', converters=genres_converters)\n",
    "medium_data_val = pd.read_csv(RAW_DATA_PATH + '/medium_data_val.csv', converters=genres_converters)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "medium_instance_triple = np.load(DATA_PATH + '/' + 'medium_instance_triple.npy')\n",
    "medium_instance_scope = np.load(DATA_PATH + '/' + 'medium_instance_scope.npy')\n",
    "medium_label = np.load(DATA_PATH + '/' + 'medium_label.npy')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "medium_train_instance_triple = np.load(DATA_PATH + '/' + 'medium_train_instance_triple.npy')\n",
    "medium_train_instance_scope = np.load(DATA_PATH + '/' + 'medium_train_instance_scope.npy')\n",
    "medium_train_label = np.load(DATA_PATH + '/' + 'medium_train_label.npy')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "medium_val_instance_triple = np.load(DATA_PATH + '/' + 'medium_val_instance_triple.npy')\n",
    "medium_val_instance_scope = np.load(DATA_PATH + '/' + 'medium_val_instance_scope.npy')\n",
    "medium_val_label = np.load(DATA_PATH + '/' + 'medium_val_label.npy')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "medium_test_entity_pair = np.load(DATA_PATH + '/' + 'medium_test_entity_pair.npy')\n",
    "medium_test_entity_scope = np.load(DATA_PATH + '/' + 'medium_test_entity_scope.npy')\n",
    "medium_test_label = np.load(DATA_PATH + '/' + 'medium_test_label.npy')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "medium_label_transform = np.load(DATA_PATH + '/' + 'medium_label_transform.npy')\n",
    "medium_train_label_transform = np.load(DATA_PATH + '/' + 'medium_train_label_transform.npy')\n",
    "medium_val_label_transform = np.load(DATA_PATH + '/' + 'medium_val_label_transform.npy')\n",
    "medium_test_label_transform = np.load(DATA_PATH + '/' + 'medium_test_label_transform.npy')\n",
    "medium_label_bottom_transform = np.load(DATA_PATH + '/' + 'medium_label_bottom_transform.npy')\n",
    "medium_train_label_bottom_transform = np.load(DATA_PATH + '/' + 'medium_train_label_bottom_transform.npy')\n",
    "medium_val_label_bottom_transform = np.load(DATA_PATH + '/' + 'medium_val_label_bottom_transform.npy')\n",
    "medium_test_label_bottom_transform = np.load(DATA_PATH + '/' + 'medium_test_label_bottom_transform.npy')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johan\\AppData\\Local\\Temp\\ipykernel_32840\\691608824.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  medium_data_train_sort = pd.read_csv(RAW_DATA_PATH + '/' + 'medium_data_train_sort.txt', sep ='-----',  skiprows =1, names  = col_name)\n",
      "C:\\Users\\Johan\\AppData\\Local\\Temp\\ipykernel_32840\\691608824.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  medium_data_val_sort = pd.read_csv(RAW_DATA_PATH + '/' + 'medium_data_VAL_sort.txt', sep = '-----',  skiprows =1, names  = col_name)\n",
      "C:\\Users\\Johan\\AppData\\Local\\Temp\\ipykernel_32840\\691608824.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  medium_data_test_sort = pd.read_csv(RAW_DATA_PATH + '/' + 'medium_data_test_sort.txt', sep = '-----', skiprows =1, names  = col_name)\n"
     ]
    }
   ],
   "source": [
    "col_name = ['track_id', 'album_id', 'album_type', 'artist_id', 'set_split', 'set_subset', 'track_genres_top', 'track_genre', 'track_genres_all']\n",
    "medium_data_train_sort = pd.read_csv(RAW_DATA_PATH + '/' + 'medium_data_train_sort.txt', sep ='-----',  skiprows =1, names  = col_name)\n",
    "medium_data_val_sort = pd.read_csv(RAW_DATA_PATH + '/' + 'medium_data_VAL_sort.txt', sep = '-----',  skiprows =1, names  = col_name)\n",
    "medium_data_test_sort = pd.read_csv(RAW_DATA_PATH + '/' + 'medium_data_test_sort.txt', sep = '-----', skiprows =1, names  = col_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "       track_id  album_id        album_type  artist_id set_split set_subset  \\\n0             2         1             Album          1  training      small   \n1             5         1             Album          1  training      small   \n2             3         1             Album          1  training     medium   \n3           134         1             Album          1  training     medium   \n4         10666         1             Album          1  training     medium   \n...         ...       ...               ...        ...       ...        ...   \n19917    155297     22935             Album      24354  training     medium   \n19918    155298     22936             Album      22050  training     medium   \n19919    155306     22936             Album      22050  training     medium   \n19920    155307     22937  Live Performance       7820  training     medium   \n19921    155314     22940  Live Performance      24357  training     medium   \n\n      track_genres_top      track_genre track_genres_all  \n0              Hip-Hop             [21]             [21]  \n1              Hip-Hop             [21]             [21]  \n2              Hip-Hop             [21]             [21]  \n3              Hip-Hop             [21]             [21]  \n4              Hip-Hop             [21]             [21]  \n...                ...              ...              ...  \n19917     Instrumental  [18, 107, 1235]  [107, 18, 1235]  \n19918             Folk        [17, 103]        [17, 103]  \n19919             Folk        [17, 103]        [17, 103]  \n19920     Experimental              [1]          [1, 38]  \n19921             Rock             [25]         [25, 12]  \n\n[19922 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>track_id</th>\n      <th>album_id</th>\n      <th>album_type</th>\n      <th>artist_id</th>\n      <th>set_split</th>\n      <th>set_subset</th>\n      <th>track_genres_top</th>\n      <th>track_genre</th>\n      <th>track_genres_all</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>1</td>\n      <td>Album</td>\n      <td>1</td>\n      <td>training</td>\n      <td>small</td>\n      <td>Hip-Hop</td>\n      <td>[21]</td>\n      <td>[21]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>1</td>\n      <td>Album</td>\n      <td>1</td>\n      <td>training</td>\n      <td>small</td>\n      <td>Hip-Hop</td>\n      <td>[21]</td>\n      <td>[21]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>Album</td>\n      <td>1</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Hip-Hop</td>\n      <td>[21]</td>\n      <td>[21]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>134</td>\n      <td>1</td>\n      <td>Album</td>\n      <td>1</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Hip-Hop</td>\n      <td>[21]</td>\n      <td>[21]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10666</td>\n      <td>1</td>\n      <td>Album</td>\n      <td>1</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Hip-Hop</td>\n      <td>[21]</td>\n      <td>[21]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19917</th>\n      <td>155297</td>\n      <td>22935</td>\n      <td>Album</td>\n      <td>24354</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Instrumental</td>\n      <td>[18, 107, 1235]</td>\n      <td>[107, 18, 1235]</td>\n    </tr>\n    <tr>\n      <th>19918</th>\n      <td>155298</td>\n      <td>22936</td>\n      <td>Album</td>\n      <td>22050</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Folk</td>\n      <td>[17, 103]</td>\n      <td>[17, 103]</td>\n    </tr>\n    <tr>\n      <th>19919</th>\n      <td>155306</td>\n      <td>22936</td>\n      <td>Album</td>\n      <td>22050</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Folk</td>\n      <td>[17, 103]</td>\n      <td>[17, 103]</td>\n    </tr>\n    <tr>\n      <th>19920</th>\n      <td>155307</td>\n      <td>22937</td>\n      <td>Live Performance</td>\n      <td>7820</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Experimental</td>\n      <td>[1]</td>\n      <td>[1, 38]</td>\n    </tr>\n    <tr>\n      <th>19921</th>\n      <td>155314</td>\n      <td>22940</td>\n      <td>Live Performance</td>\n      <td>24357</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Rock</td>\n      <td>[25]</td>\n      <td>[25, 12]</td>\n    </tr>\n  </tbody>\n</table>\n<p>19922 rows Ã— 9 columns</p>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_data_train_sort"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# Load metadata and features.\n",
    "tracks = utils.load(RAW_DATA_PATH + '/fma_metadata/tracks.csv')\n",
    "genres = utils.load(RAW_DATA_PATH + '/fma_metadata/genres.csv')\n",
    "features = utils.load(RAW_DATA_PATH + '/fma_metadata/features.csv')\n",
    "echonest = utils.load(RAW_DATA_PATH + '/fma_metadata/echonest.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "0             2\n1             5\n2             3\n3           134\n4         10666\n          ...  \n19917    155297\n19918    155298\n19919    155306\n19920    155307\n19921    155314\nName: track_id, Length: 19922, dtype: int64"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_data_train_sort.track_id"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19922 training examples, 2573 testing examples\n",
      "350 features, 16 classes\n"
     ]
    }
   ],
   "source": [
    "small = tracks['set', 'subset'] <= 'medium'\n",
    "\n",
    "train = tracks['set', 'split'] == 'training'\n",
    "small = tracks['set', 'subset'] <= 'medium'\n",
    "\n",
    "train = tracks['set', 'split'] == 'training'\n",
    "val = tracks['set', 'split'] == 'validation'\n",
    "test = tracks['set', 'split'] == 'test'\n",
    "\n",
    "chroma_feature = features.loc[medium_data_train_sort.track_id, 'chroma_cens']\n",
    "tonnetz_feature = features.loc[medium_data_train_sort.track_id, 'tonnetz']\n",
    "mfcc_feature = features.loc[medium_data_train_sort.track_id, 'mfcc']\n",
    "centroid_feature = features.loc[medium_data_train_sort.track_id, 'spectral_centroid']\n",
    "bandwidth_feature = features.loc[medium_data_train_sort.track_id, 'spectral_bandwidth']\n",
    "contrast_feature = features.loc[medium_data_train_sort.track_id, 'spectral_contrast']\n",
    "rolloff_feature = features.loc[medium_data_train_sort.track_id, 'spectral_rolloff']\n",
    "rmse_feature = features.loc[medium_data_train_sort.track_id, 'rmse']\n",
    "zcr_feature = features.loc[medium_data_train_sort.track_id, 'zcr']\n",
    "X_train = np.array(pd.concat([chroma_feature, tonnetz_feature, mfcc_feature, centroid_feature, bandwidth_feature, contrast_feature, rolloff_feature, rmse_feature, zcr_feature], axis = 1))\n",
    "\n",
    "chroma_feature = features.loc[medium_data_test_sort.track_id, 'chroma_cens']\n",
    "tonnetz_feature = features.loc[medium_data_test_sort.track_id, 'tonnetz']\n",
    "mfcc_feature = features.loc[medium_data_test_sort.track_id, 'mfcc']\n",
    "centroid_feature = features.loc[medium_data_test_sort.track_id, 'spectral_centroid']\n",
    "bandwidth_feature = features.loc[medium_data_test_sort.track_id, 'spectral_bandwidth']\n",
    "contrast_feature = features.loc[medium_data_test_sort.track_id, 'spectral_contrast']\n",
    "rolloff_feature = features.loc[medium_data_test_sort.track_id, 'spectral_rolloff']\n",
    "rmse_feature = features.loc[medium_data_test_sort.track_id, 'rmse']\n",
    "zcr_feature = features.loc[medium_data_test_sort.track_id, 'zcr']\n",
    "X_test = np.array(pd.concat(\n",
    "    [chroma_feature, tonnetz_feature, mfcc_feature, centroid_feature, bandwidth_feature,\n",
    "     contrast_feature, rolloff_feature, rmse_feature, zcr_feature], axis=1))\n",
    "\n",
    "y_train = tracks.loc[medium_data_train_sort.track_id, ('track', 'genre_top')]\n",
    "y_val = tracks.loc[medium_data_val_sort.track_id, ('track', 'genre_top')]\n",
    "y_test = tracks.loc[medium_data_test_sort.track_id, ('track', 'genre_top')]\n",
    "# X_train = features.loc[medium_data_train_sort.track_id, 'chroma_cens']\n",
    "X_val= features.loc[medium_data_val_sort.track_id, 'chroma_cens']\n",
    "# X_test = features.loc[medium_data_test_sort.track_id, 'chroma_cens']\n",
    "\n",
    "print('{} training examples, {} testing examples'.format(y_train.size, y_test.size))\n",
    "print('{} features, {} classes'.format(X_train.shape[1], np.unique(y_train).size))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-3.1772271e-01,  4.7041556e-01,  8.3269000e-01, ...,\n         0.0000000e+00,  9.0402907e-01,  2.1812849e-02],\n       [ 4.4840875e-01,  2.6973519e-01,  7.3415899e-01, ...,\n         2.9296875e-03,  6.4523172e+00,  9.2959560e-02],\n       [-1.8923731e-01, -4.3042916e-01, -5.8130997e-01, ...,\n         0.0000000e+00,  1.1771928e+00,  1.9115636e-02],\n       ...,\n       [-5.8614880e-02,  4.1765541e-02,  1.6710621e-01, ...,\n         0.0000000e+00,  1.2897763e+00,  2.7492732e-02],\n       [ 7.5126600e-01,  3.2632694e+00,  2.6064632e+00, ...,\n         5.3710938e-03,  1.3809724e+00,  4.3747392e-02],\n       [-3.3007073e-01, -7.5551963e-01, -1.0224332e+00, ...,\n         9.2773438e-03,  1.2566203e+00,  7.9019656e-03]], dtype=float32)"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Be sure training samples are shuffled.\n",
    "X_train, y_train = skl.utils.shuffle(X_train, y_train, random_state=42)\n",
    "\n",
    "\n",
    "X_train_np = np.array(X_train).astype('float32')\n",
    "X_test_np = np.array(X_test).astype('float32')\n",
    "X_val_np = np.array(X_val).astype('float32')\n",
    "\n",
    "y_train_np = np.argmax(pd.get_dummies(y_train).to_numpy(), axis=1)\n",
    "y_test_np = np.argmax(pd.get_dummies(y_test).to_numpy(), axis = 1)\n",
    "y_val_np = np.argmax(pd.get_dummies(y_val).to_numpy(), axis = 1)\n",
    "X_train_np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.30672131,  0.27931084,  0.11356005, ..., -0.51318961,\n        -0.81050529, -0.72263236],\n       [ 0.18826375,  0.14552122,  0.09464844, ...,  0.07462511,\n         1.1971453 ,  2.10486865],\n       [-0.22370899, -0.32126444, -0.15783681, ..., -0.51318961,\n        -0.71166087, -0.82982455],\n       ...,\n       [-0.13931596, -0.00646161, -0.01418914, ..., -0.51318961,\n        -0.67092247, -0.49690338],\n       [ 0.38393488,  2.14125101,  0.45401017, ...,  0.56447071,\n        -0.63792314,  0.14908666],\n       [-0.31469917, -0.53799579, -0.24250403, ...,  1.34822367,\n        -0.68292   , -1.27547641]])"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize features by removing the mean and scaling to unit variance.\n",
    "scaler = skl.preprocessing.StandardScaler(copy=False)\n",
    "scaler.fit_transform(X_train)\n",
    "scaler.transform(X_test)\n",
    "\n",
    "# Support vector classification.\n",
    "X_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "from kddirkit.dataloaders import LoadFMA\n",
    "feature_mode = \"fma_all\"\n",
    "device = \"cpu\"\n",
    "testDataLoader = LoadFMA.FMATestDataLoader(mode=\"pr\", use_label = 'top' , feature_mode = feature_mode, device=device)\n",
    "\n",
    "\n",
    "y_label_ = np.zeros((len(y_test_np), 16))\n",
    "y_label_[np.arange(len(y_test_np)), y_test_np] = 1\n",
    "y_label_\n",
    "\n",
    "exclude_na_flatten_label = y_label_.reshape(-1)\n",
    "exclude_na_label = y_label_\n",
    "index_non_zero = np.sum(exclude_na_label, 0) > 0\n",
    "\n",
    "evalMetric = metric.EvaFMATMetric(testDataLoader.id2genre,\n",
    "                                               testDataLoader.fewrel_100,\n",
    "                                               testDataLoader.fewrel_200,\n",
    "                                               exclude_na_flatten_label,\n",
    "                                               exclude_na_label,\n",
    "                                               index_non_zero\n",
    "                                               )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_rel100 = ['Easy Listening', 'International', 'Blues', 'Spoken', 'Soul-RnB']\n",
    "few_rel200 = ['Easy Listening', 'International', 'Blues', 'Spoken', 'Soul-RnB', 'Country']\n",
    "labels = np.array(range(16))\n",
    "labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170 188\n"
     ]
    }
   ],
   "source": [
    "idx_few100_list = []\n",
    "for i in range(len(X_test_np)):\n",
    "    if y_test.iloc[i] in few_rel100:\n",
    "        idx_few100_list.append(i)\n",
    "\n",
    "idx_few200_list = []\n",
    "for i in range(len(X_test_np)):\n",
    "    if y_test.iloc[i] in few_rel200:\n",
    "        idx_few200_list.append(i)\n",
    "print(len(idx_few100_list) , len(idx_few200_list))\n",
    "\n",
    "x_test_few_100 = X_test_np[idx_few100_list]\n",
    "y_test_few_100 = y_test_np[idx_few100_list]\n",
    "x_test_few_200 = X_test_np[idx_few200_list]\n",
    "y_test_few_200 = y_test_np[idx_few200_list]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MLP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 41.55%\n"
     ]
    }
   ],
   "source": [
    "mlp_model = MLPClassifier()\n",
    "mlp_model.fit(X_train_np, y_train_np)\n",
    "score = mlp_model.score(X_test_np, y_test_np)\n",
    "print('Accuracy: {:.2%}'.format(score))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_few_100_prob = mlp_model.predict_proba(x_test_few_100)\n",
    "x_test_few_200_prob = mlp_model.predict_proba(x_test_few_200)\n",
    "\n",
    "y_test_few_100_ = np.zeros((len(y_test_few_100), 16))\n",
    "y_test_few_100_[np.arange(len(y_test_few_100)), y_test_few_100] = 1\n",
    "y_test_few_100_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "0.1"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top2score = top_k_accuracy_score(y_test_few_100, x_test_few_100_prob, k=2, labels= labels)\n",
    "top2score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "0.13529411764705881"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top2score = top_k_accuracy_score(y_test_few_100, x_test_few_100_prob, k=3, labels= labels)\n",
    "top2score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "0.3411764705882353"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top2score = top_k_accuracy_score(y_test_few_100, x_test_few_100_prob, k=5, labels= labels)\n",
    "top2score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "0.09042553191489362"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top2score = top_k_accuracy_score(y_test_few_200, x_test_few_200_prob, k=2, labels= labels)\n",
    "top2score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "0.12234042553191489"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top2score = top_k_accuracy_score(y_test_few_200, x_test_few_200_prob, k=3, labels= labels)\n",
    "top2score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "top2score = top_k_accuracy_score(y_test_few_200, x_test_few_200_prob, k=5, labels= labels)\n",
    "top2score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "rand = torch.rand((30, 16))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([30, 16])"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(rand, dim= 1).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.rand((30, 16))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([16])"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(rand, dim = 0).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
