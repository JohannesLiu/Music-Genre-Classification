{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "artistic-southeast",
   "metadata": {},
   "source": [
    "# Sort Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-edgar",
   "metadata": {},
   "source": [
    "## 0. Preliminary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "corresponding-affairs",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "\"\"\n",
    "sns.set_context(\"notebook\", font_scale=1.5)\n",
    "plt.rcParams['figure.figsize'] = (17, 5)\n",
    "\n",
    "import platform\n",
    "if 'Windows' in platform.platform():\n",
    "    ROOT_PATH = \"D:/PycharmProjects/HMAN\"\n",
    "else:\n",
    "    ROOT_PATH = \"/home/xkliu/PycharmProjects/HMAN\"\n",
    "RAW_DATA_PATH = ROOT_PATH  + \"/raw_data\"\n",
    "DATA_PATH = ROOT_PATH + \"/data\"\n",
    "os.chdir(ROOT_PATH)\n",
    "sys.path.append(\"./\")\n",
    "\n",
    "from kddirkit.utils import utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complicated-folder",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "smaller-andrews",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_dtype = {'track_id': int, 'album_id':int, 'album_type':str, 'artist_id':int, 'set_split':str, 'set_subset':str, 'track_genre_top':str, 'track_genres':str, 'track_genres_all':str,'track_title':str}\n",
    "genres_converters = {'track_genres': literal_eval, 'track_genres_all': literal_eval}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "million-perception",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = pd.read_csv(RAW_DATA_PATH+'/small_data.csv',  converters=genres_converters)\n",
    "small_data_train= pd.read_csv(RAW_DATA_PATH+'/small_data_train.csv', converters=genres_converters)\n",
    "small_data_test= pd.read_csv(RAW_DATA_PATH+'/small_data_test.csv', converters=genres_converters)\n",
    "small_data_val= pd.read_csv(RAW_DATA_PATH+'/small_data_val.csv',converters=genres_converters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rocky-florence",
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_data= pd.read_csv(RAW_DATA_PATH+'/medium_data.csv',  converters=genres_converters)\n",
    "medium_data_train= pd.read_csv(RAW_DATA_PATH+'/medium_data_train.csv',  converters=genres_converters)\n",
    "medium_data_test= pd.read_csv(RAW_DATA_PATH+'/medium_data_test.csv',  converters=genres_converters)\n",
    "medium_data_val= pd.read_csv(RAW_DATA_PATH+'/medium_data_val.csv',converters=genres_converters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "smooth-defense",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_data= pd.read_csv(RAW_DATA_PATH+'/large_data.csv',  converters=genres_converters)\n",
    "large_data_train= pd.read_csv(RAW_DATA_PATH+'/large_data_train.csv',  converters=genres_converters)\n",
    "large_data_test= pd.read_csv(RAW_DATA_PATH+'/large_data_test.csv',  converters=genres_converters)\n",
    "large_data_val= pd.read_csv(RAW_DATA_PATH+'/large_data_val.csv',  converters=genres_converters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "viral-notebook",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "      track_id  album_id        album_type  artist_id set_split set_subset  \\\n0            2         1             Album          1  training      small   \n1            5         1             Album          1  training      small   \n2           10         6             Album          6  training      small   \n3          140        61             Album         54  training      small   \n4          141        60             Album         54  training      small   \n...        ...       ...               ...        ...       ...        ...   \n7995    154308     22780             Album      23208      test      small   \n7996    154309     22780             Album      23208      test      small   \n7997    154413     22789  Live Performance      24252  training      small   \n7998    154414     22789  Live Performance      24252  training      small   \n7999    155066     22899             Album      22573  training      small   \n\n     track_genre_top    track_genres track_genres_all  \\\n0            Hip-Hop            [21]             [21]   \n1            Hip-Hop            [21]             [21]   \n2                Pop            [10]             [10]   \n3               Folk            [17]             [17]   \n4               Folk            [17]             [17]   \n...              ...             ...              ...   \n7995         Hip-Hop  [21, 539, 811]   [811, 539, 21]   \n7996         Hip-Hop  [21, 539, 811]   [811, 539, 21]   \n7997             Pop            [76]         [10, 76]   \n7998             Pop            [76]         [10, 76]   \n7999         Hip-Hop       [21, 811]        [811, 21]   \n\n                      track_title  \n0                            Food  \n1                      This World  \n2                         Freeway  \n3              Queen Of The Wires  \n4                            Ohio  \n...                           ...  \n7995                          MIA  \n7996                  A1 Symphony  \n7997                      Do Easy  \n7998  Dead Can Dance (uncensored)  \n7999                          Roy  \n\n[8000 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>track_id</th>\n      <th>album_id</th>\n      <th>album_type</th>\n      <th>artist_id</th>\n      <th>set_split</th>\n      <th>set_subset</th>\n      <th>track_genre_top</th>\n      <th>track_genres</th>\n      <th>track_genres_all</th>\n      <th>track_title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>1</td>\n      <td>Album</td>\n      <td>1</td>\n      <td>training</td>\n      <td>small</td>\n      <td>Hip-Hop</td>\n      <td>[21]</td>\n      <td>[21]</td>\n      <td>Food</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>1</td>\n      <td>Album</td>\n      <td>1</td>\n      <td>training</td>\n      <td>small</td>\n      <td>Hip-Hop</td>\n      <td>[21]</td>\n      <td>[21]</td>\n      <td>This World</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10</td>\n      <td>6</td>\n      <td>Album</td>\n      <td>6</td>\n      <td>training</td>\n      <td>small</td>\n      <td>Pop</td>\n      <td>[10]</td>\n      <td>[10]</td>\n      <td>Freeway</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>140</td>\n      <td>61</td>\n      <td>Album</td>\n      <td>54</td>\n      <td>training</td>\n      <td>small</td>\n      <td>Folk</td>\n      <td>[17]</td>\n      <td>[17]</td>\n      <td>Queen Of The Wires</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>141</td>\n      <td>60</td>\n      <td>Album</td>\n      <td>54</td>\n      <td>training</td>\n      <td>small</td>\n      <td>Folk</td>\n      <td>[17]</td>\n      <td>[17]</td>\n      <td>Ohio</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7995</th>\n      <td>154308</td>\n      <td>22780</td>\n      <td>Album</td>\n      <td>23208</td>\n      <td>test</td>\n      <td>small</td>\n      <td>Hip-Hop</td>\n      <td>[21, 539, 811]</td>\n      <td>[811, 539, 21]</td>\n      <td>MIA</td>\n    </tr>\n    <tr>\n      <th>7996</th>\n      <td>154309</td>\n      <td>22780</td>\n      <td>Album</td>\n      <td>23208</td>\n      <td>test</td>\n      <td>small</td>\n      <td>Hip-Hop</td>\n      <td>[21, 539, 811]</td>\n      <td>[811, 539, 21]</td>\n      <td>A1 Symphony</td>\n    </tr>\n    <tr>\n      <th>7997</th>\n      <td>154413</td>\n      <td>22789</td>\n      <td>Live Performance</td>\n      <td>24252</td>\n      <td>training</td>\n      <td>small</td>\n      <td>Pop</td>\n      <td>[76]</td>\n      <td>[10, 76]</td>\n      <td>Do Easy</td>\n    </tr>\n    <tr>\n      <th>7998</th>\n      <td>154414</td>\n      <td>22789</td>\n      <td>Live Performance</td>\n      <td>24252</td>\n      <td>training</td>\n      <td>small</td>\n      <td>Pop</td>\n      <td>[76]</td>\n      <td>[10, 76]</td>\n      <td>Dead Can Dance (uncensored)</td>\n    </tr>\n    <tr>\n      <th>7999</th>\n      <td>155066</td>\n      <td>22899</td>\n      <td>Album</td>\n      <td>22573</td>\n      <td>training</td>\n      <td>small</td>\n      <td>Hip-Hop</td>\n      <td>[21, 811]</td>\n      <td>[811, 21]</td>\n      <td>Roy</td>\n    </tr>\n  </tbody>\n</table>\n<p>8000 rows Ã— 10 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-camel",
   "metadata": {},
   "source": [
    "In track_genres column, genres_all's sequence is turbulent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-patio",
   "metadata": {},
   "source": [
    "## 2. Sort Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "creative-spectrum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_data = 'small_data'\n",
    "# if use_data == 'small_data':\n",
    "#     data = small_data\n",
    "#     data_train = small_data_train\n",
    "#     data_test = small_data_test\n",
    "#     data_val = small_data_val\n",
    "# elif use_data == 'medium_data':\n",
    "#     data = small_data\n",
    "#     data_train = medium_data_train\n",
    "#     data_test = medium_data_test\n",
    "#     data_val = medium_data_val\n",
    "# elif use_data == 'large_data':\n",
    "#     data = large_data\n",
    "#     data_train = large_data_train\n",
    "#     data_test = large_data_test\n",
    "#     data_val = large_data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "independent-toolbox",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_id2id = {}\n",
    "genre_str2id = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "prompt-covering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading genre str2ids...\n"
     ]
    }
   ],
   "source": [
    "def init_genre():\n",
    "    # reading relation ids...\n",
    "#     global genre_id2id\n",
    "#     print('reading genre id2id...')\n",
    "#     f = open(RAW_DATA_PATH + \"/fma_metadata/genre_id2id.csv\",\"r\")\n",
    "#     total = (int)(f.readline().strip())\n",
    "#     for i in range(total):\n",
    "#         content = f.readline().strip().split(',')\n",
    "#         genre_id2id[content[0]] = int(content[1])\n",
    "#     f.close()\n",
    "    \n",
    "    global genre_str2id\n",
    "    print('reading genre str2ids...')\n",
    "    f = open(RAW_DATA_PATH + \"/fma_metadata/genre_str2id.csv\",\"r\")\n",
    "    total = (int)(f.readline().strip())\n",
    "    for i in range(total):\n",
    "        content = f.readline().strip().split(',')\n",
    "        genre_str2id[content[0]] = int(content[1])\n",
    "    f.close()\n",
    "init_genre()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "legislative-jacob",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'NA': 0,\n 'Avant-Garde': 1,\n 'International': 2,\n 'Blues': 3,\n 'Jazz': 4,\n 'Classical': 5,\n 'Novelty': 6,\n 'Comedy': 7,\n 'Old-Time / Historic': 8,\n 'Country': 9,\n 'Pop': 10,\n 'Disco': 11,\n 'Rock': 12,\n 'Easy Listening': 13,\n 'Soul-RnB': 14,\n 'Electronic': 15,\n 'Sound Effects': 16,\n 'Folk': 17,\n 'Soundtrack': 18,\n 'Funk': 19,\n 'Spoken': 20,\n 'Hip-Hop': 21,\n 'Audio Collage': 22,\n 'Punk': 25,\n 'Post-Rock': 26,\n 'Lo-Fi': 27,\n 'Field Recordings': 30,\n 'Metal': 31,\n 'Noise': 32,\n 'Psych-Folk': 33,\n 'Krautrock': 36,\n 'Jazz: Vocal': 37,\n 'Experimental': 38,\n 'Electroacoustic': 41,\n 'Ambient Electronic': 42,\n 'Radio Art': 43,\n 'Loud-Rock': 45,\n 'Latin America': 46,\n 'Drone': 47,\n 'Free-Folk': 49,\n 'Noise-Rock': 53,\n 'Psych-Rock': 58,\n 'Bluegrass': 63,\n 'Electro-Punk': 64,\n 'Radio': 65,\n 'Indie-Rock': 66,\n 'Industrial': 70,\n 'No Wave': 71,\n 'Free-Jazz': 74,\n 'Experimental Pop': 76,\n 'French': 77,\n 'Reggae - Dub': 79,\n 'Afrobeat': 81,\n 'Nerdcore': 83,\n 'Garage': 85,\n 'Indian': 86,\n 'New Wave': 88,\n 'Post-Punk': 89,\n 'Sludge': 90,\n 'African': 92,\n 'Freak-Folk': 94,\n 'Jazz: Out': 97,\n 'Progressive': 98,\n 'Alternative Hip-Hop': 100,\n 'Death-Metal': 101,\n 'Middle East': 102,\n 'Singer-Songwriter': 103,\n 'Ambient': 107,\n 'Hardcore': 109,\n 'Power-Pop': 111,\n 'Space-Rock': 113,\n 'Polka': 117,\n 'Balkan': 118,\n 'Unclassifiable': 125,\n 'Europe': 130,\n 'Americana': 137,\n 'Spoken Weird': 138,\n 'Interview': 166,\n 'Black-Metal': 167,\n 'Rockabilly': 169,\n 'Easy Listening: Vocal': 170,\n 'Brazilian': 171,\n 'Asia-Far East': 172,\n 'N. Indian Traditional': 173,\n 'South Indian Traditional': 174,\n 'Bollywood': 175,\n 'Pacific': 176,\n 'Celtic': 177,\n 'Be-Bop': 178,\n 'Big Band/Swing': 179,\n 'British Folk': 180,\n 'Techno': 181,\n 'House': 182,\n 'Glitch': 183,\n 'Minimal Electronic': 184,\n 'Breakcore - Hard': 185,\n 'Sound Poetry': 186,\n '20th Century Classical': 187,\n 'Poetry': 188,\n 'Talk Radio': 189,\n 'North African': 214,\n 'Sound Collage': 224,\n 'Flamenco': 232,\n 'IDM': 236,\n 'Chiptune': 240,\n 'Musique Concrete': 247,\n 'Improv': 250,\n 'New Age': 267,\n 'Trip-Hop': 286,\n 'Dance': 296,\n 'Chip Music': 297,\n 'Lounge': 311,\n 'Goth': 314,\n 'Composed Music': 322,\n 'Drum & Bass': 337,\n 'Shoegaze': 359,\n 'Kid-Friendly': 360,\n 'Thrash': 361,\n 'Synth Pop': 362,\n 'Banter': 374,\n 'Deep Funk': 377,\n 'Spoken Word': 378,\n 'Chill-out': 400,\n 'Bigbeat': 401,\n 'Surf': 404,\n 'Radio Theater': 428,\n 'Grindcore': 439,\n 'Rock Opera': 440,\n 'Opera': 441,\n 'Chamber Music': 442,\n 'Choral Music': 443,\n 'Symphony': 444,\n 'Minimalism': 456,\n 'Musical Theater': 465,\n 'Dubstep': 468,\n 'Skweee': 491,\n 'Western Swing': 493,\n 'Downtempo': 495,\n 'Cumbia': 502,\n 'Latin': 504,\n 'Sound Art': 514,\n 'Romany (Gypsy)': 524,\n 'Compilation': 538,\n 'Rap': 539,\n 'Breakbeat': 542,\n 'Gospel': 567,\n 'Abstract Hip-Hop': 580,\n 'Reggae - Dancehall': 602,\n 'Spanish': 619,\n 'Country & Western': 651,\n 'Contemporary Classical': 659,\n 'Wonky': 693,\n 'Jungle': 695,\n 'Klezmer': 741,\n 'Holiday': 763,\n 'Salsa': 808,\n 'Nu-Jazz': 810,\n 'Hip-Hop Beats': 811,\n 'Modern Jazz': 906,\n 'Turkish': 1032,\n 'Tango': 1060,\n 'Fado': 1156,\n 'Christmas': 1193,\n 'Instrumental': 1235}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_str2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "nasty-clark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'155314,22940,Live Performance,24357,training,medium,Rock,[25],[25, 12]\\n'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for indexs in large_data.index:\n",
    "    origin_data = large_data.loc[indexs].values[0:-1]\n",
    "origin_data\n",
    "origin_data[0]\n",
    "\",\".join(str(x) for x in origin_data.tolist()) +'\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sought-olive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ss = \"\"\n",
    "# for s in origin_data:\n",
    "#     ss += str(s)\n",
    "# ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "official-actor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_files(name):\n",
    "    data = {}\n",
    "    if name == 'small_data':\n",
    "        data = small_data\n",
    "    elif name == 'medium_data':\n",
    "        data = medium_data\n",
    "    elif name == 'large_data':\n",
    "        data = large_data\n",
    "    hash = {}\n",
    "    s = 0\n",
    "    for indexs in data.index:\n",
    "        origin_data = data.loc[indexs].values[0:-1]\n",
    "        album_id = data.loc[indexs].values[1]\n",
    "        artist_id =  data.loc[indexs].values[3]\n",
    "#         print(album_id, artist_id, data.loc[indexs].values[7])\n",
    "        genre_name = data.loc[indexs].values[6]\n",
    "        if  genre_name in genre_str2id:\n",
    "            genre_id = genre_str2id[genre_name]\n",
    "        else:\n",
    "            genre_id = genre_str2id['NA']\n",
    "#         if data.loc[indexs].values[8]:\n",
    "#             genre_id =  data.loc[indexs].values[8][-1] \n",
    "#         else:\n",
    "#             genre_id = 0\n",
    "        s = s + 1\n",
    "        id = str(album_id)+\"#\"+str(artist_id)+\"#\"+str(genre_id)\n",
    "        if not id in hash:\n",
    "            hash[id] = []\n",
    "        hash[id].append(\"-----\".join(str(x) for x in origin_data.tolist()) +'\\n')\n",
    "    f = open(RAW_DATA_PATH + '/' + name + \"_sort.txt\", \"w\", encoding=\"utf-8\")\n",
    "    f.write(\"%d\\n\"%(s))\n",
    "    for i in hash:\n",
    "        for j in hash[i]:\n",
    "            f.write(j)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "quick-florida",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_files('small_data')\n",
    "sort_files('medium_data')\n",
    "sort_files('large_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-terror",
   "metadata": {},
   "source": [
    "### 2.1 Sort Training Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "monetary-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_train_files(name):\n",
    "    data = {}\n",
    "    if name == 'small_data_train':\n",
    "        data = small_data_train\n",
    "    elif name == 'medium_data_train':\n",
    "        data = medium_data_train\n",
    "    elif name == 'large_data_train':\n",
    "        data = large_data_train\n",
    "    hash = {}\n",
    "    s = 0\n",
    "    for indexs in data.index:\n",
    "        origin_data = data.loc[indexs].values[0:-1]\n",
    "        album_id = data.loc[indexs].values[1]\n",
    "        artist_id =  data.loc[indexs].values[3]\n",
    "#         print(album_id, artist_id, data.loc[indexs].values[7])\n",
    "        genre_name = data.loc[indexs].values[6]\n",
    "        if  genre_name in genre_str2id:\n",
    "            genre_id = genre_str2id[genre_name]\n",
    "        else:\n",
    "            genre_id = genre_str2id['NA']\n",
    "#         if data.loc[indexs].values[8]:\n",
    "#             genre_id =  data.loc[indexs].values[8][-1] \n",
    "#         else:\n",
    "#             genre_id = 0\n",
    "        s = s + 1\n",
    "        id = str(album_id)+\"#\"+str(artist_id)+\"#\"+str(genre_id)\n",
    "        if not id in hash:\n",
    "            hash[id] = []\n",
    "        hash[id].append(\"-----\".join(str(x) for x in origin_data.tolist()) +'\\n')\n",
    "    f = open(RAW_DATA_PATH + '/' + name + \"_sort.txt\", \"w\")\n",
    "    f.write(\"%d\\n\"%(s))\n",
    "    for i in hash:\n",
    "        for j in hash[i]:\n",
    "            f.write(j)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "embedded-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_train_files('small_data_train')\n",
    "sort_train_files('medium_data_train')\n",
    "sort_train_files('large_data_train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-inspiration",
   "metadata": {},
   "source": [
    "### 2.2 Sort Validation Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "august-taste",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_val_files(name):\n",
    "    data = {}\n",
    "    if name == 'small_data_val':\n",
    "        data = small_data_val\n",
    "    elif name == 'medium_data_val':\n",
    "        data = medium_data_val\n",
    "    elif name == 'large_data_val':\n",
    "        data = large_data_val\n",
    "    hash = {}\n",
    "    s = 0\n",
    "    for indexs in data.index:\n",
    "        origin_data = data.loc[indexs].values[0:-1]\n",
    "        album_id = data.loc[indexs].values[1]\n",
    "        artist_id =  data.loc[indexs].values[3]\n",
    "#         print(album_id, artist_id, data.loc[indexs].values[7])\n",
    "        genre_name = data.loc[indexs].values[6]\n",
    "        if  genre_name in genre_str2id:\n",
    "            genre_id = genre_str2id[genre_name]\n",
    "        else:\n",
    "            genre_id = genre_str2id['NA']\n",
    "#         if data.loc[indexs].values[8]:\n",
    "#             genre_id =  data.loc[indexs].values[8][-1] \n",
    "#         else:\n",
    "#             genre_id = 0\n",
    "        s = s + 1\n",
    "        id = str(album_id)+\"#\"+str(artist_id)+\"#\"+str(genre_id)\n",
    "        if not id in hash:\n",
    "            hash[id] = []\n",
    "        hash[id].append(\"-----\".join(str(x) for x in origin_data.tolist()) +'\\n')\n",
    "    f = open(RAW_DATA_PATH + '/' + name + \"_sort.txt\", \"w\")\n",
    "    f.write(\"%d\\n\"%(s))\n",
    "    for i in hash:\n",
    "        for j in hash[i]:\n",
    "            f.write(j)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "plastic-planning",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_val_files('small_data_val')\n",
    "sort_val_files('medium_data_val')\n",
    "sort_val_files('large_data_val')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "natural-emerald",
   "metadata": {},
   "source": [
    "### 2.3 Sort Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "geographic-curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_test_files(name):\n",
    "    data = {}\n",
    "    if name == 'small_data_test':\n",
    "        data = small_data_test\n",
    "    elif name == 'medium_data_test':\n",
    "        data = medium_data_test\n",
    "    elif name == 'large_data_test':\n",
    "        data = large_data_test\n",
    "    hash = {}\n",
    "    s = 0\n",
    "    for indexs in data.index:\n",
    "        origin_data = data.loc[indexs].values[0:-1]\n",
    "        album_id = data.loc[indexs].values[1]\n",
    "        artist_id =  data.loc[indexs].values[3]\n",
    "#         print(album_id, artist_id, data.loc[indexs].values[7])\n",
    "        genre_name = data.loc[indexs].values[6]\n",
    "        if  genre_name in genre_str2id:\n",
    "            genre_id = genre_str2id[genre_name]\n",
    "        else:\n",
    "            genre_id = genre_str2id['NA']\n",
    "#         if data.loc[indexs].values[8]:\n",
    "#             genre_id =  data.loc[indexs].values[8][-1] \n",
    "#         else:\n",
    "#             genre_id = 0\n",
    "        s = s + 1\n",
    "        id = str(album_id)+\"#\"+str(artist_id)\n",
    "        if not id in hash:\n",
    "            hash[id] = []\n",
    "        hash[id].append(\"-----\".join(str(x) for x in origin_data.tolist()) +'\\n')\n",
    "    f = open(RAW_DATA_PATH + '/' + name + \"_sort.txt\", \"w\")\n",
    "    f.write(\"%d\\n\"%(s))\n",
    "    for i in hash:\n",
    "        for j in hash[i]:\n",
    "            f.write(j)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "divine-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_test_files('small_data_test')\n",
    "sort_test_files('medium_data_test')\n",
    "sort_test_files('large_data_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-thumb",
   "metadata": {},
   "source": [
    "## 3. Init Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "express-messenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_files(name):\n",
    "    print('reading ' + name +' data...')\n",
    "    f = open(RAW_DATA_PATH + '/'+ name + '.txt','r')\n",
    "    total = (int)(f.readline().strip())\n",
    "    print(total)\n",
    "    sen_len = np.zeros((total), dtype = np.int32)\n",
    "    sen_label = np.zeros((total), dtype = np.int32)\n",
    "    sen_label_bottom = np.zeros((total), dtype = np.int32)\n",
    "    instance_scope = []\n",
    "    instance_triple = []\n",
    "    for s in range(total):\n",
    "        content = f.readline().strip().split('-----')\n",
    "        album_id = content[1]\n",
    "        artist_id = content[3]\n",
    "#         print(content)\n",
    "        genre_name = content[6]\n",
    "        if  genre_name in genre_str2id:\n",
    "            genre_id = genre_str2id[genre_name]\n",
    "        else:\n",
    "            genre_id = genre_str2id['NA']\n",
    "        genre_id_bottom = literal_eval(content[8])\n",
    "        if genre_id_bottom:\n",
    "            genre_id_bottom =  genre_id_bottom[-1] \n",
    "        else:\n",
    "            genre_id_bottom = 0\n",
    "        sen_label[s] = genre_id\n",
    "        sen_label_bottom[s] = genre_id_bottom\n",
    "        tup = (album_id,artist_id,genre_id)\n",
    "        if instance_triple == [] or instance_triple[len(instance_triple) - 1] != tup:\n",
    "            instance_triple.append(tup)\n",
    "            instance_scope.append([s,s])\n",
    "        instance_scope[len(instance_triple) - 1][1] = s\n",
    "#         if (s+1) % 100 == 0:\n",
    "#             sys.stdout.write(str(s)+'\\r')\n",
    "#             sys.stdout.flush()\n",
    "    return np.array(instance_triple), np.array(instance_scope), sen_label, sen_label_bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bored-atlantic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "reading small_data_sort data...\n",
      "8000\n",
      "reading medium_data_sort data...\n",
      "25000\n",
      "reading large_data_sort data...\n",
      "106574\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "small_instance_triple, small_instance_scope, small_label, small_label_bottom = init_files(\"small_data_sort\")\n",
    "medium_instance_triple, medium_instance_scope, medium_label, medium_label_bottom = init_files(\"medium_data_sort\")\n",
    "large_instance_triple, large_instance_scope, large_label, large_label_bottom = init_files(\"large_data_sort\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "rental-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(DATA_PATH+'/' + 'small_instance_triple', small_instance_triple)\n",
    "np.save(DATA_PATH+'/' + 'small_instance_scope', small_instance_scope)\n",
    "np.save(DATA_PATH+'/' + 'small_label', small_label)\n",
    "np.save(DATA_PATH+'/' + 'small_label_bottom', small_label_bottom)\n",
    "np.save(DATA_PATH+'/' + 'medium_instance_triple', medium_instance_triple)\n",
    "np.save(DATA_PATH+'/' + 'medium_instance_scope', medium_instance_scope)\n",
    "np.save(DATA_PATH+'/' + 'medium_label', medium_label)\n",
    "np.save(DATA_PATH+'/' + 'medium_label_bottom', medium_label_bottom)\n",
    "np.save(DATA_PATH+'/' + 'large_instance_triple', large_instance_triple)\n",
    "np.save(DATA_PATH+'/' + 'large_instance_scope', large_instance_scope)\n",
    "np.save(DATA_PATH+'/' + 'large_label', large_label)\n",
    "np.save(DATA_PATH+'/' + 'large_label_bottom', large_label_bottom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-jesus",
   "metadata": {},
   "source": [
    "### 3.1 Init Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "arranged-bookmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def init_train_files(name):\n",
    "#     print('reading ' + name +' data...')\n",
    "#     f = open(RAW_DATA_PATH + '/'+ name + '.txt','r')\n",
    "#     total = (int)(f.readline().strip())\n",
    "#     print(total)\n",
    "#     sen_len = np.zeros((total), dtype = np.int32)\n",
    "#     sen_label = np.zeros((total), dtype = np.int32)\n",
    "#     instance_scope = []\n",
    "#     instance_triple = []\n",
    "#     for s in range(total):\n",
    "#         content = f.readline().strip().split('-----')\n",
    "#         album_id = content[1]\n",
    "#         artist_id = content[3]\n",
    "# #         print(content)'\n",
    "#         genre_name = content[6]\n",
    "#         if  genre_name in genre_str2id:\n",
    "#             genre_id = genre_str2id[genre_name]\n",
    "#         else:\n",
    "# #             print(genre_name)\n",
    "#             genre_id = genre_str2id['NA']\n",
    "#         genre_id = literal_eval(content[7])\n",
    "#         if genre_id:\n",
    "#             genre_id =  genre_id[0] \n",
    "#         else:\n",
    "#             genre_id = 0\n",
    "#         sen_label[s] = genre_id\n",
    "#         tup = (album_id,artist_id,genre_id)\n",
    "#         if instance_triple == [] or instance_triple[len(instance_triple) - 1] != tup:\n",
    "#             instance_triple.append(tup)\n",
    "#             instance_scope.append([s,s])\n",
    "#         instance_scope[len(instance_triple) - 1][1] = s\n",
    "# #         if (s+1) % 100 == 0:\n",
    "# #             sys.stdout.write(str(s)+'\\r')\n",
    "# #             sys.stdout.flush()\n",
    "#     return np.array(instance_triple), np.array(instance_scope), sen_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "promotional-validation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "reading small_data_train_sort data...\n",
      "6400\n",
      "reading medium_data_train_sort data...\n",
      "19922\n",
      "reading large_data_train_sort data...\n",
      "84353\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "small_instance_triple_train, small_instance_scope_train, small_label_train, small_label_bottom_train = init_files(\"small_data_train_sort\")\n",
    "medium_instance_triple_train, medium_instance_scope_train, medium_label_train, medium_label_bottom_train = init_files(\"medium_data_train_sort\")\n",
    "large_instance_triple_train, large_instance_scope_train, large_label_train, large_label_bottom_train = init_files(\"large_data_train_sort\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "steady-redhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# large_instance_triple_train, large_instance_scope_train, large_label_train = init_train_files(\"large_data_train_sort\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "consecutive-banking",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(DATA_PATH+'/' + 'small_train_instance_triple', small_instance_triple_train)\n",
    "np.save(DATA_PATH+'/' + 'small_train_instance_scope', small_instance_scope_train)\n",
    "np.save(DATA_PATH+'/' + 'small_train_label', small_label_train)\n",
    "np.save(DATA_PATH+'/' + 'small_label_train_bottom', small_label_bottom_train)\n",
    "np.save(DATA_PATH+'/' + 'medium_train_instance_triple', medium_instance_triple_train)\n",
    "np.save(DATA_PATH+'/' + 'medium_train_instance_scope', medium_instance_scope_train)\n",
    "np.save(DATA_PATH+'/' + 'medium_train_label', medium_label_train)\n",
    "np.save(DATA_PATH+'/' + 'medium_label_bottom_train', medium_label_bottom_train)\n",
    "np.save(DATA_PATH+'/' + 'large_train_instance_triple', large_instance_triple_train)\n",
    "np.save(DATA_PATH+'/' + 'large_train_instance_scope', large_instance_scope_train)\n",
    "np.save(DATA_PATH+'/' + 'large_train_label', large_label_train)\n",
    "np.save(DATA_PATH+'/' + 'large_label_bottom_train', large_label_bottom_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-observation",
   "metadata": {},
   "source": [
    "### 3.2 Init Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "italic-brown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def init_val_files(name):\n",
    "#     print('reading ' + name +' data...')\n",
    "#     f = open(RAW_DATA_PATH + '/'+ name + '.txt','r')\n",
    "#     total = (int)(f.readline().strip())\n",
    "#     print(total)\n",
    "#     sen_len = np.zeros((total), dtype = np.int32)\n",
    "#     sen_label = np.zeros((total), dtype = np.int32)\n",
    "#     instance_scope = []\n",
    "#     instance_triple = []\n",
    "#     for s in range(total):\n",
    "#         content = f.readline().strip().split('-----')\n",
    "#         album_id = content[1]\n",
    "#         artist_id = content[3]\n",
    "# #         print(content)\n",
    "#         genre_name = content[6]\n",
    "#         if  genre_name in genre_str2id:\n",
    "#             genre_id = genre_str2id[genre_name]\n",
    "#         else:\n",
    "#             genre_id = genre_str2id['NA']\n",
    "# #         genre_id = literal_eval(content[8])\n",
    "# #         if genre_id:\n",
    "# #             genre_id =  genre_id[-1] \n",
    "# #         else:\n",
    "# #             genre_id = 0\n",
    "#         sen_label[s] = genre_id\n",
    "#         tup = (album_id,artist_id,genre_id)\n",
    "#         if instance_triple == [] or instance_triple[len(instance_triple) - 1] != tup:\n",
    "#             instance_triple.append(tup)\n",
    "#             instance_scope.append([s,s])\n",
    "#         instance_scope[len(instance_triple) - 1][1] = s\n",
    "# #         if (s+1) % 100 == 0:\n",
    "# #             sys.stdout.write(str(s)+'\\r')\n",
    "# #             sys.stdout.flush()\n",
    "#     return np.array(instance_triple), np.array(instance_scope), sen_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "lovely-nylon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "reading small_data_val_sort data...\n",
      "800\n",
      "reading medium_data_val_sort data...\n",
      "2505\n",
      "reading large_data_val_sort data...\n",
      "10958\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "small_instance_triple_val, small_instance_scope_val, small_label_val, small_label_bottom_val = init_files(\"small_data_val_sort\")\n",
    "medium_instance_triple_val, medium_instance_scope_val, medium_label_val, medium_label_bottom_val = init_files(\"medium_data_val_sort\")\n",
    "large_instance_triple_val, large_instance_scope_val, large_label_val, large_label_bottom_val = init_files(\"large_data_val_sort\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "recorded-resource",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(DATA_PATH+'/' + 'small_val_instance_triple', small_instance_triple_val)\n",
    "np.save(DATA_PATH+'/' + 'small_val_instance_scope', small_instance_scope_val)\n",
    "np.save(DATA_PATH+'/' + 'small_val_label', small_label_val)\n",
    "np.save(DATA_PATH+'/' + 'small_label_bottom_val', small_label_bottom_val)\n",
    "np.save(DATA_PATH+'/' + 'medium_val_instance_triple', medium_instance_triple_val)\n",
    "np.save(DATA_PATH+'/' + 'medium_val_instance_scope', medium_instance_scope_val)\n",
    "np.save(DATA_PATH+'/' + 'medium_val_label', medium_label_val)\n",
    "np.save(DATA_PATH+'/' + 'medium_label_bottom_val', medium_label_bottom_val)\n",
    "np.save(DATA_PATH+'/' + 'large_val_instance_triple', large_instance_triple_val)\n",
    "np.save(DATA_PATH+'/' + 'large_val_instance_scope', large_instance_scope_val)\n",
    "np.save(DATA_PATH+'/' + 'large_val_label', large_label_val)\n",
    "np.save(DATA_PATH+'/' + 'large_label_bottom_val', large_label_bottom_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-russia",
   "metadata": {},
   "source": [
    "### 3.3 Init Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "brief-pointer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_test_files(name):\n",
    "    print('reading ' + name +' data...')\n",
    "    f = open(RAW_DATA_PATH + '/'+ name + '.txt','r')\n",
    "    total = (int)(f.readline().strip())\n",
    "    print(total)\n",
    "    sen_label = np.zeros((total), dtype = np.int32)\n",
    "    sen_label_bottom = np.zeros((total), dtype = np.int32)\n",
    "    entity_pair = []\n",
    "    entity_scope = []\n",
    "    for s in range(total):\n",
    "        content = f.readline().strip().split('-----')\n",
    "        album_id = content[1]\n",
    "        artist_id = content[3]\n",
    "#         print(content)\n",
    "        genre_name = content[6]\n",
    "        if  genre_name in genre_str2id:\n",
    "            genre_id = genre_str2id[genre_name]\n",
    "        else:\n",
    "#             print(genre_name)\n",
    "            genre_id = genre_str2id['NA']\n",
    "        genre_id_bottom = literal_eval(content[8])\n",
    "        if genre_id_bottom:\n",
    "            genre_id_bottom =  genre_id_bottom[-1] \n",
    "        else:\n",
    "            genre_id_bottom = 0\n",
    "        sen_label[s] = genre_id\n",
    "        sen_label_bottom[s] = genre_id_bottom\n",
    "        pair = (album_id,artist_id)\n",
    "        if entity_pair == [] or entity_pair[-1] != pair:\n",
    "            entity_pair.append(pair)\n",
    "            entity_scope.append([s,s])\n",
    "        entity_scope[-1][1] = s\n",
    "#         if (s+1) % 100 == 0:\n",
    "#             sys.stdout.write(str(s)+'\\r')\n",
    "#             sys.stdout.flush()\n",
    "    return np.array(entity_pair), np.array(entity_scope),  sen_label, sen_label_bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "extended-russia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "reading small_data_test_sort data...\n",
      "800\n",
      "reading medium_data_test_sort data...\n",
      "2573\n",
      "reading large_data_test_sort data...\n",
      "11263\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "small_instance_triple_test, small_instance_scope_test, small_label_test, small_label_bottom_test = init_test_files(\"small_data_test_sort\")\n",
    "medium_instance_triple_test, medium_instance_scope_test, medium_label_test, medium_label_bottom_test = init_test_files(\"medium_data_test_sort\")\n",
    "large_instance_triple_test, large_instance_scope_test, large_label_test, large_label_bottom_test = init_test_files(\"large_data_test_sort\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "convertible-permit",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(DATA_PATH+'/' + 'small_test_entity_pair', small_instance_triple_test)\n",
    "np.save(DATA_PATH+'/' + 'small_test_entity_scope', small_instance_scope_test)\n",
    "np.save(DATA_PATH+'/' + 'small_test_label', small_label_test)\n",
    "np.save(DATA_PATH+'/' + 'small_label_bottom_test', small_label_bottom_test)\n",
    "np.save(DATA_PATH+'/' + 'medium_test_entity_pair', medium_instance_triple_test)\n",
    "np.save(DATA_PATH+'/' + 'medium_test_entity_scope', medium_instance_scope_test)\n",
    "np.save(DATA_PATH+'/' + 'medium_test_label', medium_label_test)\n",
    "np.save(DATA_PATH+'/' + 'medium_label_bottom_test', medium_label_bottom_test)\n",
    "np.save(DATA_PATH+'/' + 'large_test_entity_pair', large_instance_triple_test)\n",
    "np.save(DATA_PATH+'/' + 'large_test_entity_scope', large_instance_scope_test)\n",
    "np.save(DATA_PATH+'/' + 'large_test_label', large_label_test)\n",
    "np.save(DATA_PATH+'/' + 'large_label_bottom_test', large_label_bottom_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-relay",
   "metadata": {},
   "source": [
    "## 4. Transform Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-treasurer",
   "metadata": {},
   "source": [
    "### 4.1 initialize bag label for test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "velvet-behavior",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-decimal",
   "metadata": {},
   "source": [
    "#### Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bulgarian-profession",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Counter({12: 100,\n         2: 100,\n         17: 100,\n         38: 100,\n         1235: 100,\n         10: 100,\n         21: 100,\n         15: 100})"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_label = np.load(DATA_PATH + '/' + 'small_test_label.npy')\n",
    "small_scope = np.load(DATA_PATH + '/' + 'small_test_entity_scope.npy')\n",
    "Counter(small_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "antique-shame",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Counter({0: 100, 1: 100, 2: 100, 3: 100, 4: 100, 5: 100, 6: 100, 7: 100})"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_label = np.load(DATA_PATH + '/' + 'small_test_label.npy')\n",
    "small_scope = np.load(DATA_PATH + '/' + 'small_test_entity_scope.npy')\n",
    "small_label[small_label == 12] = 0\n",
    "small_label[small_label == 2] = 1\n",
    "small_label[small_label == 17] = 2\n",
    "small_label[small_label == 38] = 3\n",
    "small_label[small_label == 1235] = 4\n",
    "small_label[small_label == 10] = 5\n",
    "small_label[small_label == 21] = 6\n",
    "small_label[small_label == 15] = 7\n",
    "Counter(small_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "earned-milton",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_all_true_label = np.zeros((small_scope.shape[0], np.max(small_label)+1))\n",
    "for pid in range(small_scope.shape[0]):\n",
    "    small_all_true_label[pid][small_label[small_scope[pid][0]:small_scope[pid][1]+1]] = 1\n",
    "small_all_true_label = np.reshape(small_all_true_label[:, 1:], -1)\n",
    "np.save(DATA_PATH + '/'  + 'small_all_true_label.npy', small_all_true_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "partial-criminal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([0., 0., 0., ..., 0., 1., 0.])"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_all_true_label"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Medium"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Transform Label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "transform_medium_dict = {12:0, 2:1, 17:2, 38:3, 1235:4, 10:5, 21:6, 15:7, 14:8, 3:9, 8:10, 4:11, 9:12, 5:13, 20:14, 13:15}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def transform_medium_label(label_pd):\n",
    "    for i in range(len(label_pd)):\n",
    "        label_pd[i] = transform_medium_dict.get(label_pd[i])\n",
    "    return label_pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "[2, 3, 4, 5, 8, 9, 10, 12, 13, 14, 15, 17, 20, 21, 38, 1235]"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_label = np.load(DATA_PATH + '/' + 'medium_test_label.npy')\n",
    "medium_scope = np.load(DATA_PATH + '/' + 'medium_test_entity_scope.npy')\n",
    "sorted(Counter(medium_label).keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "medium_label_transform = transform_medium_label(np.load(DATA_PATH+'/' + 'medium_label.npy'))\n",
    "medium_train_label_transform = transform_medium_label( np.load(DATA_PATH+'/' + 'medium_train_label.npy'))\n",
    "medium_val_label_transform = transform_medium_label(np.load(DATA_PATH+'/' + 'medium_val_label.npy'))\n",
    "medium_test_label_transform = transform_medium_label(np.load(DATA_PATH+'/' + 'medium_test_label.npy'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "(25000, 19922, 2505, 2573)"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.save(DATA_PATH+'/' + \"medium_label_transform\", medium_label_transform)\n",
    "np.save(DATA_PATH+'/' + \"medium_train_label_transform\", medium_train_label_transform)\n",
    "np.save(DATA_PATH+'/' + \"medium_val_label_transform\", medium_val_label_transform)\n",
    "np.save(DATA_PATH+'/' + \"medium_test_label_transform\", medium_test_label_transform)\n",
    "len(medium_label_transform), len(medium_train_label_transform), len(medium_val_label_transform), len(medium_test_label_transform)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "(2573, 19922, 2505, 2573)"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(medium_label), len(medium_label_train), len(medium_label_val), len(medium_label_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_label_test_tramsform = np.load(DATA_PATH + '/' + 'medium_test_label_transform.npy')\n",
    "medium_scope = np.load(DATA_PATH + '/' + 'medium_test_entity_scope.npy')\n",
    "sorted(Counter(medium_label_test_tramsform).keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[   0,    0],\n       [   1,    6],\n       [   7,    9],\n       ...,\n       [2568, 2569],\n       [2570, 2571],\n       [2572, 2572]])"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_scope"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1., 0., 0., ..., 0., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_all_true_label_transform = np.zeros((medium_scope.shape[0], np.max(medium_label_test_tramsform)+1))\n",
    "for pid in range(small_scope.shape[0]):\n",
    "    medium_all_true_label_transform[pid][medium_label_test_tramsform[medium_scope[pid][0]:medium_scope[pid][1]+1]] = 1\n",
    "medium_all_true_label_transform"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "(750, 16)"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_all_true_label_transform.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "medium_all_true_label_transform = np.reshape(medium_all_true_label_transform[:, :], -1)\n",
    "np.save(DATA_PATH + '/'  + 'medium_all_true_label_transform.npy', medium_all_true_label_transform)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1., 0., 0., ..., 0., 0., 0.])"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_all_true_label_transform"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Large"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "transform_large_dict = {0: 0, 12:1, 2:2, 17:3, 38:4, 1235:5, 10:6, 21:7, 15:8, 14:9, 3:10, 8:11, 4:12, 9:13, 5:14, 20:15, 13:16}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "def transform_large_label(label_pd):\n",
    "    for i in range(len(label_pd)):\n",
    "        label_pd[i] = transform_large_dict.get(label_pd[i])\n",
    "    return label_pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "[0, 2, 3, 4, 5, 8, 9, 10, 12, 13, 14, 15, 17, 20, 21, 38, 1235]"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_label = np.load(DATA_PATH + '/' + 'large_test_label.npy')\n",
    "large_scope = np.load(DATA_PATH + '/' + 'large_test_entity_scope.npy')\n",
    "sorted(Counter(large_label).keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "Counter({12: 1464,\n         0: 6312,\n         38: 1085,\n         15: 839,\n         3: 13,\n         8: 55,\n         1235: 309,\n         17: 299,\n         9: 18,\n         10: 204,\n         21: 323,\n         2: 128,\n         5: 87,\n         20: 31,\n         4: 47,\n         14: 43,\n         13: 6})"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(large_label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "(106574, 84353, 10958, 11263)"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_label_transform = transform_large_label(np.load(DATA_PATH + '/' + 'large_label.npy'))\n",
    "large_train_label_transform = transform_large_label(np.load(DATA_PATH + '/' + 'large_train_label.npy'))\n",
    "large_val_label_transform = transform_large_label(np.load(DATA_PATH + '/' + 'large_val_label.npy'))\n",
    "large_test_label_transform = transform_large_label(np.load(DATA_PATH + '/' + 'large_test_label.npy'))\n",
    "np.save(DATA_PATH + '/' + \"large_label_transform\", large_label_transform)\n",
    "np.save(DATA_PATH + '/' + \"large_train_label_transform\", large_train_label_transform)\n",
    "np.save(DATA_PATH + '/' + \"large_val_label_transform\", large_val_label_transform)\n",
    "np.save(DATA_PATH + '/' + \"large_test_label_transform\", large_test_label_transform)\n",
    "len(large_label_transform), len(large_train_label_transform), len(large_val_label_transform), len(large_test_label_transform)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0., 1., 0., ..., 0., 0., 0.])"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(large_label), len(large_label_train), len(large_label_val), len(large_label_test)\n",
    "large_label_test_tramsform = np.load(DATA_PATH + '/' + 'large_test_label_transform.npy')\n",
    "large_scope = np.load(DATA_PATH + '/' + 'large_test_entity_scope.npy')\n",
    "sorted(Counter(large_label_test_tramsform).keys())\n",
    "large_scope\n",
    "large_all_true_label_transform = np.zeros((large_scope.shape[0], np.max(large_label_test_tramsform) + 1))\n",
    "for pid in range(small_scope.shape[0]):\n",
    "    large_all_true_label_transform[pid][large_label_test_tramsform[large_scope[pid][0]:large_scope[pid][1] + 1]] = 1\n",
    "large_all_true_label_transform\n",
    "large_all_true_label_transform = np.reshape(large_all_true_label_transform[:, :], -1)\n",
    "np.save(DATA_PATH + '/' + 'large_all_true_label_transform.npy', large_all_true_label_transform)\n",
    "large_all_true_label_transform"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "designing-thomson",
   "metadata": {},
   "source": [
    "### 4.2 Get Bottom ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-sweden",
   "metadata": {},
   "source": [
    "#### Medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "demanding-anxiety",
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_label_bottom = np.load(DATA_PATH + '/' + 'medium_label_bottom.npy')\n",
    "medium_scope = np.load(DATA_PATH + '/' + 'medium_test_entity_scope.npy')\n",
    "# sorted(Counter(medium_label_botto|m).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cultural-courage",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_csv = pd.read_csv(RAW_DATA_PATH + '/' + 'genre2id.csv')\n",
    "orig_id = transform_csv.orig_id.to_list()\n",
    "transform_id = transform_csv.transform_id.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "verbal-huntington",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_medium_dict = {}\n",
    "for i in zip(orig_id, transform_id):\n",
    "    transform_medium_dict[i[0]] = i[1]\n",
    "# transform_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "def transform_medium_label_via_dict(label_pd, transform_medium_dict):\n",
    "    for i in range(len(label_pd)):\n",
    "        label_pd[i] = transform_medium_dict[label_pd[i]]\n",
    "    return label_pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "crazy-mailman",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "46",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[1;32mIn [62]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m medium_label_bottom_transform \u001B[38;5;241m=\u001B[39m \u001B[43mtransform_medium_label_via_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mDATA_PATH\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmedium_label_bottom.npy\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransform_medium_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m medium_train_label_bottom_transform \u001B[38;5;241m=\u001B[39m transform_medium_label_via_dict( np\u001B[38;5;241m.\u001B[39mload(DATA_PATH\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmedium_label_bottom_train.npy\u001B[39m\u001B[38;5;124m'\u001B[39m), transform_medium_dict)\n\u001B[0;32m      3\u001B[0m medium_val_label_bottom_transform \u001B[38;5;241m=\u001B[39m transform_medium_label_via_dict(np\u001B[38;5;241m.\u001B[39mload(DATA_PATH\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmedium_label_bottom_val.npy\u001B[39m\u001B[38;5;124m'\u001B[39m), transform_medium_dict)\n",
      "Input \u001B[1;32mIn [61]\u001B[0m, in \u001B[0;36mtransform_medium_label_via_dict\u001B[1;34m(label_pd, transform_medium_dict)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtransform_medium_label_via_dict\u001B[39m(label_pd, transform_medium_dict):\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(label_pd)):\n\u001B[1;32m----> 3\u001B[0m         label_pd[i] \u001B[38;5;241m=\u001B[39m \u001B[43mtransform_medium_dict\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlabel_pd\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m label_pd\n",
      "\u001B[1;31mKeyError\u001B[0m: 46"
     ]
    }
   ],
   "source": [
    "medium_label_bottom_transform = transform_medium_label_via_dict(np.load(DATA_PATH+'/' + 'medium_label_bottom.npy'), transform_medium_dict)\n",
    "medium_train_label_bottom_transform = transform_medium_label_via_dict( np.load(DATA_PATH+'/' + 'medium_label_bottom_train.npy'), transform_medium_dict)\n",
    "medium_val_label_bottom_transform = transform_medium_label_via_dict(np.load(DATA_PATH+'/' + 'medium_label_bottom_val.npy'), transform_medium_dict)\n",
    "medium_test_label_bottom_transform = transform_medium_label_via_dict(np.load(DATA_PATH+'/' + 'medium_label_bottom_test.npy'), transform_medium_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(DATA_PATH+'/' + \"medium_label_bottom_transform\", medium_label_bottom_transform)\n",
    "np.save(DATA_PATH+'/' + \"medium_train_label_bottom_transform\", medium_train_label_bottom_transform)\n",
    "np.save(DATA_PATH+'/' + \"medium_val_label_bottom_transform\", medium_val_label_bottom_transform)\n",
    "np.save(DATA_PATH+'/' + \"medium_test_label_bottom_transform\", medium_test_label_bottom_transform)\n",
    "len(medium_label_bottom_transform), len(medium_train_label_bottom_transform), len(medium_val_label_bottom_transform), len(medium_test_label_bottom_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-heath",
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_label_bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-inflation",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(Counter(medium_label_bottom_transform).keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Large"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "large_label_bottom = np.load(DATA_PATH + '/' + 'large_label_bottom.npy')\n",
    "large_scope = np.load(DATA_PATH + '/' + 'large_test_entity_scope.npy')\n",
    "sorted(Counter(large_label_bottom).keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transform_csv = pd.read_csv(RAW_DATA_PATH + '/' + 'genre2id-large.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "orig_id = transform_csv.orig_id.to_list()\n",
    "transform_id = transform_csv.transform_id.to_list()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transform_large_dict = {}\n",
    "for i in zip(orig_id, transform_id):\n",
    "    transform_large_dict[i[0]] = i[1]\n",
    "# transform_dict\n",
    "transform_large_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def transform_large_label_via_dict(label_pd, transform_large_dict):\n",
    "    for i in range(len(label_pd)):\n",
    "        print(label_pd[i])\n",
    "        label_pd[i] = transform_large_dict[label_pd[i]]\n",
    "    return label_pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.load(DATA_PATH+'/' + 'large_label_bottom.npy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# large_label_bottom_transform = transform_large_label_via_dict(np.load(DATA_PATH+'/' + 'large_label_bottom.npy'), transform_large_dict)\n",
    "# large_train_label_bottom_transform = transform_large_label_via_dict( np.load(DATA_PATH+'/' + 'large_label_bottom_train.npy'), transform_large_dict)\n",
    "# large_val_label_bottom_transform = transform_large_label_via_dict(np.load(DATA_PATH+'/' + 'large_label_bottom_val.npy'), transform_large_dict)\n",
    "# large_test_label_bottom_transform = transform_large_label_via_dict(np.load(DATA_PATH+'/' + 'large_label_bottom_test.npy'), transform_large_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# np.save(DATA_PATH+'/' + \"large_label_bottom_transform\", large_label_bottom_transform)\n",
    "# np.save(DATA_PATH+'/' + \"large_train_label_bottom_transform\", large_train_label_bottom_transform)\n",
    "# np.save(DATA_PATH+'/' + \"large_val_label_bottom_transform\", large_val_label_bottom_transform)\n",
    "# np.save(DATA_PATH+'/' + \"large_test_label_bottom_transform\", large_test_label_bottom_transform)\n",
    "# len(large_label_bottom_transform), len(large_train_label_bottom_transform), len(large_val_label_bottom_transform), len(large_test_label_bottom_transform)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "large_label_bottom"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sorted(list(Counter(large_label_bottom_transform).keys()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}