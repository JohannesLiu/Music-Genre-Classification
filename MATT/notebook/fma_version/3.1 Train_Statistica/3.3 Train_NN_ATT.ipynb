{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "%matplotlib inline\n",
    "\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import os\n",
    "import sys\n",
    "import sklearn as skl\n",
    "import sklearn.utils, sklearn.preprocessing, sklearn.decomposition, sklearn.svm\n",
    "from kddirkit.networks.models import BaselineModel, CNNModel\n",
    "\n",
    "from ast import literal_eval\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "\"\"\n",
    "sns.set_context(\"notebook\", font_scale=1.5)\n",
    "plt.rcParams['figure.figsize'] = (17, 5)\n",
    "\n",
    "import platform\n",
    "if 'Windows' in platform.platform():\n",
    "    ROOT_PATH = \"D:/PycharmProjects/HMAN\"\n",
    "else:\n",
    "    ROOT_PATH = \"/home/xkliu/PycharmProjects/HMAN\"\n",
    "RAW_DATA_PATH = ROOT_PATH  + \"/raw_data\"\n",
    "DATA_PATH = ROOT_PATH + \"/data\"\n",
    "os.chdir(ROOT_PATH)\n",
    "sys.path.append(\"./\")\n",
    "\n",
    "from kddirkit.utils import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import logging\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from kddirkit.networks.encoders import SentenceEncoder\n",
    "from kddirkit.config import *\n",
    "# from kddirkit.dataloaders import LoadNYT, LoadHierData\n",
    "from kddirkit.frameworks import Trainer\n",
    "from kddirkit.losses.FocalLoss import FocalLoss\n",
    "\n",
    "project_name = 'HMAN'\n",
    "\n",
    "logger = logging.getLogger(project_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Load Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "track_dtype = {'track_id': int, 'album_id': int, 'album_type': str, 'artist_id': int, 'set_split': str,\n",
    "               'set_subset': str, 'track_genre_top': str, 'track_genres': str, 'track_genres_all': str,\n",
    "               'track_title': str}\n",
    "genres_converters = {'track_genres': literal_eval, 'track_genres_all': literal_eval}\n",
    "medium_data = pd.read_csv(RAW_DATA_PATH + '/medium_data.csv', converters=genres_converters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "medium_data_train = pd.read_csv(RAW_DATA_PATH + '/medium_data_train.csv', converters=genres_converters)\n",
    "medium_data_test = pd.read_csv(RAW_DATA_PATH + '/medium_data_test.csv', converters=genres_converters)\n",
    "medium_data_val = pd.read_csv(RAW_DATA_PATH + '/medium_data_val.csv', converters=genres_converters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "array([['1', '1', '21'],\n       ['6', '6', '10'],\n       ['61', '54', '17'],\n       ...,\n       ['22936', '22050', '17'],\n       ['22937', '7820', '38'],\n       ['22940', '24357', '12']], dtype='<U11')"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_instance_triple = np.load(DATA_PATH + '/' + 'medium_instance_triple.npy')\n",
    "medium_instance_scope = np.load(DATA_PATH + '/' + 'medium_instance_scope.npy')\n",
    "medium_label = np.load(DATA_PATH + '/' + 'medium_label.npy')\n",
    "medium_instance_triple"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "array([21, 21, 21, ..., 17, 38, 12])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_train_instance_triple = np.load(DATA_PATH + '/' + 'medium_train_instance_triple.npy')\n",
    "medium_train_instance_scope = np.load(DATA_PATH + '/' + 'medium_train_instance_scope.npy')\n",
    "medium_train_label = np.load(DATA_PATH + '/' + 'medium_train_label.npy')\n",
    "medium_train_label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "medium_val_instance_triple = np.load(DATA_PATH + '/' + 'medium_val_instance_triple.npy')\n",
    "medium_val_instance_scope = np.load(DATA_PATH + '/' + 'medium_val_instance_scope.npy')\n",
    "medium_val_label = np.load(DATA_PATH + '/' + 'medium_val_label.npy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "medium_test_entity_pair = np.load(DATA_PATH + '/' + 'medium_test_entity_pair.npy')\n",
    "medium_test_entity_scope = np.load(DATA_PATH + '/' + 'medium_test_entity_scope.npy')\n",
    "medium_test_label = np.load(DATA_PATH + '/' + 'medium_test_label.npy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "medium_label_transform = np.load(DATA_PATH + '/' + 'medium_label_transform.npy')\n",
    "medium_train_label_transform = np.load(DATA_PATH + '/' + 'medium_train_label_transform.npy')\n",
    "medium_val_label_transform = np.load(DATA_PATH + '/' + 'medium_val_label_transform.npy')\n",
    "medium_test_label_transform = np.load(DATA_PATH + '/' + 'medium_test_label_transform.npy')\n",
    "medium_label_bottom_transform = np.load(DATA_PATH + '/' + 'medium_label_bottom_transform.npy')\n",
    "medium_train_label_bottom_transform = np.load(DATA_PATH + '/' + 'medium_train_label_bottom_transform.npy')\n",
    "medium_val_label_bottom_transform = np.load(DATA_PATH + '/' + 'medium_val_label_bottom_transform.npy')\n",
    "medium_test_label_bottom_transform = np.load(DATA_PATH + '/' + 'medium_test_label_bottom_transform.npy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johan\\AppData\\Local\\Temp\\ipykernel_70344\\691608824.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  medium_data_train_sort = pd.read_csv(RAW_DATA_PATH + '/' + 'medium_data_train_sort.txt', sep ='-----',  skiprows =1, names  = col_name)\n",
      "C:\\Users\\Johan\\AppData\\Local\\Temp\\ipykernel_70344\\691608824.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  medium_data_val_sort = pd.read_csv(RAW_DATA_PATH + '/' + 'medium_data_VAL_sort.txt', sep = '-----',  skiprows =1, names  = col_name)\n",
      "C:\\Users\\Johan\\AppData\\Local\\Temp\\ipykernel_70344\\691608824.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  medium_data_test_sort = pd.read_csv(RAW_DATA_PATH + '/' + 'medium_data_test_sort.txt', sep = '-----', skiprows =1, names  = col_name)\n"
     ]
    }
   ],
   "source": [
    "col_name = ['track_id', 'album_id', 'album_type', 'artist_id', 'set_split', 'set_subset', 'track_genres_top', 'track_genre', 'track_genres_all']\n",
    "medium_data_train_sort = pd.read_csv(RAW_DATA_PATH + '/' + 'medium_data_train_sort.txt', sep ='-----',  skiprows =1, names  = col_name)\n",
    "medium_data_val_sort = pd.read_csv(RAW_DATA_PATH + '/' + 'medium_data_VAL_sort.txt', sep = '-----',  skiprows =1, names  = col_name)\n",
    "medium_data_test_sort = pd.read_csv(RAW_DATA_PATH + '/' + 'medium_data_test_sort.txt', sep = '-----', skiprows =1, names  = col_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "       track_id  album_id        album_type  artist_id set_split set_subset  \\\n0             2         1             Album          1  training      small   \n1             5         1             Album          1  training      small   \n2            10         6             Album          6  training      small   \n3           140        61             Album         54  training      small   \n4           141        60             Album         54  training      small   \n...         ...       ...               ...        ...       ...        ...   \n24995    155297     22935             Album      24354  training     medium   \n24996    155298     22936             Album      22050  training     medium   \n24997    155306     22936             Album      22050  training     medium   \n24998    155307     22937  Live Performance       7820  training     medium   \n24999    155314     22940  Live Performance      24357  training     medium   \n\n      track_genre_top     track_genres track_genres_all         track_title  \n0             Hip-Hop             [21]             [21]                Food  \n1             Hip-Hop             [21]             [21]          This World  \n2                 Pop             [10]             [10]             Freeway  \n3                Folk             [17]             [17]  Queen Of The Wires  \n4                Folk             [17]             [17]                Ohio  \n...               ...              ...              ...                 ...  \n24995    Instrumental  [18, 107, 1235]  [107, 18, 1235]       Nebula Reborn  \n24996            Folk        [17, 103]        [17, 103]     An Idiot Abroad  \n24997            Folk        [17, 103]        [17, 103]            Tiny Man  \n24998    Experimental              [1]          [1, 38]               Kolka  \n24999            Rock             [25]         [25, 12]        Miracle Grow  \n\n[25000 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>track_id</th>\n      <th>album_id</th>\n      <th>album_type</th>\n      <th>artist_id</th>\n      <th>set_split</th>\n      <th>set_subset</th>\n      <th>track_genre_top</th>\n      <th>track_genres</th>\n      <th>track_genres_all</th>\n      <th>track_title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>1</td>\n      <td>Album</td>\n      <td>1</td>\n      <td>training</td>\n      <td>small</td>\n      <td>Hip-Hop</td>\n      <td>[21]</td>\n      <td>[21]</td>\n      <td>Food</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>1</td>\n      <td>Album</td>\n      <td>1</td>\n      <td>training</td>\n      <td>small</td>\n      <td>Hip-Hop</td>\n      <td>[21]</td>\n      <td>[21]</td>\n      <td>This World</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10</td>\n      <td>6</td>\n      <td>Album</td>\n      <td>6</td>\n      <td>training</td>\n      <td>small</td>\n      <td>Pop</td>\n      <td>[10]</td>\n      <td>[10]</td>\n      <td>Freeway</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>140</td>\n      <td>61</td>\n      <td>Album</td>\n      <td>54</td>\n      <td>training</td>\n      <td>small</td>\n      <td>Folk</td>\n      <td>[17]</td>\n      <td>[17]</td>\n      <td>Queen Of The Wires</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>141</td>\n      <td>60</td>\n      <td>Album</td>\n      <td>54</td>\n      <td>training</td>\n      <td>small</td>\n      <td>Folk</td>\n      <td>[17]</td>\n      <td>[17]</td>\n      <td>Ohio</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>24995</th>\n      <td>155297</td>\n      <td>22935</td>\n      <td>Album</td>\n      <td>24354</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Instrumental</td>\n      <td>[18, 107, 1235]</td>\n      <td>[107, 18, 1235]</td>\n      <td>Nebula Reborn</td>\n    </tr>\n    <tr>\n      <th>24996</th>\n      <td>155298</td>\n      <td>22936</td>\n      <td>Album</td>\n      <td>22050</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Folk</td>\n      <td>[17, 103]</td>\n      <td>[17, 103]</td>\n      <td>An Idiot Abroad</td>\n    </tr>\n    <tr>\n      <th>24997</th>\n      <td>155306</td>\n      <td>22936</td>\n      <td>Album</td>\n      <td>22050</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Folk</td>\n      <td>[17, 103]</td>\n      <td>[17, 103]</td>\n      <td>Tiny Man</td>\n    </tr>\n    <tr>\n      <th>24998</th>\n      <td>155307</td>\n      <td>22937</td>\n      <td>Live Performance</td>\n      <td>7820</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Experimental</td>\n      <td>[1]</td>\n      <td>[1, 38]</td>\n      <td>Kolka</td>\n    </tr>\n    <tr>\n      <th>24999</th>\n      <td>155314</td>\n      <td>22940</td>\n      <td>Live Performance</td>\n      <td>24357</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Rock</td>\n      <td>[25]</td>\n      <td>[25, 12]</td>\n      <td>Miracle Grow</td>\n    </tr>\n  </tbody>\n</table>\n<p>25000 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "       track_id  album_id        album_type  artist_id set_split set_subset  \\\n0             2         1             Album          1  training      small   \n1             5         1             Album          1  training      small   \n2             3         1             Album          1  training     medium   \n3           134         1             Album          1  training     medium   \n4         10666         1             Album          1  training     medium   \n...         ...       ...               ...        ...       ...        ...   \n19917    155297     22935             Album      24354  training     medium   \n19918    155298     22936             Album      22050  training     medium   \n19919    155306     22936             Album      22050  training     medium   \n19920    155307     22937  Live Performance       7820  training     medium   \n19921    155314     22940  Live Performance      24357  training     medium   \n\n      track_genres_top      track_genre track_genres_all  \n0              Hip-Hop             [21]             [21]  \n1              Hip-Hop             [21]             [21]  \n2              Hip-Hop             [21]             [21]  \n3              Hip-Hop             [21]             [21]  \n4              Hip-Hop             [21]             [21]  \n...                ...              ...              ...  \n19917     Instrumental  [18, 107, 1235]  [107, 18, 1235]  \n19918             Folk        [17, 103]        [17, 103]  \n19919             Folk        [17, 103]        [17, 103]  \n19920     Experimental              [1]          [1, 38]  \n19921             Rock             [25]         [25, 12]  \n\n[19922 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>track_id</th>\n      <th>album_id</th>\n      <th>album_type</th>\n      <th>artist_id</th>\n      <th>set_split</th>\n      <th>set_subset</th>\n      <th>track_genres_top</th>\n      <th>track_genre</th>\n      <th>track_genres_all</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>1</td>\n      <td>Album</td>\n      <td>1</td>\n      <td>training</td>\n      <td>small</td>\n      <td>Hip-Hop</td>\n      <td>[21]</td>\n      <td>[21]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>1</td>\n      <td>Album</td>\n      <td>1</td>\n      <td>training</td>\n      <td>small</td>\n      <td>Hip-Hop</td>\n      <td>[21]</td>\n      <td>[21]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>Album</td>\n      <td>1</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Hip-Hop</td>\n      <td>[21]</td>\n      <td>[21]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>134</td>\n      <td>1</td>\n      <td>Album</td>\n      <td>1</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Hip-Hop</td>\n      <td>[21]</td>\n      <td>[21]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10666</td>\n      <td>1</td>\n      <td>Album</td>\n      <td>1</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Hip-Hop</td>\n      <td>[21]</td>\n      <td>[21]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19917</th>\n      <td>155297</td>\n      <td>22935</td>\n      <td>Album</td>\n      <td>24354</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Instrumental</td>\n      <td>[18, 107, 1235]</td>\n      <td>[107, 18, 1235]</td>\n    </tr>\n    <tr>\n      <th>19918</th>\n      <td>155298</td>\n      <td>22936</td>\n      <td>Album</td>\n      <td>22050</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Folk</td>\n      <td>[17, 103]</td>\n      <td>[17, 103]</td>\n    </tr>\n    <tr>\n      <th>19919</th>\n      <td>155306</td>\n      <td>22936</td>\n      <td>Album</td>\n      <td>22050</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Folk</td>\n      <td>[17, 103]</td>\n      <td>[17, 103]</td>\n    </tr>\n    <tr>\n      <th>19920</th>\n      <td>155307</td>\n      <td>22937</td>\n      <td>Live Performance</td>\n      <td>7820</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Experimental</td>\n      <td>[1]</td>\n      <td>[1, 38]</td>\n    </tr>\n    <tr>\n      <th>19921</th>\n      <td>155314</td>\n      <td>22940</td>\n      <td>Live Performance</td>\n      <td>24357</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Rock</td>\n      <td>[25]</td>\n      <td>[25, 12]</td>\n    </tr>\n  </tbody>\n</table>\n<p>19922 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_data_train_sort"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Load metadata and features.\n",
    "tracks = utils.load(RAW_DATA_PATH + '/fma_metadata/tracks.csv')\n",
    "genres = utils.load(RAW_DATA_PATH + '/fma_metadata/genres.csv')\n",
    "features = utils.load(RAW_DATA_PATH + '/fma_metadata/features.csv')\n",
    "echonest = utils.load(RAW_DATA_PATH + '/fma_metadata/echonest.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "0             2\n1             5\n2             3\n3           134\n4         10666\n          ...  \n19917    155297\n19918    155298\n19919    155306\n19920    155307\n19921    155314\nName: track_id, Length: 19922, dtype: int64"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_data_train_sort.track_id"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19922 training examples, 2573 testing examples\n",
      "140 features, 16 classes\n"
     ]
    }
   ],
   "source": [
    "small = tracks['set', 'subset'] <= 'medium'\n",
    "\n",
    "train = tracks['set', 'split'] == 'training'\n",
    "small = tracks['set', 'subset'] <= 'medium'\n",
    "\n",
    "train = tracks['set', 'split'] == 'training'\n",
    "val = tracks['set', 'split'] == 'validation'\n",
    "test = tracks['set', 'split'] == 'test'\n",
    "\n",
    "y_train = tracks.loc[medium_data_train_sort.track_id, ('track', 'genre_top')]\n",
    "y_val = tracks.loc[medium_data_val_sort.track_id, ('track', 'genre_top')]\n",
    "y_test = tracks.loc[medium_data_test_sort.track_id, ('track', 'genre_top')]\n",
    "X_train = features.loc[medium_data_train_sort.track_id, 'mfcc']\n",
    "X_val= features.loc[medium_data_val_sort.track_id, 'mfcc']\n",
    "X_test = features.loc[medium_data_test_sort.track_id, 'mfcc']\n",
    "\n",
    "print('{} training examples, {} testing examples'.format(y_train.size, y_test.size))\n",
    "print('{} features, {} classes'.format(X_train.shape[1], np.unique(y_train).size))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johan\\anaconda3\\envs\\HMAN\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johan\\anaconda3\\envs\\HMAN\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johan\\anaconda3\\envs\\HMAN\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[ 2.68300051,  0.75385087,  1.75008045, ..., -0.39059965,\n        -0.66829634, -0.62860366],\n       [-0.0364069 , -0.41132161, -0.34856613, ...,  0.37020135,\n         0.28991045,  0.91080142],\n       [-0.09969836, -0.48945548,  0.04735517, ...,  0.17109902,\n         0.14077713,  0.01436047],\n       ...,\n       [-0.21710572, -0.61654383, -0.19618588, ...,  0.55899703,\n         1.18222817,  0.72873298],\n       [-0.40553948, -0.38936326, -0.36861813, ..., -0.29028054,\n        -0.16343454, -0.19068153],\n       [-0.27282894, -0.56695434, -0.14396324, ..., -1.12420629,\n        -0.09533861, -0.44360725]])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Be sure training samples are shuffled.\n",
    "X_train, y_train = skl.utils.shuffle(X_train, y_train, random_state=42)\n",
    "\n",
    "\n",
    "X_train_np = np.array(X_train).astype('float32')\n",
    "X_test_np = np.array(X_test).astype('float32')\n",
    "X_val_np = np.array(X_val).astype('float32')\n",
    "\n",
    "y_train_np = np.argmax(pd.get_dummies(y_train).to_numpy(), axis=1)\n",
    "y_test_np = np.argmax(pd.get_dummies(y_test).to_numpy(), axis = 1)\n",
    "y_val_np = np.argmax(pd.get_dummies(y_val).to_numpy(), axis = 1)\n",
    "\n",
    "# Standardize features by removing the mean and scaling to unit variance.\n",
    "scaler = skl.preprocessing.StandardScaler(copy=False)\n",
    "scaler.fit_transform(X_train)\n",
    "scaler.transform(X_test)\n",
    "\n",
    "# Support vector classification.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# clf = MLPClassifier()\n",
    "# clf.fit(X_train_np, y_train_np)\n",
    "# score = clf.score(X_test_np, y_test_np)\n",
    "# print('Accuracy: {:.2%}'.format(score))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from kddirkit.networks.encoders import SentenceEncoder\n",
    "from kddirkit.networks.models import BaselineModel\n",
    "from kddirkit.config import *\n",
    "from kddirkit.dataloaders import LoadFMA, LoadHierData\n",
    "from kddirkit.frameworks import Trainer\n",
    "from kddirkit.losses.FocalLoss import FocalLoss\n",
    "\n",
    "parser = Parser(ROOT_PATH + \"/data/config\", \"HMAN\")\n",
    "oneParser = parser.oneParser\n",
    "args, _ = oneParser.parse_known_args(args=[])\n",
    "args = vars(args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "use_cuda = not args['no_cuda'] and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args['seed'])\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "HierDataLoader = LoadHierData.HierDataLoader(workdir=os.getcwd(), pattern='default', device=device)\n",
    "genre_levels_Tensor = HierDataLoader.genre_levels_Tensor.to(device)\n",
    "genre_level_layer = HierDataLoader.genre_level_layer\n",
    "\n",
    "trainDataLoader = LoadFMA.FMATrainDataLoader(device=device)\n",
    "testDataLoader = LoadFMA.FMATestDataLoader(mode=\"pr\", device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader,TensorDataset\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "class argparse():\n",
    "    pass\n",
    "args = argparse()\n",
    "args.epochs, args.learning_rate, args.patience = [10000, 0.001, 4]\n",
    "# args.hidden_size, args.input_size= [40, 30]\n",
    "args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X_train_tensor = torch.Tensor(X_train_np)\n",
    "X_test_tensor = torch.Tensor(X_test_np)\n",
    "X_val_tensor = torch.Tensor(X_val_np)\n",
    "\n",
    "# y_train_tensor = torch.LongTensor(pd.get_dummies(y_train).to_numpy()).to(args.device)\n",
    "# y_test_tensor = torch.LongTensor(pd.get_dummies(y_test).to_numpy()).to(args.device)\n",
    "# y_val_tensor = torch.LongTensor(pd.get_dummies(y_val).to_numpy()).to(args.device)\n",
    "\n",
    "y_train_tensor = np.zeros((len(y_train_np) , 16))  # 相当于 做了一个onehot_dict\n",
    "y_train_tensor[np.arange(len(y_train_np) ), y_train_np] = 1  # 为onehot_dict 赋值\n",
    "y_train_tensor = torch.LongTensor(y_train_tensor)\n",
    "y_test_tensor = np.zeros((len(y_test_np) , 16))  # 相当于 做了一个onehot_dict\n",
    "y_test_tensor[np.arange(len(y_test_np) ), y_test_np] = 1  # 为onehot_dict 赋值\n",
    "y_test_tensor = torch.LongTensor(y_test_tensor)\n",
    "\n",
    "y_val_tensor = np.zeros((len(y_val_np) , 16))  # 相当于 做了一个onehot_dict\n",
    "y_val_tensor[np.arange(len(y_val_np) ), y_val_np] = 1  # 为onehot_dict 赋值\n",
    "y_val_tensor = torch.LongTensor(y_val_tensor)\n",
    "\n",
    "\n",
    "train_dataset=TensorDataset(X_train_tensor,y_train_tensor)\n",
    "test_dataset=TensorDataset(X_test_tensor,y_test_tensor)\n",
    "val_dataset=TensorDataset(X_val_tensor,y_val_tensor)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=1000 , shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=1000, shuffle=True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(dataset=val_dataset,batch_size=1000, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch.utils.data.dataloader.DataLoader at 0x1f7ae8b3a30>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "class BaseAttentionNetwork(nn.Module):\n",
    "    def __init__(self, sentence_encoder, genre_levels, genre_level_layer, keep_prob,\n",
    "                 train_batch_size=None, test_batch_size=262,  num_classes=16, device = \"cuda:0\"):\n",
    "        '''\n",
    "        Pay Attention!\n",
    "        relation_matrix:\n",
    "        id = 0: virtual node\n",
    "        id = 1: NA node\n",
    "        '''\n",
    "        super(BaseAttentionNetwork, self).__init__()\n",
    "        self.keep_prob = keep_prob\n",
    "        self.genre_levels = genre_levels\n",
    "        self.hidden_size = sentence_encoder.hidden_size\n",
    "        self.sentence_encoder = sentence_encoder\n",
    "\n",
    "        self.train_batch_size = train_batch_size\n",
    "        self.test_batch_size = test_batch_size\n",
    "\n",
    "        self.hier = genre_levels.shape[1]\n",
    "        self.layer = genre_level_layer\n",
    "        self.num_classes = num_classes\n",
    "        self.genre_matrixs = []\n",
    "        self.device = device\n",
    "\n",
    "        self.discrimitive_matrix = nn.Parameter(torch.Tensor(num_classes, self.hidden_size))\n",
    "        self.bias = torch.nn.Parameter(torch.Tensor(num_classes))\n",
    "        self.drop = nn.Dropout(1 - self.keep_prob)\n",
    "        self.long_tail = []\n",
    "        self.normal_body = []\n",
    "        self.short_head = []\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        NotImplemented\n",
    "    def forward(self):\n",
    "        NotImplemented\n",
    "    def forward_infer(self):\n",
    "        NotImplemented\n",
    "    def query_func(self, attention_weight, label):\n",
    "        NotImplemented"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "class AttentionNetwork16(BaseAttentionNetwork):\n",
    "    def __init__(self, sentence_encoder, genre_levels, genre_level_layer, keep_prob,\n",
    "                 train_batch_size=None, test_batch_size=262, num_classes=16, device = \"cuda:0\"):\n",
    "        '''\n",
    "        Pay Attention!\n",
    "        relation_matrix:\n",
    "        id = 0: virtual node\n",
    "        id = 1: NA node\n",
    "        '''\n",
    "        super(AttentionNetwork16, self).__init__(sentence_encoder = sentence_encoder,\n",
    "                                                genre_levels= genre_levels,\n",
    "                                                genre_level_layer= genre_level_layer,\n",
    "                                                keep_prob = keep_prob,\n",
    "                                                train_batch_size=train_batch_size,\n",
    "                                                test_batch_size=test_batch_size,\n",
    "                                                num_classes=num_classes,\n",
    "                                                device = device)\n",
    "        self.discrimitive_matrix = nn.Parameter(torch.Tensor(num_classes, self.hidden_size ))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for i in range(self.hier):\n",
    "            self.genre_matrixs.append(nn.Embedding(self.layer[i],  self.hidden_size, _weight=nn.init.xavier_uniform_(\n",
    "                torch.Tensor(self.layer[i],self.hidden_size ))).to(self.device))\n",
    "            # self.genre_matrixs.append(torch.nn.Parameter(nn.init.xavier_uniform_(\n",
    "            #     torch.Tensor(self.layer[i],self.hidden_size, self.hidden_size))).to(self.device))\n",
    "        nn.init.xavier_uniform_(self.discrimitive_matrix)\n",
    "        nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, data):\n",
    "        # data 包含word, pos1, pos2, mask, label, scope\n",
    "        x = sentence_encoder(data['mel'])\n",
    "\n",
    "        label_layer = self.genre_levels[data['label_index']]\n",
    "        attention_logits = []\n",
    "\n",
    "        if self.num_classes == '16':\n",
    "            current_relation = self.genre_matrixs[0](label_layer[:, 0])  # batch * 230\n",
    "        else:\n",
    "            current_relation = self.genre_matrixs[1](label_layer[:, 1])  # batch * 230\n",
    "\n",
    "        # print(label_layer[:, 0])\n",
    "        # print(current_relation.shape, x.shape)\n",
    "        attention_logits.append(torch.sum(current_relation * x, 1))  # batch*230 x batch*230\n",
    "        #             print(\"torch.sum(current_relation * x, 1):\" ,torch.sum(current_relation * x, 1).shape)\n",
    "\n",
    "        attention_logits_stack = torch.stack(attention_logits)  # 将一个batch的结果堆叠起来   2 * batch_size\n",
    "        #         print(\"attention_logits stack shape:\", attention_logits_stack.shape)\n",
    "\n",
    "        attention_score_hidden = torch.cat([\n",
    "            F.softmax(attention_logits_stack[:, data['scope'][i]:data['scope'][i + 1]], dim = -1) for i in\n",
    "            range(self.train_batch_size)], 1)  ###这段出了问题\n",
    "\n",
    "        tower_repre = []\n",
    "        for i in range(self.train_batch_size):\n",
    "            sen_matrix = x[data['scope'][i]:data['scope'][i + 1]]\n",
    "            #             print(\"sen_matrix shape: \",sen_matrix.shape)\n",
    "            layer_score = attention_score_hidden[:,\n",
    "                          data['scope'][i]:data['scope'][i + 1]]  # 查找Layer_score #(2 ,bag_size)\n",
    "            #             print(\"layer_score shape: \",layer_score.shape)\n",
    "            layer_repre = torch.reshape(torch.tanh(layer_score @ sen_matrix), [-1])  # 获得层次化表示表示  # 2 * batch_size @ batch_size *230\n",
    "            #             print(\"layer_score @ sen_matrix shape: \", (layer_score @ sen_matrix).shape) #(2, 230)\n",
    "            tower_repre.append(layer_repre)  # 获得每个句子的表示  append (-1, 460)\n",
    "        #             print(\"layer_repre shape: \", (layer_repre).shape)\n",
    "\n",
    "        stack_repre = self.drop(torch.stack(tower_repre))  # 获得新的表示\n",
    "        logits = stack_repre @ self.discrimitive_matrix.t() + self.bias  # sen_num * 230 matmul 230 * 53 + 53\n",
    "        return logits\n",
    "\n",
    "    def forward_infer(self, data):\n",
    "        x = sentence_encoder(data['mel'])\n",
    "\n",
    "        test_attention_scores = []\n",
    "        if self.num_classes == 16:\n",
    "            current_relation = self.genre_matrixs[0](self.genre_levels[:16, 0])  # batch * 230\n",
    "        else:\n",
    "            current_relation = self.genre_matrixs[1](self.genre_levels[:, 1])  # batch * 230\n",
    "\n",
    "        # current_relation = self.genre_matrixs[0](self.genre_levels[:, 0])  # 53 * 230\n",
    "        current_logit = current_relation @ x.t()  # 53 * batch_size\n",
    "        current_score = torch.cat([F.softmax(current_logit[:, data['scope'][j]:data['scope'][j + 1]], dim = -1) for j in\n",
    "                                   range(self.test_batch_size)], 1)  ##得到每一个袋子的attention_score\n",
    "        test_attention_scores.append(\n",
    "            current_score)  # curr_relation_num * batch_size   堆叠起来，形成两个高度不同的attention_score: 53 * batch_size\n",
    "\n",
    "\n",
    "        test_attention_scores_stack = torch.stack(test_attention_scores, 1)  # 将一个batch的结果堆叠起来: 53* 2* batch_size\n",
    "        #         print(\"attention_logits stack shape:\", attention_logits_stack.shape)\n",
    "\n",
    "        test_tower_output = []\n",
    "        for i in range(self.test_batch_size):\n",
    "            test_sen_matrix = (torch.unsqueeze(x[data['scope'][i]:data['scope'][i + 1]], 0)).repeat(self.num_classes, 1,\n",
    "                                                                                                    1)  # 先将 x[data['scope']] 扩充维度形成  53 * bag_size * 230， 然后在第一维重复53次\n",
    "            #             print(\"sen_matrix shape: \",sen_matrix.shape)\n",
    "            test_layer_score = test_attention_scores_stack[:, :,\n",
    "                               data['scope'][i]:data['scope'][i + 1]]  # 查找Layer_score #(53, 2 ,bag_size)\n",
    "            #             print(\"layer_score shape: \",layer_score.shape)\n",
    "            test_layer_repre = torch.reshape(torch.tanh(test_layer_score @ test_sen_matrix), [self.num_classes,\n",
    "                                                                                  -1])  # 获得层次化表示表示  # 53 * 2 * bag_size @ 53* bag_size *230, 53* 2 *230 ,reshape 53 *460\n",
    "            #             print(\"layer_score @ sen_matrix shape: \", (layer_score @ sen_matrix).shape) #(2, 230) (r_(h, t)^1), (r_(h, t)^2)\n",
    "            #             print(\"layer_repre shape: \", (layer_repre).shape)\n",
    "            test_logits = test_layer_repre @ self.discrimitive_matrix.t() + self.bias  # 53 * 460 @ 460 * 53 +   (53, )\n",
    "            test_output = torch.diagonal(F.softmax(test_logits, dim = -1))\n",
    "            test_tower_output.append(test_output)\n",
    "\n",
    "        test_stack_output = torch.reshape(torch.stack(test_tower_output), [self.test_batch_size, self.num_classes])\n",
    "        return test_stack_output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_units, out_units, dropout=0.1):\n",
    "        super(MLP, self).__init__()\n",
    "        self.num_units = num_units\n",
    "        self.linear_1 = nn.Linear(140, 100)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(100, out_units)\n",
    "        self.hidden_size =out_units\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.linear_1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear_2(x)\n",
    "        x = F.softmax(x, dim=-1)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded\n"
     ]
    }
   ],
   "source": [
    "\"\"\"@nni.variable(nni.choice(50, 100, 160), name=training_batch_size)\"\"\"\n",
    "training_batch_size = 1000\n",
    "\n",
    "\"\"\"@nni.variable(nni.choice(0.2, 0.3, 0.1), name=learning_rate)\"\"\"\n",
    "learning_rate = 0.2\n",
    "\n",
    "weight_decay = 0.0001\n",
    "\n",
    "keep_prob = 0.5\n",
    "\n",
    "hidden_size = 140\n",
    "\n",
    "pattern = \"default\"\n",
    "\n",
    "num_classes = 16\n",
    "\n",
    "HierDataLoader = LoadHierData.HierDataLoader(workdir=os.getcwd(), pattern=pattern, device=device)\n",
    "genre_levels_Tensor = HierDataLoader.genre_levels_Tensor.to(device)\n",
    "genre_level_layer = HierDataLoader.genre_level_layer\n",
    "\n",
    "feature_mode = 'mel_128_128'\n",
    "if num_classes == 16:\n",
    "    trainDataLoader = LoadFMA.FMATrainDataLoader(use_label = 'top', feature_mode = feature_mode, device=device)\n",
    "    testDataLoader = LoadFMA.FMATestDataLoader(mode=\"pr\", use_label = 'top' , feature_mode = feature_mode, device=device)\n",
    "else:\n",
    "    trainDataLoader = LoadFMA.FMATrainDataLoader(use_label = 'bottom', feature_mode = feature_mode, device=device)\n",
    "    testDataLoader = LoadFMA.FMATestDataLoader(mode=\"pr\", use_label = 'bottom' , feature_mode = feature_mode, device=device)\n",
    "\n",
    "print('Data Loaded')\n",
    "\n",
    "\"\"\"@nni.variable(nni.choice(\"cnn\", \"crnn\"), name=encoderName)\"\"\"\n",
    "encoderName = \"MLP\"\n",
    "\n",
    "if encoderName == \"cnn\":\n",
    "    sentence_encoder = SentenceEncoder.MusicCnnEncoder(36, 1360, hidden_size)\n",
    "elif encoderName == \"crnn\":\n",
    "    sentence_encoder = SentenceEncoder.MusicCrnnModel(36, 1360, hidden_size)\n",
    "else:\n",
    "    sentence_encoder = MLP(140, 50)\n",
    "\n",
    "modelName = \"AttentionNetwork16\"\n",
    "\n",
    "if modelName == 'AttentionNetwork16':\n",
    "    model = AttentionNetwork16(sentence_encoder = sentence_encoder,\n",
    "                                            genre_levels=genre_levels_Tensor,\n",
    "                                            genre_level_layer=genre_level_layer,\n",
    "                                            keep_prob=keep_prob,\n",
    "                                            train_batch_size=training_batch_size,\n",
    "                                            test_batch_size=263,\n",
    "                                            num_classes=16,\n",
    "                                            device=device).to(device)\n",
    "elif modelName == 'CNN':\n",
    "    model = CNNModel.CnnModel()\n",
    "\n",
    "criterionName = \"cross_entropy\"\n",
    "\n",
    "if criterionName == \"cross_entropy\":\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "parameters_to_optimize = filter(lambda x: x.requires_grad, model.parameters())\n",
    "optimizer = optim.SGD(parameters_to_optimize,\n",
    "                      learning_rate,\n",
    "                      weight_decay=weight_decay)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0,  0],\n        [ 1,  1],\n        [ 2,  2],\n        [ 3,  3],\n        [ 4,  4],\n        [ 5,  5],\n        [ 6,  6],\n        [ 7,  7],\n        [ 8,  8],\n        [ 9,  9],\n        [10, 10],\n        [11, 11],\n        [12, 12],\n        [13, 13],\n        [14, 14],\n        [15, 15],\n        [ 3, 16],\n        [14, 17],\n        [ 3, 18],\n        [ 0, 19],\n        [ 0, 20],\n        [ 0, 21],\n        [ 3, 22],\n        [ 0, 23],\n        [ 2, 24],\n        [ 0, 25],\n        [11, 26],\n        [ 3, 27],\n        [14, 28],\n        [ 3, 29],\n        [ 0, 30],\n        [ 0, 31],\n        [12, 32],\n        [ 0, 33],\n        [ 0, 34],\n        [ 0, 35],\n        [ 5, 36],\n        [ 1, 37],\n        [ 0, 38],\n        [ 0, 39],\n        [ 2, 40],\n        [ 0, 41],\n        [ 2, 42],\n        [ 0, 43],\n        [ 0, 44],\n        [ 1, 45],\n        [12, 46],\n        [14, 47],\n        [ 0, 48],\n        [12, 49],\n        [ 7, 50],\n        [ 7, 51],\n        [ 7, 52],\n        [ 7, 53],\n        [ 3, 54],\n        [14, 55],\n        [ 7, 56],\n        [ 3, 57],\n        [ 3, 58],\n        [ 7, 59],\n        [15, 60],\n        [ 0, 61],\n        [ 0, 62],\n        [ 0, 63],\n        [ 5, 64],\n        [14, 65],\n        [14, 66],\n        [ 0, 67],\n        [ 0, 68],\n        [ 3, 69],\n        [ 7, 70],\n        [ 6, 71],\n        [ 6, 72],\n        [12, 73],\n        [ 7, 74],\n        [ 3, 75],\n        [11, 76]], device='cuda:0')"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_levels_Tensor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " time 2022-04-13 09:51:41.720598 | losses : 2.58683658 | accuracy: 0.199667 \r\n",
      " time 2022-04-13 09:51:43.546506 | losses : 2.49637198 | accuracy: 0.257167 \r\n",
      " time 2022-04-13 09:51:45.376314 | losses : 2.39335203 | accuracy: 0.255500 \r\n",
      " time 2022-04-13 09:51:47.211450 | losses : 2.36433458 | accuracy: 0.257333 \r\n",
      " time 2022-04-13 09:51:49.017743 | losses : 2.33180594 | accuracy: 0.255333 \r\n",
      " time 2022-04-13 09:51:50.817542 | losses : 2.29049158 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 09:51:52.629129 | losses : 2.30289412 | accuracy: 0.255000 \r\n",
      " time 2022-04-13 09:51:54.406642 | losses : 2.24069977 | accuracy: 0.257167 \r\n",
      " time 2022-04-13 09:51:56.252067 | losses : 2.25721526 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 09:51:58.039536 | losses : 2.21505713 | accuracy: 0.253000 \r\n",
      " time 2022-04-13 09:51:59.841221 | losses : 2.26303077 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 09:52:01.643736 | losses : 2.23578072 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 09:52:03.406576 | losses : 2.19911170 | accuracy: 0.255167 \r\n",
      " time 2022-04-13 09:52:05.241144 | losses : 2.24519110 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 09:52:07.018486 | losses : 2.22005820 | accuracy: 0.254667 \r\n",
      " time 2022-04-13 09:52:08.797034 | losses : 2.17608976 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 09:52:10.637130 | losses : 2.17889571 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 09:52:12.430224 | losses : 2.20603609 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 09:52:14.267617 | losses : 2.21986651 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 09:52:16.093218 | losses : 2.17268467 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 09:52:17.875288 | losses : 2.16711998 | accuracy: 0.256667 \r\n",
      " time 2022-04-13 09:52:19.702168 | losses : 2.16209698 | accuracy: 0.254833 \r\n",
      " time 2022-04-13 09:52:21.506112 | losses : 2.16484380 | accuracy: 0.253833 \r\n",
      " time 2022-04-13 09:52:23.316716 | losses : 2.16096354 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 09:52:25.119983 | losses : 2.15583920 | accuracy: 0.255000 \r\n",
      " time 2022-04-13 09:52:26.895204 | losses : 2.17370391 | accuracy: 0.256000 \r\n",
      " time 2022-04-13 09:52:28.661859 | losses : 2.16505194 | accuracy: 0.255667 \r\n",
      " time 2022-04-13 09:52:30.423193 | losses : 2.13063192 | accuracy: 0.255333 \r\n",
      " time 2022-04-13 09:52:32.193725 | losses : 2.17593074 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 09:52:33.934323 | losses : 2.15375066 | accuracy: 0.255000 \r\n",
      " time 2022-04-13 09:52:35.715742 | losses : 2.12339735 | accuracy: 0.250500 \r\n",
      " time 2022-04-13 09:52:37.493797 | losses : 2.12315774 | accuracy: 0.255333 \r\n",
      " time 2022-04-13 09:52:39.239302 | losses : 2.11925197 | accuracy: 0.256833 \r\n",
      " time 2022-04-13 09:52:41.023883 | losses : 2.16869688 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 09:52:42.792367 | losses : 2.18706298 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 09:52:44.574300 | losses : 2.13917470 | accuracy: 0.252833 \r\n",
      " time 2022-04-13 09:52:46.389931 | losses : 2.10534668 | accuracy: 0.255667 \r\n",
      " time 2022-04-13 09:52:48.220602 | losses : 2.13923717 | accuracy: 0.256667 \r\n",
      " time 2022-04-13 09:52:50.013318 | losses : 2.18330669 | accuracy: 0.256667 \r\n",
      " time 2022-04-13 09:52:51.780691 | losses : 2.13903379 | accuracy: 0.255667 \r\n",
      " time 2022-04-13 09:52:53.594404 | losses : 2.16081405 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 09:52:55.421690 | losses : 2.07761526 | accuracy: 0.255000 \r\n",
      " time 2022-04-13 09:52:57.213075 | losses : 2.15451860 | accuracy: 0.254667 \r\n",
      " time 2022-04-13 09:52:59.012501 | losses : 2.17276978 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 09:53:00.781797 | losses : 2.15710568 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 09:53:02.542950 | losses : 2.11229229 | accuracy: 0.256000 \r\n",
      " time 2022-04-13 09:53:04.330486 | losses : 2.15213537 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 09:53:06.078447 | losses : 2.10707426 | accuracy: 0.257167 \r\n",
      " time 2022-04-13 09:53:07.826561 | losses : 2.17617750 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 09:53:09.599018 | losses : 2.11727333 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 09:53:11.352629 | losses : 2.13361859 | accuracy: 0.255667 \r\n",
      " time 2022-04-13 09:53:13.092009 | losses : 2.12754035 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 09:53:14.848960 | losses : 2.15619445 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 09:53:16.610149 | losses : 2.09700108 | accuracy: 0.252333 \r\n",
      " time 2022-04-13 09:53:18.425455 | losses : 2.14419794 | accuracy: 0.255000 \r\n",
      " time 2022-04-13 09:53:20.188198 | losses : 2.13531184 | accuracy: 0.253333 \r\n",
      " time 2022-04-13 09:53:21.966498 | losses : 2.15247011 | accuracy: 0.256000 \r\n",
      " time 2022-04-13 09:53:23.717363 | losses : 2.15542793 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 09:53:25.459356 | losses : 2.19515300 | accuracy: 0.255333 \r\n",
      " time 2022-04-13 09:53:27.244573 | losses : 2.11077762 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 09:53:29.037320 | losses : 2.14028049 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 09:53:30.827107 | losses : 2.12088037 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 09:53:32.577476 | losses : 2.15087342 | accuracy: 0.256667 \r\n",
      " time 2022-04-13 09:53:34.354681 | losses : 2.12874937 | accuracy: 0.256000 \r\n",
      " time 2022-04-13 09:53:36.341702 | losses : 2.12874842 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 09:53:38.096576 | losses : 2.15130210 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 09:53:39.882680 | losses : 2.17373085 | accuracy: 0.257167 \r\n",
      " time 2022-04-13 09:53:41.623150 | losses : 2.10343337 | accuracy: 0.257000 \r\n",
      " time 2022-04-13 09:53:43.378047 | losses : 2.14552689 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 09:53:45.113606 | losses : 2.08354807 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 09:53:46.834635 | losses : 2.18056965 | accuracy: 0.255667 \r\n",
      " time 2022-04-13 09:53:48.620201 | losses : 2.13722682 | accuracy: 0.252833 \r\n",
      " time 2022-04-13 09:53:50.399899 | losses : 2.12855816 | accuracy: 0.253167 \r\n",
      " time 2022-04-13 09:53:52.161793 | losses : 2.15314746 | accuracy: 0.257167 \r\n",
      " time 2022-04-13 09:53:53.910920 | losses : 2.16276765 | accuracy: 0.248500 \r\n",
      " time 2022-04-13 09:53:55.668808 | losses : 2.12917328 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 09:53:57.454360 | losses : 2.15956736 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 09:53:59.294162 | losses : 2.13002157 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 09:54:01.058460 | losses : 2.12205672 | accuracy: 0.254333 \r\n",
      " time 2022-04-13 09:54:02.807400 | losses : 2.17716575 | accuracy: 0.255667 \r\n",
      " time 2022-04-13 09:54:04.581923 | losses : 2.11405993 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 09:54:06.380308 | losses : 2.13742137 | accuracy: 0.256000 \r\n",
      " time 2022-04-13 09:54:08.186261 | losses : 2.18914461 | accuracy: 0.255333 \r\n",
      " time 2022-04-13 09:54:09.949988 | losses : 2.11660290 | accuracy: 0.257500 \r\n",
      " time 2022-04-13 09:54:11.720479 | losses : 2.08896542 | accuracy: 0.255333 \r\n",
      " time 2022-04-13 09:54:13.513204 | losses : 2.14012718 | accuracy: 0.256667 \r\n",
      " time 2022-04-13 09:54:15.351838 | losses : 2.14590621 | accuracy: 0.251333 \r\n",
      " time 2022-04-13 09:54:17.115677 | losses : 2.14904571 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 09:54:18.949346 | losses : 2.14310718 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 09:54:20.759866 | losses : 2.14913940 | accuracy: 0.257833 \r\n",
      " time 2022-04-13 09:54:22.563420 | losses : 2.11139703 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 09:54:24.393033 | losses : 2.12834883 | accuracy: 0.255500 \r\n",
      " time 2022-04-13 09:54:26.210487 | losses : 2.15611100 | accuracy: 0.256667 \r\n",
      " time 2022-04-13 09:54:28.045475 | losses : 2.10070062 | accuracy: 0.256667 \r\n",
      " time 2022-04-13 09:54:29.870422 | losses : 2.16847205 | accuracy: 0.256000 \r\n",
      " time 2022-04-13 09:54:31.692976 | losses : 2.14241815 | accuracy: 0.255667 \r\n",
      " time 2022-04-13 09:54:33.517957 | losses : 2.16330981 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 09:54:35.315450 | losses : 2.14117742 | accuracy: 0.256000 \r\n",
      " time 2022-04-13 09:54:37.161061 | losses : 2.15545678 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 09:54:39.007990 | losses : 2.11870003 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 09:54:40.820194 | losses : 2.12552714 | accuracy: 0.255667 \r\n",
      " time 2022-04-13 09:54:42.689037 | losses : 2.09863639 | accuracy: 0.249500 \r\n",
      " time 2022-04-13 09:54:44.548488 | losses : 2.19044971 | accuracy: 0.251667 \r\n",
      " time 2022-04-13 09:54:46.386154 | losses : 2.12061858 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 09:54:48.208342 | losses : 2.12407970 | accuracy: 0.251667 \r\n",
      " time 2022-04-13 09:54:50.055359 | losses : 2.11275625 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 09:54:51.887141 | losses : 2.12521601 | accuracy: 0.247500 \r\n",
      " time 2022-04-13 09:54:53.730857 | losses : 2.13432717 | accuracy: 0.256667 \r\n",
      " time 2022-04-13 09:54:55.545359 | losses : 2.09886718 | accuracy: 0.250500 \r\n",
      " time 2022-04-13 09:54:57.401198 | losses : 2.10824776 | accuracy: 0.252167 \r\n",
      " time 2022-04-13 09:54:59.231203 | losses : 2.10040569 | accuracy: 0.252833 \r\n",
      " time 2022-04-13 09:55:01.086360 | losses : 2.14729524 | accuracy: 0.251500 \r\n",
      " time 2022-04-13 09:55:02.926431 | losses : 2.13743186 | accuracy: 0.257333 \r\n",
      " time 2022-04-13 09:55:04.718728 | losses : 2.15260887 | accuracy: 0.255333 \r\n",
      " time 2022-04-13 09:55:06.511488 | losses : 2.13438344 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 09:55:08.346051 | losses : 2.13319921 | accuracy: 0.256000 \r\n",
      " time 2022-04-13 09:55:10.199708 | losses : 2.07650447 | accuracy: 0.256000 \r\n",
      " time 2022-04-13 09:55:12.239806 | losses : 2.10800147 | accuracy: 0.255167 \r\n",
      " time 2022-04-13 09:55:14.102786 | losses : 2.10732651 | accuracy: 0.257000 \r\n",
      " time 2022-04-13 09:55:15.938673 | losses : 2.14641905 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 09:55:17.775113 | losses : 2.18068433 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 09:55:19.578999 | losses : 2.15255427 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 09:55:21.387409 | losses : 2.08846164 | accuracy: 0.255500 \r\n",
      " time 2022-04-13 09:55:23.184242 | losses : 2.11754894 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 09:55:24.976800 | losses : 2.09468102 | accuracy: 0.257000 \r\n",
      " time 2022-04-13 09:55:26.806857 | losses : 2.16650105 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 09:55:28.657226 | losses : 2.06322670 | accuracy: 0.256000 \r\n",
      " time 2022-04-13 09:55:30.468472 | losses : 2.09286213 | accuracy: 0.257167 \r\n",
      " time 2022-04-13 09:55:32.284642 | losses : 2.09504819 | accuracy: 0.256833 \r\n",
      " time 2022-04-13 09:55:34.084395 | losses : 2.11094689 | accuracy: 0.255000 \r\n",
      " time 2022-04-13 09:55:35.945295 | losses : 2.10809541 | accuracy: 0.255167 \r\n",
      " time 2022-04-13 09:55:37.708940 | losses : 2.14352727 | accuracy: 0.257000 \r\n",
      " time 2022-04-13 09:55:39.574294 | losses : 2.09455156 | accuracy: 0.256833 \r\n",
      " time 2022-04-13 09:55:41.448899 | losses : 2.14185739 | accuracy: 0.254333 \r\n",
      " time 2022-04-13 09:55:43.306723 | losses : 2.12905264 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 09:55:45.108550 | losses : 2.16112876 | accuracy: 0.255667 \r\n",
      " time 2022-04-13 09:55:46.899512 | losses : 2.10850382 | accuracy: 0.255000 \r\n",
      " time 2022-04-13 09:55:48.707736 | losses : 2.14144444 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 09:55:50.561757 | losses : 2.19254351 | accuracy: 0.256000 \r\n",
      " time 2022-04-13 09:55:52.349098 | losses : 2.09862232 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 09:55:54.167781 | losses : 2.10278702 | accuracy: 0.255667 \r\n",
      " time 2022-04-13 09:55:55.971527 | losses : 2.16158462 | accuracy: 0.254500 \r\n",
      " time 2022-04-13 09:55:57.774687 | losses : 2.13234925 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 09:55:59.663550 | losses : 2.14998722 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 09:56:01.456571 | losses : 2.14178276 | accuracy: 0.256000 \r\n",
      " time 2022-04-13 09:56:03.274027 | losses : 2.10268950 | accuracy: 0.256667 \r\n",
      " time 2022-04-13 09:56:05.092803 | losses : 2.12651277 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 09:56:06.872718 | losses : 2.15582156 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 09:56:08.713402 | losses : 2.12631440 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 09:56:10.536418 | losses : 2.13959837 | accuracy: 0.257167 \r\n",
      " time 2022-04-13 09:56:12.434661 | losses : 2.12233520 | accuracy: 0.255667 \r\n",
      " time 2022-04-13 09:56:14.267152 | losses : 2.12713003 | accuracy: 0.256000 \r\n",
      " time 2022-04-13 09:56:16.072880 | losses : 2.14905190 | accuracy: 0.255333 \r\n",
      " time 2022-04-13 09:56:18.176668 | losses : 2.13730979 | accuracy: 0.255000 \r\n",
      " time 2022-04-13 09:56:20.015206 | losses : 2.16031694 | accuracy: 0.255167 \r\n",
      " time 2022-04-13 09:56:21.848666 | losses : 2.14763618 | accuracy: 0.255167 \r\n",
      " time 2022-04-13 09:56:23.680777 | losses : 2.14319944 | accuracy: 0.257500 \r\n",
      " time 2022-04-13 09:56:25.481703 | losses : 2.15392637 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 09:56:27.282395 | losses : 2.13174987 | accuracy: 0.255667 \r\n",
      " time 2022-04-13 09:56:29.107712 | losses : 2.20603085 | accuracy: 0.257500 \r\n",
      " time 2022-04-13 09:56:30.950368 | losses : 2.13978720 | accuracy: 0.256667 \r\n",
      " time 2022-04-13 09:56:32.824767 | losses : 2.13350344 | accuracy: 0.255333 \r\n",
      " time 2022-04-13 09:56:34.600171 | losses : 2.16570306 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 09:56:36.426910 | losses : 2.13859224 | accuracy: 0.255167 \r\n",
      " time 2022-04-13 09:56:38.245751 | losses : 2.12396908 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 09:56:40.082304 | losses : 2.16338372 | accuracy: 0.255333 \r\n",
      " time 2022-04-13 09:56:41.912063 | losses : 2.17712617 | accuracy: 0.256667 \r\n",
      " time 2022-04-13 09:56:43.720449 | losses : 2.12808418 | accuracy: 0.254833 \r\n",
      " time 2022-04-13 09:56:45.578356 | losses : 2.13492370 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 09:56:47.408686 | losses : 2.11602736 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 09:56:49.236840 | losses : 2.14920282 | accuracy: 0.256000 \r\n",
      " time 2022-04-13 09:56:51.047869 | losses : 2.14800048 | accuracy: 0.257167 \r\n",
      " time 2022-04-13 09:56:52.917580 | losses : 2.13949823 | accuracy: 0.257167 \r\n",
      " time 2022-04-13 09:56:54.733546 | losses : 2.18491483 | accuracy: 0.256000 \r\n",
      " time 2022-04-13 09:56:56.545436 | losses : 2.09609890 | accuracy: 0.257167 \r\n",
      " time 2022-04-13 09:56:58.346901 | losses : 2.16171312 | accuracy: 0.256833 \r\n",
      " time 2022-04-13 09:57:00.200524 | losses : 2.11809969 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 09:57:02.059688 | losses : 2.12600970 | accuracy: 0.254833 \r\n",
      " time 2022-04-13 09:57:03.899522 | losses : 2.12666225 | accuracy: 0.251833 \r\n",
      " time 2022-04-13 09:57:05.718552 | losses : 2.12363315 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 09:57:07.776818 | losses : 2.11491799 | accuracy: 0.254500 \r\n",
      " time 2022-04-13 09:57:09.609986 | losses : 2.13497829 | accuracy: 0.255500 \r\n",
      " time 2022-04-13 09:57:11.436551 | losses : 2.07893634 | accuracy: 0.255167 \r\n",
      " time 2022-04-13 09:57:13.250064 | losses : 2.14293957 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 09:57:15.063960 | losses : 2.09289098 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 09:57:16.847112 | losses : 2.12567425 | accuracy: 0.256833 \r\n",
      " time 2022-04-13 09:57:18.668122 | losses : 2.10744381 | accuracy: 0.256000 \r\n",
      " time 2022-04-13 09:57:20.537987 | losses : 2.14828587 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 09:57:22.375667 | losses : 2.17567110 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 09:57:24.205648 | losses : 2.11542630 | accuracy: 0.255667 \r\n",
      " time 2022-04-13 09:57:25.988094 | losses : 2.06723380 | accuracy: 0.257167 \r\n",
      " time 2022-04-13 09:57:27.744618 | losses : 2.11993575 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 09:57:29.488612 | losses : 2.13009214 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 09:57:31.265694 | losses : 2.16023803 | accuracy: 0.255000 \r\n",
      " time 2022-04-13 09:57:33.085170 | losses : 2.13495588 | accuracy: 0.255333 \r\n",
      " time 2022-04-13 09:57:34.927144 | losses : 2.13282084 | accuracy: 0.256667 \r\n",
      " time 2022-04-13 09:57:36.827165 | losses : 2.11944628 | accuracy: 0.254833 \r\n",
      " time 2022-04-13 09:57:38.636407 | losses : 2.09076262 | accuracy: 0.252167 \r\n",
      " time 2022-04-13 09:57:40.434863 | losses : 2.12398982 | accuracy: 0.257000 \r\n",
      " time 2022-04-13 09:57:42.252834 | losses : 2.12363696 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 09:57:44.068498 | losses : 2.11354184 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 09:57:45.920295 | losses : 2.09193039 | accuracy: 0.254833 \r\n",
      " time 2022-04-13 09:57:47.942812 | losses : 2.15647531 | accuracy: 0.256667 \r\n",
      " time 2022-04-13 09:57:49.767397 | losses : 2.16038871 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 09:57:51.575449 | losses : 2.16600537 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 09:57:53.386431 | losses : 2.07947373 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 09:57:55.181445 | losses : 2.10558152 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 09:57:56.942700 | losses : 2.16855788 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 09:57:58.737407 | losses : 2.11622405 | accuracy: 0.255500 \r\n",
      " time 2022-04-13 09:58:00.559385 | losses : 2.09917068 | accuracy: 0.256667 \r\n",
      " time 2022-04-13 09:58:02.357014 | losses : 2.12533998 | accuracy: 0.257500 \r\n",
      " time 2022-04-13 09:58:04.158353 | losses : 2.13870025 | accuracy: 0.257167 \r\n",
      " time 2022-04-13 09:58:05.942038 | losses : 2.14452887 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 09:58:07.732937 | losses : 2.10354376 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 09:58:09.493416 | losses : 2.11762428 | accuracy: 0.255500 \r\n",
      " time 2022-04-13 09:58:11.280087 | losses : 2.06749201 | accuracy: 0.257333 \r\n",
      " time 2022-04-13 09:58:13.082933 | losses : 2.12113619 | accuracy: 0.255167 \r\n",
      " time 2022-04-13 09:58:14.910115 | losses : 2.12565756 | accuracy: 0.257000 \r\n",
      " time 2022-04-13 09:58:16.735811 | losses : 2.11070323 | accuracy: 0.252167 \r\n",
      " time 2022-04-13 09:58:18.615812 | losses : 2.10813785 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 09:58:20.498799 | losses : 2.14036322 | accuracy: 0.253167 \r\n",
      " time 2022-04-13 09:58:22.338473 | losses : 2.13992286 | accuracy: 0.255667 \r\n",
      " time 2022-04-13 09:58:24.176007 | losses : 2.15555263 | accuracy: 0.256667 \r\n",
      " time 2022-04-13 09:58:25.975724 | losses : 2.13782692 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 09:58:27.815875 | losses : 2.12656879 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 09:58:29.625660 | losses : 2.08016944 | accuracy: 0.252667 \r\n",
      " time 2022-04-13 09:58:31.467296 | losses : 2.07089186 | accuracy: 0.256000 \r\n",
      " time 2022-04-13 09:58:33.286123 | losses : 2.16245723 | accuracy: 0.250167 \r\n",
      " time 2022-04-13 09:58:35.092434 | losses : 2.09976077 | accuracy: 0.256833 \r\n",
      " time 2022-04-13 09:58:36.921836 | losses : 2.14753222 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 09:58:38.782161 | losses : 2.15191770 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 09:58:40.633114 | losses : 2.11127973 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 09:58:42.462379 | losses : 2.11889601 | accuracy: 0.256000 \r\n",
      " time 2022-04-13 09:58:44.302982 | losses : 2.11334133 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 09:58:46.079211 | losses : 2.10543513 | accuracy: 0.257500 \r\n",
      " time 2022-04-13 09:58:47.901706 | losses : 2.15882301 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 09:58:49.673072 | losses : 2.10279298 | accuracy: 0.256667 \r\n",
      " time 2022-04-13 09:58:51.482480 | losses : 2.15450382 | accuracy: 0.256833 \r\n",
      " time 2022-04-13 09:58:53.280533 | losses : 2.14926195 | accuracy: 0.256667 \r\n",
      " time 2022-04-13 09:58:55.097382 | losses : 2.12040186 | accuracy: 0.256833 \r\n",
      " time 2022-04-13 09:58:56.969501 | losses : 2.10669875 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 09:58:58.829338 | losses : 2.16033077 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 09:59:00.687166 | losses : 2.17351294 | accuracy: 0.256667 \r\n",
      " time 2022-04-13 09:59:02.591462 | losses : 2.17370176 | accuracy: 0.256000 \r\n",
      " time 2022-04-13 09:59:04.643355 | losses : 2.12156487 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 09:59:06.768862 | losses : 2.08421969 | accuracy: 0.252000 \r\n",
      " time 2022-04-13 09:59:08.798995 | losses : 2.10585618 | accuracy: 0.254333 \r\n",
      " time 2022-04-13 09:59:10.894834 | losses : 2.12164593 | accuracy: 0.252000 \r\n",
      " time 2022-04-13 09:59:12.767572 | losses : 2.15507746 | accuracy: 0.255167 \r\n",
      " time 2022-04-13 09:59:14.600640 | losses : 2.12180781 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 09:59:16.391507 | losses : 2.13566542 | accuracy: 0.250500 \r\n",
      " time 2022-04-13 09:59:18.209071 | losses : 2.14691687 | accuracy: 0.256000 \r\n",
      " time 2022-04-13 09:59:20.023891 | losses : 2.13632965 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 09:59:21.854681 | losses : 2.15019894 | accuracy: 0.256667 \r\n",
      " time 2022-04-13 09:59:23.661831 | losses : 2.10248852 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 09:59:25.538852 | losses : 2.14615321 | accuracy: 0.256000 \r\n",
      " time 2022-04-13 09:59:27.375270 | losses : 2.12314963 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 09:59:29.185269 | losses : 2.15203047 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 09:59:31.032376 | losses : 2.09255028 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 09:59:32.886938 | losses : 2.11191368 | accuracy: 0.256667 \r\n",
      " time 2022-04-13 09:59:34.708052 | losses : 2.11585069 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 09:59:36.529974 | losses : 2.14451170 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 09:59:38.331502 | losses : 2.14069581 | accuracy: 0.251167 \r\n",
      " time 2022-04-13 09:59:40.177185 | losses : 2.12960243 | accuracy: 0.256667 \r\n",
      " time 2022-04-13 09:59:41.981625 | losses : 2.14272237 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 09:59:43.797484 | losses : 2.13722920 | accuracy: 0.255500 \r\n",
      " time 2022-04-13 09:59:45.629321 | losses : 2.13191891 | accuracy: 0.256833 \r\n",
      " time 2022-04-13 09:59:47.422790 | losses : 2.13623834 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 09:59:49.210948 | losses : 2.09954357 | accuracy: 0.256833 \r\n",
      " time 2022-04-13 09:59:51.045172 | losses : 2.11805749 | accuracy: 0.255167 \r\n",
      " time 2022-04-13 09:59:52.915716 | losses : 2.10779190 | accuracy: 0.249500 \r\n",
      " time 2022-04-13 09:59:54.753438 | losses : 2.14255738 | accuracy: 0.257167 \r\n",
      " time 2022-04-13 09:59:56.643392 | losses : 2.08386946 | accuracy: 0.257333 \r\n",
      " time 2022-04-13 09:59:58.424551 | losses : 2.13109207 | accuracy: 0.257000 \r\n",
      " time 2022-04-13 10:00:00.227863 | losses : 2.16789341 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 10:00:02.084942 | losses : 2.07770681 | accuracy: 0.255500 \r\n",
      " time 2022-04-13 10:00:03.962779 | losses : 2.19691062 | accuracy: 0.256000 \r\n",
      " time 2022-04-13 10:00:05.768821 | losses : 2.12075543 | accuracy: 0.257500 \r\n",
      " time 2022-04-13 10:00:07.595757 | losses : 2.12229466 | accuracy: 0.256000 \r\n",
      " time 2022-04-13 10:00:09.416419 | losses : 2.12377143 | accuracy: 0.256667 \r\n",
      " time 2022-04-13 10:00:11.237325 | losses : 2.20652628 | accuracy: 0.256000 \r\n",
      " time 2022-04-13 10:00:13.067925 | losses : 2.10275817 | accuracy: 0.257000 \r\n",
      " time 2022-04-13 10:00:14.902742 | losses : 2.14605379 | accuracy: 0.255167 \r\n",
      " time 2022-04-13 10:00:16.687505 | losses : 2.09377074 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 10:00:18.490867 | losses : 2.08511281 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 10:00:20.333871 | losses : 2.12676120 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 10:00:22.137570 | losses : 2.11066127 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 10:00:23.973719 | losses : 2.07348323 | accuracy: 0.255667 \r\n",
      " time 2022-04-13 10:00:25.789332 | losses : 2.10310483 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 10:00:27.592387 | losses : 2.09474897 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 10:00:29.414900 | losses : 2.12354565 | accuracy: 0.256833 \r\n",
      " time 2022-04-13 10:00:31.229344 | losses : 2.14194465 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 10:00:33.020858 | losses : 2.10638738 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 10:00:34.804291 | losses : 2.12837052 | accuracy: 0.257333 \r\n",
      " time 2022-04-13 10:00:36.626526 | losses : 2.08918095 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 10:00:38.419447 | losses : 2.16251206 | accuracy: 0.255667 \r\n",
      " time 2022-04-13 10:00:40.241923 | losses : 2.14860845 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 10:00:42.054845 | losses : 2.09757566 | accuracy: 0.255000 \r\n",
      " time 2022-04-13 10:00:43.871016 | losses : 2.18550324 | accuracy: 0.255333 \r\n",
      " time 2022-04-13 10:00:45.726739 | losses : 2.10736370 | accuracy: 0.255667 \r\n",
      " time 2022-04-13 10:00:47.568562 | losses : 2.11950850 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 10:00:49.352540 | losses : 2.10816383 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 10:00:51.158333 | losses : 2.10909224 | accuracy: 0.256833 \r\n",
      " time 2022-04-13 10:00:52.935474 | losses : 2.06773043 | accuracy: 0.255167 \r\n",
      " time 2022-04-13 10:00:54.705147 | losses : 2.13842869 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 10:00:56.455603 | losses : 2.16375685 | accuracy: 0.256833 \r\n",
      " time 2022-04-13 10:00:58.300692 | losses : 2.15405178 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 10:01:00.457963 | losses : 2.16640019 | accuracy: 0.255167 \r\n",
      " time 2022-04-13 10:01:02.306648 | losses : 2.14666319 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 10:01:04.137792 | losses : 2.11194372 | accuracy: 0.255667 \r\n",
      " time 2022-04-13 10:01:05.933955 | losses : 2.14017844 | accuracy: 0.256667 \r\n",
      " time 2022-04-13 10:01:07.684334 | losses : 2.07692647 | accuracy: 0.256000 \r\n",
      " time 2022-04-13 10:01:09.451265 | losses : 2.12342238 | accuracy: 0.256833 \r\n",
      " time 2022-04-13 10:01:11.207648 | losses : 2.16870117 | accuracy: 0.256000 \r\n",
      " time 2022-04-13 10:01:12.987242 | losses : 2.17637300 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 10:01:14.741084 | losses : 2.13292885 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 10:01:16.508717 | losses : 2.13643670 | accuracy: 0.256667 \r\n",
      " time 2022-04-13 10:01:18.293616 | losses : 2.14980865 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 10:01:20.055295 | losses : 2.13495851 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 10:01:21.814170 | losses : 2.09231091 | accuracy: 0.255667 \r\n",
      " time 2022-04-13 10:01:23.571540 | losses : 2.10253119 | accuracy: 0.256833 \r\n",
      " time 2022-04-13 10:01:25.341160 | losses : 2.13316727 | accuracy: 0.256833 \r\n",
      " time 2022-04-13 10:01:27.098529 | losses : 2.14659548 | accuracy: 0.255167 \r\n",
      " time 2022-04-13 10:01:28.890751 | losses : 2.12190819 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 10:01:30.641664 | losses : 2.10441351 | accuracy: 0.256833 \r\n",
      " time 2022-04-13 10:01:32.369720 | losses : 2.12949324 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 10:01:34.152955 | losses : 2.07216692 | accuracy: 0.255667 \r\n",
      " time 2022-04-13 10:01:35.974253 | losses : 2.11866736 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 10:01:37.785786 | losses : 2.12586737 | accuracy: 0.257167 \r\n",
      " time 2022-04-13 10:01:39.603233 | losses : 2.11284995 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 10:01:41.375762 | losses : 2.09892392 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 10:01:43.161957 | losses : 2.10901976 | accuracy: 0.254667 \r\n",
      " time 2022-04-13 10:01:44.956002 | losses : 2.13272500 | accuracy: 0.256000 \r\n",
      " time 2022-04-13 10:01:46.758329 | losses : 2.14850593 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 10:01:48.559914 | losses : 2.10107136 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 10:01:50.374160 | losses : 2.14726162 | accuracy: 0.256000 \r\n",
      " time 2022-04-13 10:01:52.240855 | losses : 2.09959364 | accuracy: 0.256667 \r\n",
      " time 2022-04-13 10:01:54.046493 | losses : 2.06270409 | accuracy: 0.255667 \r\n",
      " time 2022-04-13 10:01:55.852154 | losses : 2.08086419 | accuracy: 0.256667 \r\n",
      " time 2022-04-13 10:01:57.687573 | losses : 2.15626621 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 10:01:59.575986 | losses : 2.10015988 | accuracy: 0.255167 \r\n",
      " time 2022-04-13 10:02:01.412475 | losses : 2.09543490 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 10:02:03.191492 | losses : 2.14244771 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 10:02:05.003515 | losses : 2.15728641 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 10:02:06.825598 | losses : 2.12427473 | accuracy: 0.257000 \r\n",
      " time 2022-04-13 10:02:08.675643 | losses : 2.12709904 | accuracy: 0.255500 \r\n",
      " time 2022-04-13 10:02:10.524048 | losses : 2.13499999 | accuracy: 0.256000 \r\n",
      " time 2022-04-13 10:02:12.388976 | losses : 2.13186264 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 10:02:14.220587 | losses : 2.15120101 | accuracy: 0.256667 \r\n",
      " time 2022-04-13 10:02:16.078604 | losses : 2.09535575 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 10:02:17.947823 | losses : 2.12790728 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 10:02:19.783572 | losses : 2.14871478 | accuracy: 0.255333 \r\n",
      " time 2022-04-13 10:02:21.663671 | losses : 2.13255191 | accuracy: 0.256667 \r\n",
      " time 2022-04-13 10:02:23.513639 | losses : 2.13070822 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 10:02:25.382134 | losses : 2.15107179 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 10:02:27.188238 | losses : 2.13013005 | accuracy: 0.257000 \r\n",
      " time 2022-04-13 10:02:29.027739 | losses : 2.15059233 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 10:02:30.881634 | losses : 2.11559510 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 10:02:32.716278 | losses : 2.11162710 | accuracy: 0.255333 \r\n",
      " time 2022-04-13 10:02:34.547040 | losses : 2.13781857 | accuracy: 0.255167 \r\n",
      " time 2022-04-13 10:02:36.361605 | losses : 2.06901431 | accuracy: 0.255500 \r\n",
      " time 2022-04-13 10:02:38.265248 | losses : 2.08524799 | accuracy: 0.255667 \r\n",
      " time 2022-04-13 10:02:40.139783 | losses : 2.13967490 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 10:02:42.031246 | losses : 2.11495543 | accuracy: 0.255667 \r\n",
      " time 2022-04-13 10:02:43.908876 | losses : 2.15237212 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 10:02:45.778816 | losses : 2.12785649 | accuracy: 0.255667 \r\n",
      " time 2022-04-13 10:02:47.629817 | losses : 2.16531372 | accuracy: 0.257000 \r\n",
      " time 2022-04-13 10:02:49.497357 | losses : 2.14812613 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 10:02:51.377972 | losses : 2.12871361 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 10:02:53.272365 | losses : 2.13828254 | accuracy: 0.256833 \r\n",
      " time 2022-04-13 10:02:55.151875 | losses : 2.13798428 | accuracy: 0.256667 \r\n",
      " time 2022-04-13 10:02:57.019405 | losses : 2.09612417 | accuracy: 0.255500 \r\n",
      " time 2022-04-13 10:02:58.831757 | losses : 2.16872406 | accuracy: 0.251167 \r\n",
      " time 2022-04-13 10:03:00.689089 | losses : 2.09467602 | accuracy: 0.255667 \r\n",
      " time 2022-04-13 10:03:02.506494 | losses : 2.12582421 | accuracy: 0.255667 \r\n",
      " time 2022-04-13 10:03:04.361237 | losses : 2.14359069 | accuracy: 0.255500 \r\n",
      " time 2022-04-13 10:03:06.198019 | losses : 2.14390445 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 10:03:08.092652 | losses : 2.08897877 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 10:03:09.923724 | losses : 2.11302805 | accuracy: 0.256667 \r\n",
      " time 2022-04-13 10:03:11.752122 | losses : 2.10821176 | accuracy: 0.255167 \r\n",
      " time 2022-04-13 10:03:13.590574 | losses : 2.14601421 | accuracy: 0.257333 \r\n",
      " time 2022-04-13 10:03:15.454322 | losses : 2.13550353 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 10:03:17.299145 | losses : 2.13378358 | accuracy: 0.255333 \r\n",
      " time 2022-04-13 10:03:19.148044 | losses : 2.13966346 | accuracy: 0.255667 \r\n",
      " time 2022-04-13 10:03:21.021058 | losses : 2.13734126 | accuracy: 0.257000 \r\n",
      " time 2022-04-13 10:03:22.852520 | losses : 2.14310336 | accuracy: 0.256000 \r\n",
      " time 2022-04-13 10:03:24.697864 | losses : 2.11126065 | accuracy: 0.257167 \r\n",
      " time 2022-04-13 10:03:26.539536 | losses : 2.10068369 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 10:03:28.389863 | losses : 2.10253978 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 10:03:30.230249 | losses : 2.10645771 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 10:03:32.077292 | losses : 2.11665130 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 10:03:33.908337 | losses : 2.14064884 | accuracy: 0.251167 \r\n",
      " time 2022-04-13 10:03:35.843266 | losses : 2.08371568 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 10:03:37.753680 | losses : 2.11857724 | accuracy: 0.257167 \r\n",
      " time 2022-04-13 10:03:39.662576 | losses : 2.10226178 | accuracy: 0.252333 \r\n",
      " time 2022-04-13 10:03:41.548315 | losses : 2.12829542 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 10:03:43.456887 | losses : 2.13529754 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 10:03:45.351273 | losses : 2.09378934 | accuracy: 0.256000 \r\n",
      " time 2022-04-13 10:03:47.223367 | losses : 2.10067081 | accuracy: 0.255667 \r\n",
      " time 2022-04-13 10:03:49.067513 | losses : 2.12806463 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 10:03:50.923039 | losses : 2.09418082 | accuracy: 0.256500 \r\n",
      " time 2022-04-13 10:03:52.812364 | losses : 2.13180447 | accuracy: 0.256000 \r\n",
      " time 2022-04-13 10:03:54.674832 | losses : 2.13374686 | accuracy: 0.256667 \r\n",
      " time 2022-04-13 10:03:56.588230 | losses : 2.08660269 | accuracy: 0.256667 \r\n",
      " time 2022-04-13 10:03:58.490351 | losses : 2.14196086 | accuracy: 0.255833 \r\n",
      " time 2022-04-13 10:04:00.371791 | losses : 2.10989475 | accuracy: 0.256833 \r\n",
      " time 2022-04-13 10:04:02.257505 | losses : 2.11137342 | accuracy: 0.256333 \r\n",
      " time 2022-04-13 10:04:04.103231 | losses : 2.13119555 | accuracy: 0.256167 \r\n",
      " time 2022-04-13 10:04:05.977051 | losses : 2.14834356 | accuracy: 0.255500 \r\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "for e in range(args.epochs):\n",
    "    model.train()\n",
    "\n",
    "    train_instance_scope = medium_train_instance_scope\n",
    "    train_order = list(range(len(train_instance_scope)))\n",
    "\n",
    "\n",
    "    # if(self.epoch == 0):\n",
    "    #     torch.save(self.model, self.args['model_dir'] + self.args['model'] + '-iter-' + str(0) + '.pkl')  # save entire net\n",
    "    #     torch.save(self.model.state_dict(), self.args['model_dir'] +  self.args['model'] + '-iter-' + str(0) + '.pkl')  # save o\n",
    "    np.random.shuffle(train_order)  # 打乱训练集\n",
    "    s1 = 0.0\n",
    "    s2 = 0.0\n",
    "    tot1 = 0.0\n",
    "    tot2 = 0.0\n",
    "    loss_sum = 0.0\n",
    "    accuracy_sum = 0.0\n",
    "    step_sum = 0.0\n",
    "    for i in range(int(len(train_order) / float(training_batch_size ))):\n",
    "        input_scope = np.take(train_instance_scope, train_order[i * training_batch_size :(i + 1) * training_batch_size ],  axis=0)\n",
    "        index = []\n",
    "        scope = [0]\n",
    "        label = []\n",
    "        for num in input_scope:\n",
    "            index = index + list(range(num[0], num[1] + 1))  # 放入每一个袋子的起点和重点的每个序号\n",
    "            label.append(medium_train_label_transform[num[0]])  # 这个是每个袋子的第一个数的序号的标签\n",
    "            scope.append(scope[len(scope) - 1] + num[1] - num[\n",
    "                0] + 1)  # 这个存的是，当前的scope 类似于[0,1,2, , 19, 27, 35]， 代表着每一个袋子包含的实例的个数\n",
    "        #         print(\"index length:\", len(index), \"label length\", len(label), \"scope length\", len(scope), \"label_\", len(label_))\n",
    "        label_ = np.zeros((training_batch_size , 16))  # 相当于 做了一个onehot_dict\n",
    "        label_[np.arange(training_batch_size ), label] = 1  # 为onehot_dict 赋值\n",
    "        #         output, losses, correct_predictions = train_step(train_word[index,:], train_pos1[index,:], train_pos2[index,:],\n",
    "        #             train_mask[index,:], train_len[index],train_label[index], label_, np.array(scope))\n",
    "\n",
    "        feed_dict = {\n",
    "            'mel': X_train_tensor[index, :].to(args.device),\n",
    "            'label_index': torch.argmax(y_train_tensor[index], dim =1).to(args.device),\n",
    "            'label_': torch.LongTensor(label_).to(args.device),  # 可以不用\n",
    "            'scope': scope\n",
    "        }\n",
    "\n",
    "\n",
    "        logits = model(feed_dict)\n",
    "        output = F.softmax(logits, dim = -1)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(logits, torch.LongTensor(label).to(args.device))  # 计算损失值\n",
    "        # loss = self.criterion(logits, torch.LongTensor(label_).to(self._device))  # 计算损失值\n",
    "        loss.backward()  # 反向传播计算参数的梯度\n",
    "        optimizer.step()  # 使用优化方法进行梯度更新\n",
    "        predictions = torch.argmax(logits, 1)\n",
    "        # print(logits)\n",
    "        correct_predictions = torch.eq(predictions, torch.argmax(torch.LongTensor(label_).to(args.device), 1))\n",
    "        accuracy = torch.mean(correct_predictions.float())\n",
    "\n",
    "        loss_sum += loss.item()  # 更新 losses\n",
    "        step_sum += 1.0  # 更新一个batch 中的step_sum， 疑似等于 i， 这个可能用在外循环上\n",
    "        accuracy_sum += accuracy\n",
    "        step_sum += 0\n",
    "        time_str = datetime.datetime.now().isoformat().replace('T', ' ')\n",
    "        temp_str = ' time {0:26} | losses : {1:1.8f} | accuracy: {2:1.6f} \\r'.format(\n",
    "            time_str, loss.item(),\n",
    "            accuracy)\n",
    "        sys.stdout.write(temp_str)\n",
    "        sys.stdout.flush()\n",
    "        # print(temp_str)\n",
    "\n",
    "\n",
    "    accuracy_sum = accuracy_sum /step_sum\n",
    "    losses = loss_sum / step_sum\n",
    "\n",
    "    # temp_str = 'epoch {0:0>3}/{1:0>3} step {2:0>4} time {3:26} | losses : {4:1.8f} | NA accuracy: {5:1.6f} | not NA accuracy: {6:1.6f}\\r'.format(\n",
    "    #     self.args['restore_epoch'] + self.epoch + 1, self.args['restore_epoch'] + self.args['max_epoch'], i,\n",
    "    #     time_str, losses,\n",
    "    #     na_acc, not_na_acc)\n",
    "    time_str = datetime.datetime.now().isoformat().replace('T', ' ')\n",
    "    temp_str = ' time {0:26} | losses : {1:1.8f} | accuracy: {2:1.6f} \\r'.format(\n",
    "        time_str, loss.item(),\n",
    "        accuracy_sum)\n",
    "    print(temp_str)\n",
    "    accuracy_list.append(accuracy_sum)\n",
    "\n",
    "\n",
    "    #     current_step = tf.train.global_step(sess, global_step) #tensorflow 版本的模型保存\n",
    "    # if (self._epoch + 1) % self.args['save_epoch'] == 0:  # 如果到达一个保存周期\n",
    "    #     # 2 ways to save the net\n",
    "    #     torch.save(self.model, self.args['model_dir'] + self.args['model'] + '-epoch-' + str(self.epoch+1) + '.pkl')  # save entire net\n",
    "    #     torch.save(self.model.state_dict(), self.args['model_dir'] + self.args['model'] + '-epoch-' + str(self.epoch+1) + '.pkl')  # save o"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    stack_output = []  # stack_out 干什么的\n",
    "    accuracy_sum = 0.0\n",
    "    step_sum = 0.0\n",
    "\n",
    "    iteration = len(self.test_instance_scope) // self.args['testing_batch_size']\n",
    "    for i in range(iteration):  # 循环迭代次数\n",
    "        input_scope = self.test_instance_scope[i * self.args['testing_batch_size']:(i + 1) * self.args['testing_batch_size']]\n",
    "        index = []\n",
    "        scope = [0]\n",
    "        label = []\n",
    "        for num in input_scope:\n",
    "            index = index + list(range(num[0], num[1] + 1))\n",
    "            label.append(self.FMATestDataLoader.label[num[0]])\n",
    "            scope.append(scope[len(scope) - 1] + num[1] - num[0] + 1)\n",
    "        label_ = np.zeros((self.args['testing_batch_size'], self.args['num_classes']))\n",
    "        label_[np.arange(self.args['testing_batch_size']), label] = 1\n",
    "        feed_dict = {\n",
    "            # 'word': self.FMATestDataLoader.word_Tensor[index, :],\n",
    "            # 'pos1': self.FMATestDataLoader.pos1_Tensor[index, :],\n",
    "            # 'pos2': self.FMATestDataLoader.pos2_Tensor[index, :],\n",
    "            # 'mask': self.FMATestDataLoader.mask_Tensor[index, :],\n",
    "            'mel': torch.FloatTensor(self.FMATrainDataLoader.feature[index, :]).to(self._device),\n",
    "            'label_index': self.FMATrainDataLoader.label_Tensor[index],\n",
    "            # 'label_': torch.LongTensor(label_).to(self._device),  #\n",
    "            # 'len': self.FMATestDataLoader.len_Tensor[index],\n",
    "            'label_': label_,  # 可以不用\n",
    "            'scope': scope\n",
    "        }\n",
    "        output_Tensor = self.model.forward_infer(feed_dict)\n",
    "        output = output_Tensor.cpu().numpy()\n",
    "        stack_output.append(output)  # 将输出，拼接到输出stack里边\n",
    "        predictions = torch.argmax(output_Tensor, 1)\n",
    "        # print(logits)\n",
    "        correct_predictions = torch.eq(predictions,\n",
    "                                       torch.argmax(torch.LongTensor(label_).to(self._device), 1))\n",
    "        accuracy = torch.mean(correct_predictions.float())\n",
    "        accuracy_sum += accuracy\n",
    "        step_sum += 1.0  # 更新一个batch 中的step_sum， 疑似等于 i， 这个可能用在外循环上\n",
    "\n",
    "    accuracy_ave = accuracy_sum / step_sum\n",
    "\n",
    "    stack_output = np.concatenate(stack_output, axis=0)  # 拼接输出\n",
    "    exclude_na_output = stack_output[:, 0:]  # 拼接从排除NA列的输出\n",
    "    exclude_na_flatten_output = np.reshape(stack_output[:, 0:], (-1))  # 重置stack_output的维度\n",
    "\n",
    "    auc = average_precision_score(self.exclude_na_flatten_label, exclude_na_flatten_output)\n",
    "    mi_ma_100 = self.evalMetric.mi_ma_100(exclude_na_output)\n",
    "    mi_ma_200 = self.evalMetric.mi_ma_200(exclude_na_output)\n",
    "    pr = self.evalMetric.pr(exclude_na_output, exclude_na_flatten_output)\n",
    "    return accuracy_ave.cpu().numpy(), auc, mi_ma_100, mi_ma_200, pr, exclude_na_flatten_output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predictions = model(X_test_tensor.to(args.device))\n",
    "correct_predictions = torch.eq(torch.argmax(predictions, axis= 1), torch.tensor(y_test_np).to(args.device))\n",
    "accuracy = torch.mean(correct_predictions.float())\n",
    "accuracy_list.append(accuracy.cpu().numpy())\n",
    "print(\"epoch={}/{},{}/{} of train, loss={}, training accuracy = {}, testing accuracy = {}\".format(\n",
    "epoch, args.epochs, idx, len(train_dataloader),loss.item(), accuracy_sum/step, accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}