{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "%matplotlib inline\n",
    "\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import os\n",
    "import sys\n",
    "import sklearn as skl\n",
    "import sklearn.utils, sklearn.preprocessing, sklearn.decomposition, sklearn.svm\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "\"\"\n",
    "sns.set_context(\"notebook\", font_scale=1.5)\n",
    "plt.rcParams['figure.figsize'] = (17, 5)\n",
    "\n",
    "import platform\n",
    "if 'Windows' in platform.platform():\n",
    "    ROOT_PATH = \"D:/PycharmProjects/HMAN\"\n",
    "else:\n",
    "    ROOT_PATH = \"/home/xkliu/PycharmProjects/HMAN\"\n",
    "RAW_DATA_PATH = ROOT_PATH  + \"/raw_data\"\n",
    "DATA_PATH = ROOT_PATH + \"/data\"\n",
    "os.chdir(ROOT_PATH)\n",
    "sys.path.append(\"./\")\n",
    "\n",
    "from kddirkit.utils import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import logging\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from kddirkit.networks.encoders import SentenceEncoder\n",
    "from kddirkit.networks.models import BaselineModel\n",
    "from kddirkit.config import *\n",
    "# from kddirkit.dataloaders import LoadNYT, LoadHierData\n",
    "from kddirkit.frameworks import Trainer\n",
    "from kddirkit.losses.FocalLoss import FocalLoss\n",
    "\n",
    "project_name = 'HMAN'\n",
    "\n",
    "logger = logging.getLogger(project_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Load Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "track_dtype = {'track_id': int, 'album_id': int, 'album_type': str, 'artist_id': int, 'set_split': str,\n",
    "               'set_subset': str, 'track_genre_top': str, 'track_genres': str, 'track_genres_all': str,\n",
    "               'track_title': str}\n",
    "genres_converters = {'track_genres': literal_eval, 'track_genres_all': literal_eval}\n",
    "medium_data = pd.read_csv(RAW_DATA_PATH + '/medium_data.csv', converters=genres_converters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "medium_data_train = pd.read_csv(RAW_DATA_PATH + '/medium_data_train.csv', converters=genres_converters)\n",
    "medium_data_test = pd.read_csv(RAW_DATA_PATH + '/medium_data_test.csv', converters=genres_converters)\n",
    "medium_data_val = pd.read_csv(RAW_DATA_PATH + '/medium_data_val.csv', converters=genres_converters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "medium_instance_triple = np.load(DATA_PATH + '/' + 'medium_instance_triple.npy')\n",
    "medium_instance_scope = np.load(DATA_PATH + '/' + 'medium_instance_scope.npy')\n",
    "medium_label = np.load(DATA_PATH + '/' + 'medium_label.npy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "medium_train_instance_triple = np.load(DATA_PATH + '/' + 'medium_train_instance_triple.npy')\n",
    "medium_train_instance_scope = np.load(DATA_PATH + '/' + 'medium_train_instance_scope.npy')\n",
    "medium_train_label = np.load(DATA_PATH + '/' + 'medium_train_label.npy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "medium_val_instance_triple = np.load(DATA_PATH + '/' + 'medium_val_instance_triple.npy')\n",
    "medium_val_instance_scope = np.load(DATA_PATH + '/' + 'medium_val_instance_scope.npy')\n",
    "medium_val_label = np.load(DATA_PATH + '/' + 'medium_val_label.npy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "medium_test_entity_pair = np.load(DATA_PATH + '/' + 'medium_test_entity_pair.npy')\n",
    "medium_test_entity_scope = np.load(DATA_PATH + '/' + 'medium_test_entity_scope.npy')\n",
    "medium_test_label = np.load(DATA_PATH + '/' + 'medium_test_label.npy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "medium_label_transform = np.load(DATA_PATH + '/' + 'medium_label_transform.npy')\n",
    "medium_train_label_transform = np.load(DATA_PATH + '/' + 'medium_train_label_transform.npy')\n",
    "medium_val_label_transform = np.load(DATA_PATH + '/' + 'medium_val_label_transform.npy')\n",
    "medium_test_label_transform = np.load(DATA_PATH + '/' + 'medium_test_label_transform.npy')\n",
    "medium_label_bottom_transform = np.load(DATA_PATH + '/' + 'medium_label_bottom_transform.npy')\n",
    "medium_train_label_bottom_transform = np.load(DATA_PATH + '/' + 'medium_train_label_bottom_transform.npy')\n",
    "medium_val_label_bottom_transform = np.load(DATA_PATH + '/' + 'medium_val_label_bottom_transform.npy')\n",
    "medium_test_label_bottom_transform = np.load(DATA_PATH + '/' + 'medium_test_label_bottom_transform.npy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johan\\AppData\\Local\\Temp\\ipykernel_64284\\691608824.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  medium_data_train_sort = pd.read_csv(RAW_DATA_PATH + '/' + 'medium_data_train_sort.txt', sep ='-----',  skiprows =1, names  = col_name)\n",
      "C:\\Users\\Johan\\AppData\\Local\\Temp\\ipykernel_64284\\691608824.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  medium_data_val_sort = pd.read_csv(RAW_DATA_PATH + '/' + 'medium_data_VAL_sort.txt', sep = '-----',  skiprows =1, names  = col_name)\n",
      "C:\\Users\\Johan\\AppData\\Local\\Temp\\ipykernel_64284\\691608824.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  medium_data_test_sort = pd.read_csv(RAW_DATA_PATH + '/' + 'medium_data_test_sort.txt', sep = '-----', skiprows =1, names  = col_name)\n"
     ]
    }
   ],
   "source": [
    "col_name = ['track_id', 'album_id', 'album_type', 'artist_id', 'set_split', 'set_subset', 'track_genres_top', 'track_genre', 'track_genres_all']\n",
    "medium_data_train_sort = pd.read_csv(RAW_DATA_PATH + '/' + 'medium_data_train_sort.txt', sep ='-----',  skiprows =1, names  = col_name)\n",
    "medium_data_val_sort = pd.read_csv(RAW_DATA_PATH + '/' + 'medium_data_VAL_sort.txt', sep = '-----',  skiprows =1, names  = col_name)\n",
    "medium_data_test_sort = pd.read_csv(RAW_DATA_PATH + '/' + 'medium_data_test_sort.txt', sep = '-----', skiprows =1, names  = col_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "       track_id  album_id        album_type  artist_id set_split set_subset  \\\n0             2         1             Album          1  training      small   \n1             5         1             Album          1  training      small   \n2            10         6             Album          6  training      small   \n3           140        61             Album         54  training      small   \n4           141        60             Album         54  training      small   \n...         ...       ...               ...        ...       ...        ...   \n24995    155297     22935             Album      24354  training     medium   \n24996    155298     22936             Album      22050  training     medium   \n24997    155306     22936             Album      22050  training     medium   \n24998    155307     22937  Live Performance       7820  training     medium   \n24999    155314     22940  Live Performance      24357  training     medium   \n\n      track_genre_top     track_genres track_genres_all         track_title  \n0             Hip-Hop             [21]             [21]                Food  \n1             Hip-Hop             [21]             [21]          This World  \n2                 Pop             [10]             [10]             Freeway  \n3                Folk             [17]             [17]  Queen Of The Wires  \n4                Folk             [17]             [17]                Ohio  \n...               ...              ...              ...                 ...  \n24995    Instrumental  [18, 107, 1235]  [107, 18, 1235]       Nebula Reborn  \n24996            Folk        [17, 103]        [17, 103]     An Idiot Abroad  \n24997            Folk        [17, 103]        [17, 103]            Tiny Man  \n24998    Experimental              [1]          [1, 38]               Kolka  \n24999            Rock             [25]         [25, 12]        Miracle Grow  \n\n[25000 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>track_id</th>\n      <th>album_id</th>\n      <th>album_type</th>\n      <th>artist_id</th>\n      <th>set_split</th>\n      <th>set_subset</th>\n      <th>track_genre_top</th>\n      <th>track_genres</th>\n      <th>track_genres_all</th>\n      <th>track_title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>1</td>\n      <td>Album</td>\n      <td>1</td>\n      <td>training</td>\n      <td>small</td>\n      <td>Hip-Hop</td>\n      <td>[21]</td>\n      <td>[21]</td>\n      <td>Food</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>1</td>\n      <td>Album</td>\n      <td>1</td>\n      <td>training</td>\n      <td>small</td>\n      <td>Hip-Hop</td>\n      <td>[21]</td>\n      <td>[21]</td>\n      <td>This World</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10</td>\n      <td>6</td>\n      <td>Album</td>\n      <td>6</td>\n      <td>training</td>\n      <td>small</td>\n      <td>Pop</td>\n      <td>[10]</td>\n      <td>[10]</td>\n      <td>Freeway</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>140</td>\n      <td>61</td>\n      <td>Album</td>\n      <td>54</td>\n      <td>training</td>\n      <td>small</td>\n      <td>Folk</td>\n      <td>[17]</td>\n      <td>[17]</td>\n      <td>Queen Of The Wires</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>141</td>\n      <td>60</td>\n      <td>Album</td>\n      <td>54</td>\n      <td>training</td>\n      <td>small</td>\n      <td>Folk</td>\n      <td>[17]</td>\n      <td>[17]</td>\n      <td>Ohio</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>24995</th>\n      <td>155297</td>\n      <td>22935</td>\n      <td>Album</td>\n      <td>24354</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Instrumental</td>\n      <td>[18, 107, 1235]</td>\n      <td>[107, 18, 1235]</td>\n      <td>Nebula Reborn</td>\n    </tr>\n    <tr>\n      <th>24996</th>\n      <td>155298</td>\n      <td>22936</td>\n      <td>Album</td>\n      <td>22050</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Folk</td>\n      <td>[17, 103]</td>\n      <td>[17, 103]</td>\n      <td>An Idiot Abroad</td>\n    </tr>\n    <tr>\n      <th>24997</th>\n      <td>155306</td>\n      <td>22936</td>\n      <td>Album</td>\n      <td>22050</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Folk</td>\n      <td>[17, 103]</td>\n      <td>[17, 103]</td>\n      <td>Tiny Man</td>\n    </tr>\n    <tr>\n      <th>24998</th>\n      <td>155307</td>\n      <td>22937</td>\n      <td>Live Performance</td>\n      <td>7820</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Experimental</td>\n      <td>[1]</td>\n      <td>[1, 38]</td>\n      <td>Kolka</td>\n    </tr>\n    <tr>\n      <th>24999</th>\n      <td>155314</td>\n      <td>22940</td>\n      <td>Live Performance</td>\n      <td>24357</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Rock</td>\n      <td>[25]</td>\n      <td>[25, 12]</td>\n      <td>Miracle Grow</td>\n    </tr>\n  </tbody>\n</table>\n<p>25000 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "       track_id  album_id        album_type  artist_id set_split set_subset  \\\n0             2         1             Album          1  training      small   \n1             5         1             Album          1  training      small   \n2             3         1             Album          1  training     medium   \n3           134         1             Album          1  training     medium   \n4         10666         1             Album          1  training     medium   \n...         ...       ...               ...        ...       ...        ...   \n19917    155297     22935             Album      24354  training     medium   \n19918    155298     22936             Album      22050  training     medium   \n19919    155306     22936             Album      22050  training     medium   \n19920    155307     22937  Live Performance       7820  training     medium   \n19921    155314     22940  Live Performance      24357  training     medium   \n\n      track_genres_top      track_genre track_genres_all  \n0              Hip-Hop             [21]             [21]  \n1              Hip-Hop             [21]             [21]  \n2              Hip-Hop             [21]             [21]  \n3              Hip-Hop             [21]             [21]  \n4              Hip-Hop             [21]             [21]  \n...                ...              ...              ...  \n19917     Instrumental  [18, 107, 1235]  [107, 18, 1235]  \n19918             Folk        [17, 103]        [17, 103]  \n19919             Folk        [17, 103]        [17, 103]  \n19920     Experimental              [1]          [1, 38]  \n19921             Rock             [25]         [25, 12]  \n\n[19922 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>track_id</th>\n      <th>album_id</th>\n      <th>album_type</th>\n      <th>artist_id</th>\n      <th>set_split</th>\n      <th>set_subset</th>\n      <th>track_genres_top</th>\n      <th>track_genre</th>\n      <th>track_genres_all</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>1</td>\n      <td>Album</td>\n      <td>1</td>\n      <td>training</td>\n      <td>small</td>\n      <td>Hip-Hop</td>\n      <td>[21]</td>\n      <td>[21]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>1</td>\n      <td>Album</td>\n      <td>1</td>\n      <td>training</td>\n      <td>small</td>\n      <td>Hip-Hop</td>\n      <td>[21]</td>\n      <td>[21]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>Album</td>\n      <td>1</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Hip-Hop</td>\n      <td>[21]</td>\n      <td>[21]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>134</td>\n      <td>1</td>\n      <td>Album</td>\n      <td>1</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Hip-Hop</td>\n      <td>[21]</td>\n      <td>[21]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10666</td>\n      <td>1</td>\n      <td>Album</td>\n      <td>1</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Hip-Hop</td>\n      <td>[21]</td>\n      <td>[21]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19917</th>\n      <td>155297</td>\n      <td>22935</td>\n      <td>Album</td>\n      <td>24354</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Instrumental</td>\n      <td>[18, 107, 1235]</td>\n      <td>[107, 18, 1235]</td>\n    </tr>\n    <tr>\n      <th>19918</th>\n      <td>155298</td>\n      <td>22936</td>\n      <td>Album</td>\n      <td>22050</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Folk</td>\n      <td>[17, 103]</td>\n      <td>[17, 103]</td>\n    </tr>\n    <tr>\n      <th>19919</th>\n      <td>155306</td>\n      <td>22936</td>\n      <td>Album</td>\n      <td>22050</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Folk</td>\n      <td>[17, 103]</td>\n      <td>[17, 103]</td>\n    </tr>\n    <tr>\n      <th>19920</th>\n      <td>155307</td>\n      <td>22937</td>\n      <td>Live Performance</td>\n      <td>7820</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Experimental</td>\n      <td>[1]</td>\n      <td>[1, 38]</td>\n    </tr>\n    <tr>\n      <th>19921</th>\n      <td>155314</td>\n      <td>22940</td>\n      <td>Live Performance</td>\n      <td>24357</td>\n      <td>training</td>\n      <td>medium</td>\n      <td>Rock</td>\n      <td>[25]</td>\n      <td>[25, 12]</td>\n    </tr>\n  </tbody>\n</table>\n<p>19922 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_data_train_sort"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Load metadata and features.\n",
    "tracks = utils.load(RAW_DATA_PATH + '/fma_metadata/tracks.csv')\n",
    "genres = utils.load(RAW_DATA_PATH + '/fma_metadata/genres.csv')\n",
    "features = utils.load(RAW_DATA_PATH + '/fma_metadata/features.csv')\n",
    "echonest = utils.load(RAW_DATA_PATH + '/fma_metadata/echonest.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "0             2\n1             5\n2             3\n3           134\n4         10666\n          ...  \n19917    155297\n19918    155298\n19919    155306\n19920    155307\n19921    155314\nName: track_id, Length: 19922, dtype: int64"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_data_train_sort.track_id"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19922 training examples, 2573 testing examples\n",
      "140 features, 16 classes\n"
     ]
    }
   ],
   "source": [
    "small = tracks['set', 'subset'] <= 'medium'\n",
    "\n",
    "train = tracks['set', 'split'] == 'training'\n",
    "small = tracks['set', 'subset'] <= 'medium'\n",
    "\n",
    "train = tracks['set', 'split'] == 'training'\n",
    "val = tracks['set', 'split'] == 'validation'\n",
    "test = tracks['set', 'split'] == 'test'\n",
    "\n",
    "y_train = tracks.loc[medium_data_train_sort.track_id, ('track', 'genre_top')]\n",
    "y_val = tracks.loc[medium_data_val_sort.track_id, ('track', 'genre_top')]\n",
    "y_test = tracks.loc[medium_data_test_sort.track_id, ('track', 'genre_top')]\n",
    "X_train = features.loc[medium_data_train_sort.track_id, 'mfcc']\n",
    "X_val= features.loc[medium_data_val_sort.track_id, 'mfcc']\n",
    "X_test = features.loc[medium_data_test_sort.track_id, 'mfcc']\n",
    "\n",
    "print('{} training examples, {} testing examples'.format(y_train.size, y_test.size))\n",
    "print('{} features, {} classes'.format(X_train.shape[1], np.unique(y_train).size))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johan\\anaconda3\\envs\\HMAN\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johan\\anaconda3\\envs\\HMAN\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johan\\anaconda3\\envs\\HMAN\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[ 2.68300051,  0.75385087,  1.75008045, ..., -0.39059965,\n        -0.66829634, -0.62860366],\n       [-0.0364069 , -0.41132161, -0.34856613, ...,  0.37020135,\n         0.28991045,  0.91080142],\n       [-0.09969836, -0.48945548,  0.04735517, ...,  0.17109902,\n         0.14077713,  0.01436047],\n       ...,\n       [-0.21710572, -0.61654383, -0.19618588, ...,  0.55899703,\n         1.18222817,  0.72873298],\n       [-0.40553948, -0.38936326, -0.36861813, ..., -0.29028054,\n        -0.16343454, -0.19068153],\n       [-0.27282894, -0.56695434, -0.14396324, ..., -1.12420629,\n        -0.09533861, -0.44360725]])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Be sure training samples are shuffled.\n",
    "X_train, y_train = skl.utils.shuffle(X_train, y_train, random_state=42)\n",
    "\n",
    "\n",
    "X_train_np = np.array(X_train).astype('float32')\n",
    "X_test_np = np.array(X_test).astype('float32')\n",
    "X_val_np = np.array(X_val).astype('float32')\n",
    "\n",
    "y_train_np = np.argmax(pd.get_dummies(y_train).to_numpy(), axis=1)\n",
    "y_test_np = np.argmax(pd.get_dummies(y_test).to_numpy(), axis = 1)\n",
    "y_val_np = np.argmax(pd.get_dummies(y_val).to_numpy(), axis = 1)\n",
    "\n",
    "# Standardize features by removing the mean and scaling to unit variance.\n",
    "scaler = skl.preprocessing.StandardScaler(copy=False)\n",
    "scaler.fit_transform(X_train)\n",
    "scaler.transform(X_test)\n",
    "\n",
    "# Support vector classification.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.75%\n"
     ]
    }
   ],
   "source": [
    "# clf = MLPClassifier()\n",
    "# clf.fit(X_train_np, y_train_np)\n",
    "# score = clf.score(X_test_np, y_test_np)\n",
    "# print('Accuracy: {:.2%}'.format(score))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "from kddirkit.networks.encoders import SentenceEncoder\n",
    "from kddirkit.networks.models import BaselineModel\n",
    "from kddirkit.config import *\n",
    "from kddirkit.dataloaders import LoadFMA, LoadHierData\n",
    "from kddirkit.frameworks import Trainer\n",
    "from kddirkit.losses.FocalLoss import FocalLoss\n",
    "\n",
    "parser = Parser(ROOT_PATH + \"/data/config\", \"HMAN\")\n",
    "oneParser = parser.oneParser\n",
    "args, _ = oneParser.parse_known_args(args=[])\n",
    "args = vars(args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "use_cuda = not args['no_cuda'] and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args['seed'])\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "HierDataLoader = LoadHierData.HierDataLoader(workdir=os.getcwd(), pattern='default', device=device)\n",
    "genre_levels_Tensor = HierDataLoader.genre_levels_Tensor.to(device)\n",
    "genre_level_layer = HierDataLoader.genre_level_layer\n",
    "\n",
    "trainDataLoader = LoadFMA.FMATrainDataLoader(device=device)\n",
    "testDataLoader = LoadFMA.FMATestDataLoader(mode=\"pr\", device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# class MLP(nn.Module):\n",
    "#   def __init__(self, input_size, common_size):\n",
    "#     super(MLP, self).__init__()\n",
    "#     self.linear = nn.Sequential(\n",
    "#       nn.Linear(input_size, common_size),\n",
    "#       nn.LogSoftmax(inplace=True)\n",
    "#       # nn.ReLU(inplace=True)\n",
    "#     )\n",
    "#\n",
    "#   def forward(self, x):\n",
    "#     out = self.linear(x)\n",
    "#     return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_units, out_units, dropout=0.1):\n",
    "        super(MLP, self).__init__()\n",
    "        self.num_units = num_units\n",
    "        self.linear_1 = nn.Linear(140, 100)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(100, out_units)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.linear_1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear_2(x)\n",
    "        x = F.softmax(x, dim=-1)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "# class MLP(nn.Module):\n",
    "#     def __init__(self, num_units, out_units, dropout=0.1):\n",
    "#         super(MLP, self).__init__()\n",
    "#         self.num_units = num_units\n",
    "#         self.linear_1 = nn.Linear(140, 100)\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "#         self.linear_2 = nn.Linear(100, 10)\n",
    "#         self.linear_3 = nn.Linear(10, out_units)\n",
    "#\n",
    "#     def forward(self, x):\n",
    "#\n",
    "#         x = self.linear_1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.linear_2(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.linear_3(x)\n",
    "#         x = F.softmax(x, dim=-1)\n",
    "#\n",
    "#         return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "# fma_data = torch.rand((3, 140)).to(args.device)\n",
    "# test_module = MLP(140, 16).to(args.device)\n",
    "# test_module(fma_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader,TensorDataset\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "class argparse():\n",
    "    pass\n",
    "args = argparse()\n",
    "args.epochs, args.learning_rate, args.patience = [400, 0.001, 4]\n",
    "# args.hidden_size, args.input_size= [40, 30]\n",
    "args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X_train_tensor = torch.Tensor(X_train_np)\n",
    "X_test_tensor = torch.Tensor(X_test_np)\n",
    "X_val_tensor = torch.Tensor(X_val_np)\n",
    "\n",
    "# y_train_tensor = torch.LongTensor(pd.get_dummies(y_train).to_numpy()).to(args.device)\n",
    "# y_test_tensor = torch.LongTensor(pd.get_dummies(y_test).to_numpy()).to(args.device)\n",
    "# y_val_tensor = torch.LongTensor(pd.get_dummies(y_val).to_numpy()).to(args.device)\n",
    "\n",
    "y_train_tensor = np.zeros((len(y_train_np) , 16))  # 相当于 做了一个onehot_dict\n",
    "y_train_tensor[np.arange(len(y_train_np) ), y_train_np] = 1  # 为onehot_dict 赋值\n",
    "y_train_tensor = torch.LongTensor(y_train_tensor)\n",
    "y_test_tensor = np.zeros((len(y_test_np) , 16))  # 相当于 做了一个onehot_dict\n",
    "y_test_tensor[np.arange(len(y_test_np) ), y_test_np] = 1  # 为onehot_dict 赋值\n",
    "y_test_tensor = torch.LongTensor(y_test_tensor)\n",
    "\n",
    "y_val_tensor = np.zeros((len(y_val_np) , 16))  # 相当于 做了一个onehot_dict\n",
    "y_val_tensor[np.arange(len(y_val_np) ), y_val_np] = 1  # 为onehot_dict 赋值\n",
    "y_val_tensor = torch.LongTensor(y_val_tensor)\n",
    "\n",
    "\n",
    "train_dataset=TensorDataset(X_train_tensor,y_train_tensor)\n",
    "test_dataset=TensorDataset(X_test_tensor,y_test_tensor)\n",
    "val_dataset=TensorDataset(X_val_tensor,y_val_tensor)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=1000 , shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=1000, shuffle=True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(dataset=val_dataset,batch_size=1000, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "# class EarlyStopping():\n",
    "#     def __init__(self,patience=7,verbose=False,delta=0):\n",
    "#         self.patience = patience\n",
    "#         self.verbose = verbose\n",
    "#         self.counter = 0\n",
    "#         self.best_score = None\n",
    "#         self.early_stop = False\n",
    "#         self.val_loss_min = np.Inf\n",
    "#         self.delta = delta\n",
    "#     def __call__(self,val_loss,model,path):\n",
    "#         print(\"val_loss={}\".format(val_loss))\n",
    "#         score = -val_loss\n",
    "#         if self.best_score is None:\n",
    "#             self.best_score = score\n",
    "#             self.save_checkpoint(val_loss,model,path)\n",
    "#         elif score < self.best_score+self.delta:\n",
    "#             self.counter+=1\n",
    "#             print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "#             if self.counter>=self.patience:\n",
    "#                 self.early_stop = True\n",
    "#         else:\n",
    "#             self.best_score = score\n",
    "#             self.save_checkpoint(val_loss,model,path)\n",
    "#             self.counter = 0\n",
    "#     def save_checkpoint(self,val_loss,model,path):\n",
    "#         if self.verbose:\n",
    "#             print(\n",
    "#                 f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "#         torch.save(model.state_dict(), path+'/'+'model_checkpoint.pth')\n",
    "#         self.val_loss_min = val_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0/400,0/20 of train, loss=2.8721954822540283, training accuracy = 0.0010000000474974513, testing accuracy = 0.032258063554763794\n",
      "epoch=0/400,10/20 of train, loss=2.560014009475708, training accuracy = 0.23227275907993317, testing accuracy = 0.2922658324241638\n",
      "epoch=1/400,0/20 of train, loss=2.565474033355713, training accuracy = 0.30900001525878906, testing accuracy = 0.29848426580429077\n",
      "epoch=1/400,10/20 of train, loss=2.586824417114258, training accuracy = 0.30372729897499084, testing accuracy = 0.303148090839386\n",
      "epoch=2/400,0/20 of train, loss=2.547996759414673, training accuracy = 0.32500001788139343, testing accuracy = 0.30275943875312805\n",
      "epoch=2/400,10/20 of train, loss=2.5994064807891846, training accuracy = 0.30618181824684143, testing accuracy = 0.30392539501190186\n",
      "epoch=3/400,0/20 of train, loss=2.549370050430298, training accuracy = 0.3240000009536743, testing accuracy = 0.30509135127067566\n",
      "epoch=3/400,10/20 of train, loss=2.560255527496338, training accuracy = 0.3137272894382477, testing accuracy = 0.3074232339859009\n",
      "epoch=4/400,0/20 of train, loss=2.5418472290039062, training accuracy = 0.33100003004074097, testing accuracy = 0.3078118860721588\n",
      "epoch=4/400,10/20 of train, loss=2.5641705989837646, training accuracy = 0.31863638758659363, testing accuracy = 0.3047026991844177\n",
      "epoch=5/400,0/20 of train, loss=2.5436480045318604, training accuracy = 0.33000001311302185, testing accuracy = 0.3085891902446747\n",
      "epoch=5/400,10/20 of train, loss=2.5561270713806152, training accuracy = 0.3179091215133667, testing accuracy = 0.30392539501190186\n",
      "epoch=6/400,0/20 of train, loss=2.5534508228302, training accuracy = 0.32100000977516174, testing accuracy = 0.2996502220630646\n",
      "epoch=6/400,10/20 of train, loss=2.5544931888580322, training accuracy = 0.31645455956459045, testing accuracy = 0.3000388741493225\n",
      "epoch=7/400,0/20 of train, loss=2.535700559616089, training accuracy = 0.3360000252723694, testing accuracy = 0.30275943875312805\n",
      "epoch=7/400,10/20 of train, loss=2.5471553802490234, training accuracy = 0.31800001859664917, testing accuracy = 0.3066459596157074\n",
      "epoch=8/400,0/20 of train, loss=2.547239303588867, training accuracy = 0.32600000500679016, testing accuracy = 0.3054800033569336\n",
      "epoch=8/400,10/20 of train, loss=2.547795057296753, training accuracy = 0.32554545998573303, testing accuracy = 0.3054800033569336\n",
      "epoch=9/400,0/20 of train, loss=2.575464963912964, training accuracy = 0.2980000078678131, testing accuracy = 0.303148090839386\n",
      "epoch=9/400,10/20 of train, loss=2.546543836593628, training accuracy = 0.3206363916397095, testing accuracy = 0.3008161783218384\n",
      "epoch=10/400,0/20 of train, loss=2.538055896759033, training accuracy = 0.3360000252723694, testing accuracy = 0.2996502220630646\n",
      "epoch=10/400,10/20 of train, loss=2.553278684616089, training accuracy = 0.32418182492256165, testing accuracy = 0.3078118860721588\n",
      "epoch=11/400,0/20 of train, loss=2.541741371154785, training accuracy = 0.3320000171661377, testing accuracy = 0.303148090839386\n",
      "epoch=11/400,10/20 of train, loss=2.571422576904297, training accuracy = 0.3238182067871094, testing accuracy = 0.3074232339859009\n",
      "epoch=12/400,0/20 of train, loss=2.5715041160583496, training accuracy = 0.3020000159740448, testing accuracy = 0.3043140470981598\n",
      "epoch=12/400,10/20 of train, loss=2.5378434658050537, training accuracy = 0.3274545669555664, testing accuracy = 0.3074232339859009\n",
      "epoch=13/400,0/20 of train, loss=2.548987865447998, training accuracy = 0.32100000977516174, testing accuracy = 0.3066459596157074\n",
      "epoch=13/400,10/20 of train, loss=2.554274559020996, training accuracy = 0.32681822776794434, testing accuracy = 0.30509135127067566\n",
      "epoch=14/400,0/20 of train, loss=2.556643009185791, training accuracy = 0.31700000166893005, testing accuracy = 0.30586865544319153\n",
      "epoch=14/400,10/20 of train, loss=2.5392651557922363, training accuracy = 0.3279999792575836, testing accuracy = 0.3054800033569336\n",
      "epoch=15/400,0/20 of train, loss=2.538679599761963, training accuracy = 0.33500000834465027, testing accuracy = 0.30625730752944946\n",
      "epoch=15/400,10/20 of train, loss=2.5337610244750977, training accuracy = 0.3208182156085968, testing accuracy = 0.3085891902446747\n",
      "epoch=16/400,0/20 of train, loss=2.530709981918335, training accuracy = 0.34300002455711365, testing accuracy = 0.3074232339859009\n",
      "epoch=16/400,10/20 of train, loss=2.5252561569213867, training accuracy = 0.3280000388622284, testing accuracy = 0.30703458189964294\n",
      "epoch=17/400,0/20 of train, loss=2.5532796382904053, training accuracy = 0.32100000977516174, testing accuracy = 0.30586865544319153\n",
      "epoch=17/400,10/20 of train, loss=2.533125638961792, training accuracy = 0.3296363949775696, testing accuracy = 0.30392539501190186\n",
      "epoch=18/400,0/20 of train, loss=2.560340404510498, training accuracy = 0.3100000023841858, testing accuracy = 0.30703458189964294\n",
      "epoch=18/400,10/20 of train, loss=2.549593925476074, training accuracy = 0.3170909583568573, testing accuracy = 0.3047026991844177\n",
      "epoch=19/400,0/20 of train, loss=2.5211427211761475, training accuracy = 0.3530000150203705, testing accuracy = 0.30703458189964294\n",
      "epoch=19/400,10/20 of train, loss=2.5433156490325928, training accuracy = 0.32554545998573303, testing accuracy = 0.3043140470981598\n",
      "epoch=20/400,0/20 of train, loss=2.5690274238586426, training accuracy = 0.30400002002716064, testing accuracy = 0.30820053815841675\n",
      "epoch=20/400,10/20 of train, loss=2.570511817932129, training accuracy = 0.3250909149646759, testing accuracy = 0.3047026991844177\n",
      "epoch=21/400,0/20 of train, loss=2.5495617389678955, training accuracy = 0.3230000138282776, testing accuracy = 0.3035367429256439\n",
      "epoch=21/400,10/20 of train, loss=2.55000901222229, training accuracy = 0.3230000138282776, testing accuracy = 0.30703458189964294\n",
      "epoch=22/400,0/20 of train, loss=2.541774034500122, training accuracy = 0.33100003004074097, testing accuracy = 0.3074232339859009\n",
      "epoch=22/400,10/20 of train, loss=2.558518886566162, training accuracy = 0.3288182318210602, testing accuracy = 0.3097551465034485\n",
      "epoch=23/400,0/20 of train, loss=2.5534164905548096, training accuracy = 0.3190000057220459, testing accuracy = 0.30275943875312805\n",
      "epoch=23/400,10/20 of train, loss=2.5450897216796875, training accuracy = 0.3230000138282776, testing accuracy = 0.3101437985897064\n",
      "epoch=24/400,0/20 of train, loss=2.565945863723755, training accuracy = 0.3070000112056732, testing accuracy = 0.3047026991844177\n",
      "epoch=24/400,10/20 of train, loss=2.52329158782959, training accuracy = 0.32709091901779175, testing accuracy = 0.303148090839386\n",
      "epoch=25/400,0/20 of train, loss=2.544569253921509, training accuracy = 0.328000009059906, testing accuracy = 0.30586865544319153\n",
      "epoch=25/400,10/20 of train, loss=2.526456832885742, training accuracy = 0.3221818506717682, testing accuracy = 0.30703458189964294\n",
      "epoch=26/400,0/20 of train, loss=2.5243492126464844, training accuracy = 0.3500000238418579, testing accuracy = 0.3085891902446747\n",
      "epoch=26/400,10/20 of train, loss=2.523266315460205, training accuracy = 0.32836365699768066, testing accuracy = 0.30820053815841675\n",
      "epoch=27/400,0/20 of train, loss=2.5719735622406006, training accuracy = 0.30000001192092896, testing accuracy = 0.30703458189964294\n",
      "epoch=27/400,10/20 of train, loss=2.525869369506836, training accuracy = 0.3230000436306, testing accuracy = 0.3074232339859009\n",
      "epoch=28/400,0/20 of train, loss=2.5614287853240967, training accuracy = 0.3100000023841858, testing accuracy = 0.30586865544319153\n",
      "epoch=28/400,10/20 of train, loss=2.548617362976074, training accuracy = 0.32390910387039185, testing accuracy = 0.30703458189964294\n",
      "epoch=29/400,0/20 of train, loss=2.546936273574829, training accuracy = 0.32600000500679016, testing accuracy = 0.3066459596157074\n",
      "epoch=29/400,10/20 of train, loss=2.5500807762145996, training accuracy = 0.32736366987228394, testing accuracy = 0.3012048304080963\n",
      "epoch=30/400,0/20 of train, loss=2.548717737197876, training accuracy = 0.32500001788139343, testing accuracy = 0.30936649441719055\n",
      "epoch=30/400,10/20 of train, loss=2.548548460006714, training accuracy = 0.33109092712402344, testing accuracy = 0.30625730752944946\n",
      "epoch=31/400,0/20 of train, loss=2.538936138153076, training accuracy = 0.33500000834465027, testing accuracy = 0.30275943875312805\n",
      "epoch=31/400,10/20 of train, loss=2.554424524307251, training accuracy = 0.3255454897880554, testing accuracy = 0.3023707866668701\n",
      "epoch=32/400,0/20 of train, loss=2.5619864463806152, training accuracy = 0.3110000193119049, testing accuracy = 0.303148090839386\n",
      "epoch=32/400,10/20 of train, loss=2.543164014816284, training accuracy = 0.32809093594551086, testing accuracy = 0.303148090839386\n",
      "epoch=33/400,0/20 of train, loss=2.545297384262085, training accuracy = 0.328000009059906, testing accuracy = 0.3066459596157074\n",
      "epoch=33/400,10/20 of train, loss=2.5426480770111084, training accuracy = 0.3231818377971649, testing accuracy = 0.30509135127067566\n",
      "epoch=34/400,0/20 of train, loss=2.535518169403076, training accuracy = 0.3370000123977661, testing accuracy = 0.3074232339859009\n",
      "epoch=34/400,10/20 of train, loss=2.5462238788604736, training accuracy = 0.3272727429866791, testing accuracy = 0.3085891902446747\n",
      "epoch=35/400,0/20 of train, loss=2.5376150608062744, training accuracy = 0.33800002932548523, testing accuracy = 0.30703458189964294\n",
      "epoch=35/400,10/20 of train, loss=2.5315139293670654, training accuracy = 0.3240909278392792, testing accuracy = 0.3054800033569336\n",
      "epoch=36/400,0/20 of train, loss=2.548658847808838, training accuracy = 0.3270000219345093, testing accuracy = 0.3078118860721588\n",
      "epoch=36/400,10/20 of train, loss=2.5415079593658447, training accuracy = 0.3325454592704773, testing accuracy = 0.31053245067596436\n",
      "epoch=37/400,0/20 of train, loss=2.55222749710083, training accuracy = 0.32200002670288086, testing accuracy = 0.3085891902446747\n",
      "epoch=37/400,10/20 of train, loss=2.550140142440796, training accuracy = 0.32200002670288086, testing accuracy = 0.30936649441719055\n",
      "epoch=38/400,0/20 of train, loss=2.5470752716064453, training accuracy = 0.32600000500679016, testing accuracy = 0.3078118860721588\n",
      "epoch=38/400,10/20 of train, loss=2.5380289554595947, training accuracy = 0.3351818323135376, testing accuracy = 0.30820053815841675\n",
      "epoch=39/400,0/20 of train, loss=2.543267011642456, training accuracy = 0.3290000259876251, testing accuracy = 0.30936649441719055\n",
      "epoch=39/400,10/20 of train, loss=2.5190134048461914, training accuracy = 0.3301818370819092, testing accuracy = 0.30509135127067566\n",
      "epoch=40/400,0/20 of train, loss=2.5416622161865234, training accuracy = 0.3320000171661377, testing accuracy = 0.3066459596157074\n",
      "epoch=40/400,10/20 of train, loss=2.512705087661743, training accuracy = 0.33190909028053284, testing accuracy = 0.30509135127067566\n",
      "epoch=41/400,0/20 of train, loss=2.5394909381866455, training accuracy = 0.3320000171661377, testing accuracy = 0.3078118860721588\n",
      "epoch=41/400,10/20 of train, loss=2.5522961616516113, training accuracy = 0.33100003004074097, testing accuracy = 0.3054800033569336\n",
      "epoch=42/400,0/20 of train, loss=2.5289976596832275, training accuracy = 0.3450000286102295, testing accuracy = 0.3097551465034485\n",
      "epoch=42/400,10/20 of train, loss=2.570810079574585, training accuracy = 0.32736366987228394, testing accuracy = 0.3097551465034485\n",
      "epoch=43/400,0/20 of train, loss=2.555356979370117, training accuracy = 0.3190000057220459, testing accuracy = 0.3089778423309326\n",
      "epoch=43/400,10/20 of train, loss=2.539790391921997, training accuracy = 0.3255454897880554, testing accuracy = 0.30625730752944946\n",
      "epoch=44/400,0/20 of train, loss=2.5611870288848877, training accuracy = 0.3110000193119049, testing accuracy = 0.3101437985897064\n",
      "epoch=44/400,10/20 of train, loss=2.5173585414886475, training accuracy = 0.31827273964881897, testing accuracy = 0.3066459596157074\n",
      "epoch=45/400,0/20 of train, loss=2.5159971714019775, training accuracy = 0.3570000231266022, testing accuracy = 0.3054800033569336\n",
      "epoch=45/400,10/20 of train, loss=2.5400214195251465, training accuracy = 0.33318185806274414, testing accuracy = 0.3097551465034485\n",
      "epoch=46/400,0/20 of train, loss=2.5622379779815674, training accuracy = 0.30800002813339233, testing accuracy = 0.3043140470981598\n",
      "epoch=46/400,10/20 of train, loss=2.5323662757873535, training accuracy = 0.328000009059906, testing accuracy = 0.3078118860721588\n",
      "epoch=47/400,0/20 of train, loss=2.552196741104126, training accuracy = 0.320000022649765, testing accuracy = 0.3085891902446747\n",
      "epoch=47/400,10/20 of train, loss=2.5269410610198975, training accuracy = 0.32918182015419006, testing accuracy = 0.30392539501190186\n",
      "epoch=48/400,0/20 of train, loss=2.548988103866577, training accuracy = 0.3240000009536743, testing accuracy = 0.3066459596157074\n",
      "epoch=48/400,10/20 of train, loss=2.534250020980835, training accuracy = 0.3330909311771393, testing accuracy = 0.3019821345806122\n",
      "epoch=49/400,0/20 of train, loss=2.531187057495117, training accuracy = 0.34200000762939453, testing accuracy = 0.3097551465034485\n",
      "epoch=49/400,10/20 of train, loss=2.531505584716797, training accuracy = 0.33127278089523315, testing accuracy = 0.3074232339859009\n",
      "epoch=50/400,0/20 of train, loss=2.5490212440490723, training accuracy = 0.32500001788139343, testing accuracy = 0.3054800033569336\n",
      "epoch=50/400,10/20 of train, loss=2.5619494915008545, training accuracy = 0.3259091377258301, testing accuracy = 0.30509135127067566\n",
      "epoch=51/400,0/20 of train, loss=2.52885103225708, training accuracy = 0.3450000286102295, testing accuracy = 0.30392539501190186\n",
      "epoch=51/400,10/20 of train, loss=2.5563628673553467, training accuracy = 0.33027276396751404, testing accuracy = 0.3085891902446747\n",
      "epoch=52/400,0/20 of train, loss=2.55371356010437, training accuracy = 0.31700000166893005, testing accuracy = 0.3043140470981598\n",
      "epoch=52/400,10/20 of train, loss=2.5114450454711914, training accuracy = 0.32945457100868225, testing accuracy = 0.3097551465034485\n",
      "epoch=53/400,0/20 of train, loss=2.537726640701294, training accuracy = 0.33400002121925354, testing accuracy = 0.30625730752944946\n",
      "epoch=53/400,10/20 of train, loss=2.5754895210266113, training accuracy = 0.3317273259162903, testing accuracy = 0.30703458189964294\n",
      "epoch=54/400,0/20 of train, loss=2.547525644302368, training accuracy = 0.3290000259876251, testing accuracy = 0.3097551465034485\n",
      "epoch=54/400,10/20 of train, loss=2.5416958332061768, training accuracy = 0.3333636522293091, testing accuracy = 0.3047026991844177\n",
      "epoch=55/400,0/20 of train, loss=2.5340261459350586, training accuracy = 0.3400000035762787, testing accuracy = 0.30703458189964294\n",
      "epoch=55/400,10/20 of train, loss=2.5665156841278076, training accuracy = 0.3319091200828552, testing accuracy = 0.3097551465034485\n",
      "epoch=56/400,0/20 of train, loss=2.5431432723999023, training accuracy = 0.33100003004074097, testing accuracy = 0.3078118860721588\n",
      "epoch=56/400,10/20 of train, loss=2.5378055572509766, training accuracy = 0.33372730016708374, testing accuracy = 0.30703458189964294\n",
      "epoch=57/400,0/20 of train, loss=2.5339736938476562, training accuracy = 0.33900001645088196, testing accuracy = 0.3078118860721588\n",
      "epoch=57/400,10/20 of train, loss=2.540802478790283, training accuracy = 0.3330909311771393, testing accuracy = 0.3074232339859009\n",
      "epoch=58/400,0/20 of train, loss=2.5498733520507812, training accuracy = 0.3240000009536743, testing accuracy = 0.3078118860721588\n",
      "epoch=58/400,10/20 of train, loss=2.517401933670044, training accuracy = 0.3306364119052887, testing accuracy = 0.3054800033569336\n",
      "epoch=59/400,0/20 of train, loss=2.5497705936431885, training accuracy = 0.3240000009536743, testing accuracy = 0.3085891902446747\n",
      "epoch=59/400,10/20 of train, loss=2.5286943912506104, training accuracy = 0.3383636474609375, testing accuracy = 0.30703458189964294\n",
      "epoch=60/400,0/20 of train, loss=2.5409812927246094, training accuracy = 0.3320000171661377, testing accuracy = 0.3109211027622223\n",
      "epoch=60/400,10/20 of train, loss=2.5472657680511475, training accuracy = 0.3360000550746918, testing accuracy = 0.30936649441719055\n",
      "epoch=61/400,0/20 of train, loss=2.521028518676758, training accuracy = 0.3530000150203705, testing accuracy = 0.30703458189964294\n",
      "epoch=61/400,10/20 of train, loss=2.5290334224700928, training accuracy = 0.33609092235565186, testing accuracy = 0.30625730752944946\n",
      "epoch=62/400,0/20 of train, loss=2.5524933338165283, training accuracy = 0.31700000166893005, testing accuracy = 0.30936649441719055\n",
      "epoch=62/400,10/20 of train, loss=2.535691499710083, training accuracy = 0.3327272832393646, testing accuracy = 0.3074232339859009\n",
      "epoch=63/400,0/20 of train, loss=2.5518972873687744, training accuracy = 0.3230000138282776, testing accuracy = 0.31169840693473816\n",
      "epoch=63/400,10/20 of train, loss=2.525186538696289, training accuracy = 0.3369999825954437, testing accuracy = 0.30625730752944946\n",
      "epoch=64/400,0/20 of train, loss=2.523181200027466, training accuracy = 0.35100001096725464, testing accuracy = 0.3089778423309326\n",
      "epoch=64/400,10/20 of train, loss=2.53947377204895, training accuracy = 0.332727313041687, testing accuracy = 0.3074232339859009\n",
      "epoch=65/400,0/20 of train, loss=2.5187759399414062, training accuracy = 0.35500001907348633, testing accuracy = 0.3089778423309326\n",
      "epoch=65/400,10/20 of train, loss=2.540182590484619, training accuracy = 0.33909091353416443, testing accuracy = 0.3074232339859009\n",
      "epoch=66/400,0/20 of train, loss=2.529761552810669, training accuracy = 0.3410000205039978, testing accuracy = 0.30703458189964294\n",
      "epoch=66/400,10/20 of train, loss=2.532771348953247, training accuracy = 0.34054550528526306, testing accuracy = 0.3074232339859009\n",
      "epoch=67/400,0/20 of train, loss=2.527118682861328, training accuracy = 0.34800001978874207, testing accuracy = 0.30586865544319153\n",
      "epoch=67/400,10/20 of train, loss=2.5189828872680664, training accuracy = 0.3357273042201996, testing accuracy = 0.3066459596157074\n",
      "epoch=68/400,0/20 of train, loss=2.5473880767822266, training accuracy = 0.3230000138282776, testing accuracy = 0.3074232339859009\n",
      "epoch=68/400,10/20 of train, loss=2.53210711479187, training accuracy = 0.33472728729248047, testing accuracy = 0.3066459596157074\n",
      "epoch=69/400,0/20 of train, loss=2.522944688796997, training accuracy = 0.35100001096725464, testing accuracy = 0.3054800033569336\n",
      "epoch=69/400,10/20 of train, loss=2.553386688232422, training accuracy = 0.33127275109291077, testing accuracy = 0.3078118860721588\n",
      "epoch=70/400,0/20 of train, loss=2.5474162101745605, training accuracy = 0.3270000219345093, testing accuracy = 0.30509135127067566\n",
      "epoch=70/400,10/20 of train, loss=2.5319950580596924, training accuracy = 0.3293636739253998, testing accuracy = 0.3078118860721588\n",
      "epoch=71/400,0/20 of train, loss=2.5276803970336914, training accuracy = 0.3440000116825104, testing accuracy = 0.3074232339859009\n",
      "epoch=71/400,10/20 of train, loss=2.548414707183838, training accuracy = 0.34109094738960266, testing accuracy = 0.3101437985897064\n",
      "epoch=72/400,0/20 of train, loss=2.542693853378296, training accuracy = 0.33000001311302185, testing accuracy = 0.31053245067596436\n",
      "epoch=72/400,10/20 of train, loss=2.520131826400757, training accuracy = 0.3361818194389343, testing accuracy = 0.3089778423309326\n",
      "epoch=73/400,0/20 of train, loss=2.544052839279175, training accuracy = 0.33100003004074097, testing accuracy = 0.30586865544319153\n",
      "epoch=73/400,10/20 of train, loss=2.522674322128296, training accuracy = 0.3313636779785156, testing accuracy = 0.303148090839386\n",
      "epoch=74/400,0/20 of train, loss=2.541807174682617, training accuracy = 0.3330000042915344, testing accuracy = 0.30703458189964294\n",
      "epoch=74/400,10/20 of train, loss=2.5334737300872803, training accuracy = 0.3400000333786011, testing accuracy = 0.3074232339859009\n",
      "epoch=75/400,0/20 of train, loss=2.5394606590270996, training accuracy = 0.33500000834465027, testing accuracy = 0.303148090839386\n",
      "epoch=75/400,10/20 of train, loss=2.5230414867401123, training accuracy = 0.3328181803226471, testing accuracy = 0.3074232339859009\n",
      "epoch=76/400,0/20 of train, loss=2.5497779846191406, training accuracy = 0.3240000009536743, testing accuracy = 0.3097551465034485\n",
      "epoch=76/400,10/20 of train, loss=2.5563366413116455, training accuracy = 0.3353636562824249, testing accuracy = 0.3074232339859009\n",
      "epoch=77/400,0/20 of train, loss=2.5416553020477295, training accuracy = 0.3320000171661377, testing accuracy = 0.3078118860721588\n",
      "epoch=77/400,10/20 of train, loss=2.5559000968933105, training accuracy = 0.3270000219345093, testing accuracy = 0.30625730752944946\n",
      "epoch=78/400,0/20 of train, loss=2.5294785499572754, training accuracy = 0.3440000116825104, testing accuracy = 0.3047026991844177\n",
      "epoch=78/400,10/20 of train, loss=2.53903865814209, training accuracy = 0.3340909481048584, testing accuracy = 0.3089778423309326\n",
      "epoch=79/400,0/20 of train, loss=2.517849922180176, training accuracy = 0.3570000231266022, testing accuracy = 0.3074232339859009\n",
      "epoch=79/400,10/20 of train, loss=2.5388922691345215, training accuracy = 0.34090912342071533, testing accuracy = 0.30703458189964294\n",
      "epoch=80/400,0/20 of train, loss=2.548496723175049, training accuracy = 0.32200002670288086, testing accuracy = 0.31053245067596436\n",
      "epoch=80/400,10/20 of train, loss=2.5516412258148193, training accuracy = 0.3306363821029663, testing accuracy = 0.30586865544319153\n",
      "epoch=81/400,0/20 of train, loss=2.5238795280456543, training accuracy = 0.3500000238418579, testing accuracy = 0.3066459596157074\n",
      "epoch=81/400,10/20 of train, loss=2.5415332317352295, training accuracy = 0.3354545831680298, testing accuracy = 0.3089778423309326\n",
      "epoch=82/400,0/20 of train, loss=2.522662878036499, training accuracy = 0.34800001978874207, testing accuracy = 0.3078118860721588\n",
      "epoch=82/400,10/20 of train, loss=2.5153071880340576, training accuracy = 0.340181827545166, testing accuracy = 0.3085891902446747\n",
      "epoch=83/400,0/20 of train, loss=2.5405821800231934, training accuracy = 0.3320000171661377, testing accuracy = 0.30703458189964294\n",
      "epoch=83/400,10/20 of train, loss=2.5436220169067383, training accuracy = 0.3439091444015503, testing accuracy = 0.3089778423309326\n",
      "epoch=84/400,0/20 of train, loss=2.507815361022949, training accuracy = 0.3680000305175781, testing accuracy = 0.3074232339859009\n",
      "epoch=84/400,10/20 of train, loss=2.555079221725464, training accuracy = 0.33799999952316284, testing accuracy = 0.3097551465034485\n",
      "epoch=85/400,0/20 of train, loss=2.539712429046631, training accuracy = 0.3320000171661377, testing accuracy = 0.3085891902446747\n",
      "epoch=85/400,10/20 of train, loss=2.525095224380493, training accuracy = 0.33472728729248047, testing accuracy = 0.3066459596157074\n",
      "epoch=86/400,0/20 of train, loss=2.5175530910491943, training accuracy = 0.35600000619888306, testing accuracy = 0.31053245067596436\n",
      "epoch=86/400,10/20 of train, loss=2.529538631439209, training accuracy = 0.34481820464134216, testing accuracy = 0.30936649441719055\n",
      "epoch=87/400,0/20 of train, loss=2.5259015560150146, training accuracy = 0.34800001978874207, testing accuracy = 0.3047026991844177\n",
      "epoch=87/400,10/20 of train, loss=2.5494205951690674, training accuracy = 0.34754544496536255, testing accuracy = 0.30936649441719055\n",
      "epoch=88/400,0/20 of train, loss=2.514293670654297, training accuracy = 0.359000027179718, testing accuracy = 0.3078118860721588\n",
      "epoch=88/400,10/20 of train, loss=2.5355894565582275, training accuracy = 0.33636367321014404, testing accuracy = 0.30586865544319153\n",
      "epoch=89/400,0/20 of train, loss=2.520359516143799, training accuracy = 0.35200002789497375, testing accuracy = 0.3089778423309326\n",
      "epoch=89/400,10/20 of train, loss=2.5203421115875244, training accuracy = 0.3372727632522583, testing accuracy = 0.3078118860721588\n",
      "epoch=90/400,0/20 of train, loss=2.527665615081787, training accuracy = 0.3450000286102295, testing accuracy = 0.3101437985897064\n",
      "epoch=90/400,10/20 of train, loss=2.545018434524536, training accuracy = 0.3380909264087677, testing accuracy = 0.30820053815841675\n",
      "epoch=91/400,0/20 of train, loss=2.5455665588378906, training accuracy = 0.3290000259876251, testing accuracy = 0.3085891902446747\n",
      "epoch=91/400,10/20 of train, loss=2.5402541160583496, training accuracy = 0.3370000422000885, testing accuracy = 0.3074232339859009\n",
      "epoch=92/400,0/20 of train, loss=2.5185606479644775, training accuracy = 0.35500001907348633, testing accuracy = 0.3089778423309326\n",
      "epoch=92/400,10/20 of train, loss=2.541815996170044, training accuracy = 0.3386363983154297, testing accuracy = 0.3054800033569336\n",
      "epoch=93/400,0/20 of train, loss=2.542479991912842, training accuracy = 0.3320000171661377, testing accuracy = 0.3066459596157074\n",
      "epoch=93/400,10/20 of train, loss=2.5522289276123047, training accuracy = 0.3447272777557373, testing accuracy = 0.3097551465034485\n",
      "epoch=94/400,0/20 of train, loss=2.5534956455230713, training accuracy = 0.32200002670288086, testing accuracy = 0.3101437985897064\n",
      "epoch=94/400,10/20 of train, loss=2.560145139694214, training accuracy = 0.3343636393547058, testing accuracy = 0.3113097548484802\n",
      "epoch=95/400,0/20 of train, loss=2.5234720706939697, training accuracy = 0.35100001096725464, testing accuracy = 0.3078118860721588\n",
      "epoch=95/400,10/20 of train, loss=2.501809597015381, training accuracy = 0.34136366844177246, testing accuracy = 0.30820053815841675\n",
      "epoch=96/400,0/20 of train, loss=2.5159103870391846, training accuracy = 0.3570000231266022, testing accuracy = 0.3078118860721588\n",
      "epoch=96/400,10/20 of train, loss=2.5268330574035645, training accuracy = 0.3433636724948883, testing accuracy = 0.30820053815841675\n",
      "epoch=97/400,0/20 of train, loss=2.5567173957824707, training accuracy = 0.31700000166893005, testing accuracy = 0.30936649441719055\n",
      "epoch=97/400,10/20 of train, loss=2.5102145671844482, training accuracy = 0.33945462107658386, testing accuracy = 0.3089778423309326\n",
      "epoch=98/400,0/20 of train, loss=2.535982131958008, training accuracy = 0.3400000035762787, testing accuracy = 0.30936649441719055\n",
      "epoch=98/400,10/20 of train, loss=2.5256035327911377, training accuracy = 0.3430909216403961, testing accuracy = 0.3109211027622223\n",
      "epoch=99/400,0/20 of train, loss=2.518204689025879, training accuracy = 0.35500001907348633, testing accuracy = 0.30820053815841675\n",
      "epoch=99/400,10/20 of train, loss=2.525338649749756, training accuracy = 0.34036365151405334, testing accuracy = 0.3085891902446747\n",
      "epoch=100/400,0/20 of train, loss=2.519808769226074, training accuracy = 0.35200002789497375, testing accuracy = 0.3078118860721588\n",
      "epoch=100/400,10/20 of train, loss=2.55330491065979, training accuracy = 0.33763638138771057, testing accuracy = 0.31169840693473816\n",
      "epoch=101/400,0/20 of train, loss=2.5353243350982666, training accuracy = 0.33800002932548523, testing accuracy = 0.30703458189964294\n",
      "epoch=101/400,10/20 of train, loss=2.515977621078491, training accuracy = 0.34427276253700256, testing accuracy = 0.30625730752944946\n",
      "epoch=102/400,0/20 of train, loss=2.4992330074310303, training accuracy = 0.37300002574920654, testing accuracy = 0.3047026991844177\n",
      "epoch=102/400,10/20 of train, loss=2.5083706378936768, training accuracy = 0.3413636386394501, testing accuracy = 0.30936649441719055\n",
      "epoch=103/400,0/20 of train, loss=2.5173418521881104, training accuracy = 0.3580000102519989, testing accuracy = 0.3089778423309326\n",
      "epoch=103/400,10/20 of train, loss=2.5204527378082275, training accuracy = 0.33818182349205017, testing accuracy = 0.3089778423309326\n",
      "epoch=104/400,0/20 of train, loss=2.546262741088867, training accuracy = 0.328000009059906, testing accuracy = 0.3047026991844177\n",
      "epoch=104/400,10/20 of train, loss=2.5313174724578857, training accuracy = 0.3408181965351105, testing accuracy = 0.3097551465034485\n",
      "epoch=105/400,0/20 of train, loss=2.547203540802002, training accuracy = 0.32600000500679016, testing accuracy = 0.30936649441719055\n",
      "epoch=105/400,10/20 of train, loss=2.536515951156616, training accuracy = 0.3389091193675995, testing accuracy = 0.3089778423309326\n",
      "epoch=106/400,0/20 of train, loss=2.5382633209228516, training accuracy = 0.3370000123977661, testing accuracy = 0.3066459596157074\n",
      "epoch=106/400,10/20 of train, loss=2.5373289585113525, training accuracy = 0.33681821823120117, testing accuracy = 0.3085891902446747\n",
      "epoch=107/400,0/20 of train, loss=2.550199508666992, training accuracy = 0.320000022649765, testing accuracy = 0.3074232339859009\n",
      "epoch=107/400,10/20 of train, loss=2.524383068084717, training accuracy = 0.34490910172462463, testing accuracy = 0.3085891902446747\n",
      "epoch=108/400,0/20 of train, loss=2.5419704914093018, training accuracy = 0.3330000042915344, testing accuracy = 0.3074232339859009\n",
      "epoch=108/400,10/20 of train, loss=2.525398015975952, training accuracy = 0.3412727415561676, testing accuracy = 0.3085891902446747\n",
      "epoch=109/400,0/20 of train, loss=2.5347280502319336, training accuracy = 0.3400000035762787, testing accuracy = 0.3097551465034485\n",
      "epoch=109/400,10/20 of train, loss=2.5338854789733887, training accuracy = 0.33481818437576294, testing accuracy = 0.31053245067596436\n",
      "epoch=110/400,0/20 of train, loss=2.5113301277160645, training accuracy = 0.3630000054836273, testing accuracy = 0.3078118860721588\n",
      "epoch=110/400,10/20 of train, loss=2.509657859802246, training accuracy = 0.3478182256221771, testing accuracy = 0.30509135127067566\n",
      "epoch=111/400,0/20 of train, loss=2.486577272415161, training accuracy = 0.38700002431869507, testing accuracy = 0.3078118860721588\n",
      "epoch=111/400,10/20 of train, loss=2.5353987216949463, training accuracy = 0.34063637256622314, testing accuracy = 0.30392539501190186\n",
      "epoch=112/400,0/20 of train, loss=2.5064914226531982, training accuracy = 0.36900001764297485, testing accuracy = 0.3097551465034485\n",
      "epoch=112/400,10/20 of train, loss=2.5359559059143066, training accuracy = 0.3433636724948883, testing accuracy = 0.3019821345806122\n",
      "epoch=113/400,0/20 of train, loss=2.525747776031494, training accuracy = 0.3490000069141388, testing accuracy = 0.3066459596157074\n",
      "epoch=113/400,10/20 of train, loss=2.5237746238708496, training accuracy = 0.34063640236854553, testing accuracy = 0.3113097548484802\n",
      "epoch=114/400,0/20 of train, loss=2.5463333129882812, training accuracy = 0.328000009059906, testing accuracy = 0.30703458189964294\n",
      "epoch=114/400,10/20 of train, loss=2.5190958976745605, training accuracy = 0.33845457434654236, testing accuracy = 0.30820053815841675\n",
      "epoch=115/400,0/20 of train, loss=2.5527536869049072, training accuracy = 0.32200002670288086, testing accuracy = 0.3035367429256439\n",
      "epoch=115/400,10/20 of train, loss=2.52240252494812, training accuracy = 0.3425455093383789, testing accuracy = 0.3054800033569336\n",
      "epoch=116/400,0/20 of train, loss=2.553712844848633, training accuracy = 0.320000022649765, testing accuracy = 0.3078118860721588\n",
      "epoch=116/400,10/20 of train, loss=2.519655227661133, training accuracy = 0.3364545702934265, testing accuracy = 0.30509135127067566\n",
      "epoch=117/400,0/20 of train, loss=2.5363516807556152, training accuracy = 0.33900001645088196, testing accuracy = 0.30820053815841675\n",
      "epoch=117/400,10/20 of train, loss=2.536400556564331, training accuracy = 0.3391818404197693, testing accuracy = 0.30509135127067566\n",
      "epoch=118/400,0/20 of train, loss=2.525865316390991, training accuracy = 0.3440000116825104, testing accuracy = 0.3097551465034485\n",
      "epoch=118/400,10/20 of train, loss=2.529726505279541, training accuracy = 0.34063640236854553, testing accuracy = 0.30936649441719055\n",
      "epoch=119/400,0/20 of train, loss=2.542172908782959, training accuracy = 0.33100003004074097, testing accuracy = 0.3089778423309326\n",
      "epoch=119/400,10/20 of train, loss=2.5207066535949707, training accuracy = 0.34200000762939453, testing accuracy = 0.30392539501190186\n",
      "epoch=120/400,0/20 of train, loss=2.5552730560302734, training accuracy = 0.31800001859664917, testing accuracy = 0.3066459596157074\n",
      "epoch=120/400,10/20 of train, loss=2.5532946586608887, training accuracy = 0.3419090807437897, testing accuracy = 0.3054800033569336\n",
      "epoch=121/400,0/20 of train, loss=2.5169517993927, training accuracy = 0.35600000619888306, testing accuracy = 0.3089778423309326\n",
      "epoch=121/400,10/20 of train, loss=2.5390186309814453, training accuracy = 0.3447273373603821, testing accuracy = 0.30703458189964294\n",
      "epoch=122/400,0/20 of train, loss=2.5225985050201416, training accuracy = 0.35200002789497375, testing accuracy = 0.30392539501190186\n",
      "epoch=122/400,10/20 of train, loss=2.5160679817199707, training accuracy = 0.34454548358917236, testing accuracy = 0.30703458189964294\n",
      "epoch=123/400,0/20 of train, loss=2.5055508613586426, training accuracy = 0.3680000305175781, testing accuracy = 0.3078118860721588\n",
      "epoch=123/400,10/20 of train, loss=2.5528488159179688, training accuracy = 0.3457272946834564, testing accuracy = 0.30703458189964294\n",
      "epoch=124/400,0/20 of train, loss=2.5491678714752197, training accuracy = 0.3240000009536743, testing accuracy = 0.3054800033569336\n",
      "epoch=124/400,10/20 of train, loss=2.523083209991455, training accuracy = 0.3422727584838867, testing accuracy = 0.3089778423309326\n",
      "epoch=125/400,0/20 of train, loss=2.5564913749694824, training accuracy = 0.3160000145435333, testing accuracy = 0.30703458189964294\n",
      "epoch=125/400,10/20 of train, loss=2.521653890609741, training accuracy = 0.3410000205039978, testing accuracy = 0.3047026991844177\n",
      "epoch=126/400,0/20 of train, loss=2.5257527828216553, training accuracy = 0.34800001978874207, testing accuracy = 0.3074232339859009\n",
      "epoch=126/400,10/20 of train, loss=2.5228726863861084, training accuracy = 0.34409093856811523, testing accuracy = 0.3054800033569336\n",
      "epoch=127/400,0/20 of train, loss=2.5126442909240723, training accuracy = 0.3630000054836273, testing accuracy = 0.3089778423309326\n",
      "epoch=127/400,10/20 of train, loss=2.5409507751464844, training accuracy = 0.3422727584838867, testing accuracy = 0.30820053815841675\n",
      "epoch=128/400,0/20 of train, loss=2.520537853240967, training accuracy = 0.35500001907348633, testing accuracy = 0.3043140470981598\n",
      "epoch=128/400,10/20 of train, loss=2.51716947555542, training accuracy = 0.3411818742752075, testing accuracy = 0.3074232339859009\n",
      "epoch=129/400,0/20 of train, loss=2.525313138961792, training accuracy = 0.34800001978874207, testing accuracy = 0.3101437985897064\n",
      "epoch=129/400,10/20 of train, loss=2.5124199390411377, training accuracy = 0.35018184781074524, testing accuracy = 0.30586865544319153\n",
      "epoch=130/400,0/20 of train, loss=2.52602481842041, training accuracy = 0.34800001978874207, testing accuracy = 0.30586865544319153\n",
      "epoch=130/400,10/20 of train, loss=2.537498950958252, training accuracy = 0.3484545648097992, testing accuracy = 0.3054800033569336\n",
      "epoch=131/400,0/20 of train, loss=2.513408899307251, training accuracy = 0.3630000054836273, testing accuracy = 0.3074232339859009\n",
      "epoch=131/400,10/20 of train, loss=2.51680326461792, training accuracy = 0.34354543685913086, testing accuracy = 0.3054800033569336\n",
      "epoch=132/400,0/20 of train, loss=2.5443103313446045, training accuracy = 0.33000001311302185, testing accuracy = 0.30509135127067566\n",
      "epoch=132/400,10/20 of train, loss=2.5514678955078125, training accuracy = 0.3463636636734009, testing accuracy = 0.3035367429256439\n",
      "epoch=133/400,0/20 of train, loss=2.522128105163574, training accuracy = 0.35100001096725464, testing accuracy = 0.3066459596157074\n",
      "epoch=133/400,10/20 of train, loss=2.5482592582702637, training accuracy = 0.34409093856811523, testing accuracy = 0.30586865544319153\n",
      "epoch=134/400,0/20 of train, loss=2.3780510425567627, training accuracy = 0.49900001287460327, testing accuracy = 0.46910223364830017\n",
      "epoch=134/400,10/20 of train, loss=2.3991899490356445, training accuracy = 0.4773636758327484, testing accuracy = 0.45549944043159485\n",
      "epoch=135/400,0/20 of train, loss=2.408808946609497, training accuracy = 0.4660000205039978, testing accuracy = 0.4772638976573944\n",
      "epoch=135/400,10/20 of train, loss=2.369877576828003, training accuracy = 0.4824545681476593, testing accuracy = 0.4718227982521057\n",
      "epoch=136/400,0/20 of train, loss=2.388561964035034, training accuracy = 0.48600003123283386, testing accuracy = 0.479595810174942\n",
      "epoch=136/400,10/20 of train, loss=2.393527030944824, training accuracy = 0.4868181645870209, testing accuracy = 0.48231637477874756\n",
      "epoch=137/400,0/20 of train, loss=2.3858091831207275, training accuracy = 0.48600003123283386, testing accuracy = 0.4726001024246216\n",
      "epoch=137/400,10/20 of train, loss=2.369889497756958, training accuracy = 0.49527278542518616, testing accuracy = 0.4760979413986206\n",
      "epoch=138/400,0/20 of train, loss=2.3822133541107178, training accuracy = 0.4930000305175781, testing accuracy = 0.473766028881073\n",
      "epoch=138/400,10/20 of train, loss=2.359227180480957, training accuracy = 0.49927279353141785, testing accuracy = 0.479595810174942\n",
      "epoch=139/400,0/20 of train, loss=2.380030393600464, training accuracy = 0.492000013589859, testing accuracy = 0.47881850600242615\n",
      "epoch=139/400,10/20 of train, loss=2.365680694580078, training accuracy = 0.5070000886917114, testing accuracy = 0.4768752455711365\n",
      "epoch=140/400,0/20 of train, loss=2.364941358566284, training accuracy = 0.5100000500679016, testing accuracy = 0.48348233103752136\n",
      "epoch=140/400,10/20 of train, loss=2.3811540603637695, training accuracy = 0.518818199634552, testing accuracy = 0.4815390706062317\n",
      "epoch=141/400,0/20 of train, loss=2.3477940559387207, training accuracy = 0.5270000100135803, testing accuracy = 0.4897007346153259\n",
      "epoch=141/400,10/20 of train, loss=2.353604316711426, training accuracy = 0.5183636546134949, testing accuracy = 0.4897007346153259\n",
      "epoch=142/400,0/20 of train, loss=2.3678512573242188, training accuracy = 0.5060000419616699, testing accuracy = 0.4881461560726166\n",
      "epoch=142/400,10/20 of train, loss=2.361262321472168, training accuracy = 0.5300000309944153, testing accuracy = 0.47765254974365234\n",
      "epoch=143/400,0/20 of train, loss=2.3460254669189453, training accuracy = 0.527999997138977, testing accuracy = 0.4838709831237793\n",
      "epoch=143/400,10/20 of train, loss=2.3411548137664795, training accuracy = 0.5236364006996155, testing accuracy = 0.48775750398635864\n",
      "epoch=144/400,0/20 of train, loss=2.355614423751831, training accuracy = 0.5190000534057617, testing accuracy = 0.49125534296035767\n",
      "epoch=144/400,10/20 of train, loss=2.3352348804473877, training accuracy = 0.5293636322021484, testing accuracy = 0.4772638976573944\n",
      "epoch=145/400,0/20 of train, loss=2.335205078125, training accuracy = 0.5380000472068787, testing accuracy = 0.4862028956413269\n",
      "epoch=145/400,10/20 of train, loss=2.323178768157959, training accuracy = 0.5290000438690186, testing accuracy = 0.4904780387878418\n",
      "epoch=146/400,0/20 of train, loss=2.3315539360046387, training accuracy = 0.5440000295639038, testing accuracy = 0.4904780387878418\n",
      "epoch=146/400,10/20 of train, loss=2.347975492477417, training accuracy = 0.5350000262260437, testing accuracy = 0.4881461560726166\n",
      "epoch=147/400,0/20 of train, loss=2.33325457572937, training accuracy = 0.5440000295639038, testing accuracy = 0.4780412018299103\n",
      "epoch=147/400,10/20 of train, loss=2.3415534496307373, training accuracy = 0.5378182530403137, testing accuracy = 0.4768752455711365\n",
      "epoch=148/400,0/20 of train, loss=2.316502094268799, training accuracy = 0.5580000281333923, testing accuracy = 0.48892346024513245\n",
      "epoch=148/400,10/20 of train, loss=2.3335695266723633, training accuracy = 0.5388181805610657, testing accuracy = 0.48892346024513245\n",
      "epoch=149/400,0/20 of train, loss=2.337533950805664, training accuracy = 0.5350000262260437, testing accuracy = 0.4830936789512634\n",
      "epoch=149/400,10/20 of train, loss=2.3257689476013184, training accuracy = 0.5348182320594788, testing accuracy = 0.4904780387878418\n",
      "epoch=150/400,0/20 of train, loss=2.36588978767395, training accuracy = 0.5049999952316284, testing accuracy = 0.4897007346153259\n",
      "epoch=150/400,10/20 of train, loss=2.3266756534576416, training accuracy = 0.5361818671226501, testing accuracy = 0.489312082529068\n",
      "epoch=151/400,0/20 of train, loss=2.349592924118042, training accuracy = 0.5260000228881836, testing accuracy = 0.4873688519001007\n",
      "epoch=151/400,10/20 of train, loss=2.33693790435791, training accuracy = 0.5323636531829834, testing accuracy = 0.4947532117366791\n",
      "epoch=152/400,0/20 of train, loss=2.309084892272949, training accuracy = 0.5680000185966492, testing accuracy = 0.49086669087409973\n",
      "epoch=152/400,10/20 of train, loss=2.327686071395874, training accuracy = 0.5481818914413452, testing accuracy = 0.49008938670158386\n",
      "epoch=153/400,0/20 of train, loss=2.338550329208374, training accuracy = 0.5350000262260437, testing accuracy = 0.49086669087409973\n",
      "epoch=153/400,10/20 of train, loss=2.336540460586548, training accuracy = 0.5427272915840149, testing accuracy = 0.49008938670158386\n",
      "epoch=154/400,0/20 of train, loss=2.3272271156311035, training accuracy = 0.5490000247955322, testing accuracy = 0.4904780387878418\n",
      "epoch=154/400,10/20 of train, loss=2.3622100353240967, training accuracy = 0.532090961933136, testing accuracy = 0.49242129921913147\n",
      "epoch=155/400,0/20 of train, loss=2.3493151664733887, training accuracy = 0.5230000019073486, testing accuracy = 0.48659154772758484\n",
      "epoch=155/400,10/20 of train, loss=2.328190565109253, training accuracy = 0.5487273335456848, testing accuracy = 0.4916439950466156\n",
      "epoch=156/400,0/20 of train, loss=2.3435866832733154, training accuracy = 0.5330000519752502, testing accuracy = 0.49242129921913147\n",
      "epoch=156/400,10/20 of train, loss=2.343622922897339, training accuracy = 0.5465455055236816, testing accuracy = 0.4947532117366791\n",
      "epoch=157/400,0/20 of train, loss=2.3340039253234863, training accuracy = 0.5430000424385071, testing accuracy = 0.48542559146881104\n",
      "epoch=157/400,10/20 of train, loss=2.324702262878418, training accuracy = 0.5400000810623169, testing accuracy = 0.4916439950466156\n",
      "epoch=158/400,0/20 of train, loss=2.3070998191833496, training accuracy = 0.5660000443458557, testing accuracy = 0.4862028956413269\n",
      "epoch=158/400,10/20 of train, loss=2.3214452266693115, training accuracy = 0.5493636727333069, testing accuracy = 0.4935872554779053\n",
      "epoch=159/400,0/20 of train, loss=2.354203224182129, training accuracy = 0.5230000019073486, testing accuracy = 0.48892346024513245\n",
      "epoch=159/400,10/20 of train, loss=2.32843279838562, training accuracy = 0.5421817898750305, testing accuracy = 0.49008938670158386\n",
      "epoch=160/400,0/20 of train, loss=2.324723720550537, training accuracy = 0.5470000505447388, testing accuracy = 0.49086669087409973\n",
      "epoch=160/400,10/20 of train, loss=2.336543321609497, training accuracy = 0.5419090986251831, testing accuracy = 0.4970851242542267\n",
      "epoch=161/400,0/20 of train, loss=2.3356499671936035, training accuracy = 0.5400000214576721, testing accuracy = 0.4970851242542267\n",
      "epoch=161/400,10/20 of train, loss=2.36702036857605, training accuracy = 0.5436364412307739, testing accuracy = 0.4974737763404846\n",
      "epoch=162/400,0/20 of train, loss=2.3386471271514893, training accuracy = 0.5400000214576721, testing accuracy = 0.4947532117366791\n",
      "epoch=162/400,10/20 of train, loss=2.3158717155456543, training accuracy = 0.5516363382339478, testing accuracy = 0.489312082529068\n",
      "epoch=163/400,0/20 of train, loss=2.315352201461792, training accuracy = 0.5590000152587891, testing accuracy = 0.49553051590919495\n",
      "epoch=163/400,10/20 of train, loss=2.3311142921447754, training accuracy = 0.5460909008979797, testing accuracy = 0.49786242842674255\n",
      "epoch=164/400,0/20 of train, loss=2.3395705223083496, training accuracy = 0.5360000133514404, testing accuracy = 0.4897007346153259\n",
      "epoch=164/400,10/20 of train, loss=2.3208110332489014, training accuracy = 0.5537272691726685, testing accuracy = 0.4947532117366791\n",
      "epoch=165/400,0/20 of train, loss=2.31547474861145, training accuracy = 0.5600000023841858, testing accuracy = 0.49902838468551636\n",
      "epoch=165/400,10/20 of train, loss=2.3226914405822754, training accuracy = 0.55472731590271, testing accuracy = 0.489312082529068\n",
      "epoch=166/400,0/20 of train, loss=2.3140413761138916, training accuracy = 0.562000036239624, testing accuracy = 0.49125534296035767\n",
      "epoch=166/400,10/20 of train, loss=2.328885793685913, training accuracy = 0.5515455007553101, testing accuracy = 0.4885348081588745\n",
      "epoch=167/400,0/20 of train, loss=2.3389549255371094, training accuracy = 0.534000039100647, testing accuracy = 0.49242129921913147\n",
      "epoch=167/400,10/20 of train, loss=2.3486461639404297, training accuracy = 0.5514546036720276, testing accuracy = 0.48542559146881104\n",
      "epoch=168/400,0/20 of train, loss=2.3400485515594482, training accuracy = 0.5370000004768372, testing accuracy = 0.49319860339164734\n",
      "epoch=168/400,10/20 of train, loss=2.325913667678833, training accuracy = 0.5521818399429321, testing accuracy = 0.49203264713287354\n",
      "epoch=169/400,0/20 of train, loss=2.3070366382598877, training accuracy = 0.5660000443458557, testing accuracy = 0.4970851242542267\n",
      "epoch=169/400,10/20 of train, loss=2.3279385566711426, training accuracy = 0.5582728385925293, testing accuracy = 0.4959191679954529\n",
      "epoch=170/400,0/20 of train, loss=2.3411295413970947, training accuracy = 0.534000039100647, testing accuracy = 0.489312082529068\n",
      "epoch=170/400,10/20 of train, loss=2.3289568424224854, training accuracy = 0.5496364235877991, testing accuracy = 0.48581424355506897\n",
      "epoch=171/400,0/20 of train, loss=2.314927816390991, training accuracy = 0.5610000491142273, testing accuracy = 0.48659154772758484\n",
      "epoch=171/400,10/20 of train, loss=2.3478145599365234, training accuracy = 0.5503636598587036, testing accuracy = 0.49786242842674255\n",
      "epoch=172/400,0/20 of train, loss=2.3075475692749023, training accuracy = 0.5720000267028809, testing accuracy = 0.49242129921913147\n",
      "epoch=172/400,10/20 of train, loss=2.338242292404175, training accuracy = 0.5566364526748657, testing accuracy = 0.49436455965042114\n",
      "epoch=173/400,0/20 of train, loss=2.329169988632202, training accuracy = 0.5530000329017639, testing accuracy = 0.49125534296035767\n",
      "epoch=173/400,10/20 of train, loss=2.306579113006592, training accuracy = 0.5554545521736145, testing accuracy = 0.49086669087409973\n",
      "epoch=174/400,0/20 of train, loss=2.3336551189422607, training accuracy = 0.5480000376701355, testing accuracy = 0.4897007346153259\n",
      "epoch=174/400,10/20 of train, loss=2.3269448280334473, training accuracy = 0.5592727661132812, testing accuracy = 0.5001943111419678\n",
      "epoch=175/400,0/20 of train, loss=2.331813335418701, training accuracy = 0.5430000424385071, testing accuracy = 0.4947532117366791\n",
      "epoch=175/400,10/20 of train, loss=2.3301260471343994, training accuracy = 0.5544546246528625, testing accuracy = 0.49902838468551636\n",
      "epoch=176/400,0/20 of train, loss=2.3242218494415283, training accuracy = 0.550000011920929, testing accuracy = 0.4994170367717743\n",
      "epoch=176/400,10/20 of train, loss=2.3513896465301514, training accuracy = 0.5450000762939453, testing accuracy = 0.49203264713287354\n",
      "epoch=177/400,0/20 of train, loss=2.315855026245117, training accuracy = 0.5630000233650208, testing accuracy = 0.4869801998138428\n",
      "epoch=177/400,10/20 of train, loss=2.301439046859741, training accuracy = 0.5577272772789001, testing accuracy = 0.48892346024513245\n",
      "epoch=178/400,0/20 of train, loss=2.3043267726898193, training accuracy = 0.5730000138282776, testing accuracy = 0.49203264713287354\n",
      "epoch=178/400,10/20 of train, loss=2.3032007217407227, training accuracy = 0.5567272305488586, testing accuracy = 0.49902838468551636\n",
      "epoch=179/400,0/20 of train, loss=2.3231754302978516, training accuracy = 0.5520000457763672, testing accuracy = 0.4947532117366791\n",
      "epoch=179/400,10/20 of train, loss=2.306509494781494, training accuracy = 0.5580909848213196, testing accuracy = 0.48542559146881104\n",
      "epoch=180/400,0/20 of train, loss=2.3462555408477783, training accuracy = 0.5270000100135803, testing accuracy = 0.479595810174942\n",
      "epoch=180/400,10/20 of train, loss=2.3324549198150635, training accuracy = 0.5490909218788147, testing accuracy = 0.4939759075641632\n",
      "epoch=181/400,0/20 of train, loss=2.311136245727539, training accuracy = 0.5630000233650208, testing accuracy = 0.4838709831237793\n",
      "epoch=181/400,10/20 of train, loss=2.3400845527648926, training accuracy = 0.5485454797744751, testing accuracy = 0.495141863822937\n",
      "epoch=182/400,0/20 of train, loss=2.337170124053955, training accuracy = 0.5380000472068787, testing accuracy = 0.49203264713287354\n",
      "epoch=182/400,10/20 of train, loss=2.3004534244537354, training accuracy = 0.5579091310501099, testing accuracy = 0.49319860339164734\n",
      "epoch=183/400,0/20 of train, loss=2.320160150527954, training accuracy = 0.5570000410079956, testing accuracy = 0.4935872554779053\n",
      "epoch=183/400,10/20 of train, loss=2.308339834213257, training accuracy = 0.5597273111343384, testing accuracy = 0.4916439950466156\n",
      "epoch=184/400,0/20 of train, loss=2.300114870071411, training accuracy = 0.581000030040741, testing accuracy = 0.48542559146881104\n",
      "epoch=184/400,10/20 of train, loss=2.3232955932617188, training accuracy = 0.5590909123420715, testing accuracy = 0.4939759075641632\n",
      "epoch=185/400,0/20 of train, loss=2.3022620677948, training accuracy = 0.5740000009536743, testing accuracy = 0.49203264713287354\n",
      "epoch=185/400,10/20 of train, loss=2.3101847171783447, training accuracy = 0.5571818351745605, testing accuracy = 0.4959191679954529\n",
      "epoch=186/400,0/20 of train, loss=2.3309500217437744, training accuracy = 0.5460000038146973, testing accuracy = 0.4862028956413269\n",
      "epoch=186/400,10/20 of train, loss=2.3061366081237793, training accuracy = 0.5521818399429321, testing accuracy = 0.495141863822937\n",
      "epoch=187/400,0/20 of train, loss=2.311856508255005, training accuracy = 0.5670000314712524, testing accuracy = 0.4904780387878418\n",
      "epoch=187/400,10/20 of train, loss=2.344545364379883, training accuracy = 0.5520000457763672, testing accuracy = 0.4873688519001007\n",
      "epoch=188/400,0/20 of train, loss=2.3198704719543457, training accuracy = 0.5560000538825989, testing accuracy = 0.4838709831237793\n",
      "epoch=188/400,10/20 of train, loss=2.304856061935425, training accuracy = 0.5601818561553955, testing accuracy = 0.4881461560726166\n",
      "epoch=189/400,0/20 of train, loss=2.2976925373077393, training accuracy = 0.5800000429153442, testing accuracy = 0.48425963521003723\n",
      "epoch=189/400,10/20 of train, loss=2.317704916000366, training accuracy = 0.5617273449897766, testing accuracy = 0.4928099513053894\n",
      "epoch=190/400,0/20 of train, loss=2.3100435733795166, training accuracy = 0.5649999976158142, testing accuracy = 0.48775750398635864\n",
      "epoch=190/400,10/20 of train, loss=2.326674461364746, training accuracy = 0.556454598903656, testing accuracy = 0.4904780387878418\n",
      "epoch=191/400,0/20 of train, loss=2.324309825897217, training accuracy = 0.5480000376701355, testing accuracy = 0.4982510805130005\n",
      "epoch=191/400,10/20 of train, loss=2.3248648643493652, training accuracy = 0.560272753238678, testing accuracy = 0.48892346024513245\n",
      "epoch=192/400,0/20 of train, loss=2.335521697998047, training accuracy = 0.5400000214576721, testing accuracy = 0.489312082529068\n",
      "epoch=192/400,10/20 of train, loss=2.321016788482666, training accuracy = 0.5627272725105286, testing accuracy = 0.48775750398635864\n",
      "epoch=193/400,0/20 of train, loss=2.3246374130249023, training accuracy = 0.5540000200271606, testing accuracy = 0.49319860339164734\n",
      "epoch=193/400,10/20 of train, loss=2.3068418502807617, training accuracy = 0.5625455379486084, testing accuracy = 0.4904780387878418\n",
      "epoch=194/400,0/20 of train, loss=2.3187122344970703, training accuracy = 0.5580000281333923, testing accuracy = 0.49008938670158386\n",
      "epoch=194/400,10/20 of train, loss=2.314178705215454, training accuracy = 0.5654545426368713, testing accuracy = 0.49203264713287354\n",
      "epoch=195/400,0/20 of train, loss=2.3204097747802734, training accuracy = 0.5570000410079956, testing accuracy = 0.49242129921913147\n",
      "epoch=195/400,10/20 of train, loss=2.310678005218506, training accuracy = 0.5626363754272461, testing accuracy = 0.4970851242542267\n",
      "epoch=196/400,0/20 of train, loss=2.2943296432495117, training accuracy = 0.5800000429153442, testing accuracy = 0.4963078200817108\n",
      "epoch=196/400,10/20 of train, loss=2.300812005996704, training accuracy = 0.5693637132644653, testing accuracy = 0.4904780387878418\n",
      "epoch=197/400,0/20 of train, loss=2.3349366188049316, training accuracy = 0.5410000085830688, testing accuracy = 0.49086669087409973\n",
      "epoch=197/400,10/20 of train, loss=2.3068032264709473, training accuracy = 0.5660000443458557, testing accuracy = 0.49242129921913147\n",
      "epoch=198/400,0/20 of train, loss=2.311635971069336, training accuracy = 0.5630000233650208, testing accuracy = 0.4916439950466156\n",
      "epoch=198/400,10/20 of train, loss=2.3285951614379883, training accuracy = 0.565000057220459, testing accuracy = 0.495141863822937\n",
      "epoch=199/400,0/20 of train, loss=2.3038077354431152, training accuracy = 0.5720000267028809, testing accuracy = 0.49902838468551636\n",
      "epoch=199/400,10/20 of train, loss=2.3413846492767334, training accuracy = 0.5662727355957031, testing accuracy = 0.4881461560726166\n",
      "epoch=200/400,0/20 of train, loss=2.3077518939971924, training accuracy = 0.5700000524520874, testing accuracy = 0.49319860339164734\n",
      "epoch=200/400,10/20 of train, loss=2.3025333881378174, training accuracy = 0.5638182163238525, testing accuracy = 0.4873688519001007\n",
      "epoch=201/400,0/20 of train, loss=2.3089075088500977, training accuracy = 0.5690000057220459, testing accuracy = 0.4916439950466156\n",
      "epoch=201/400,10/20 of train, loss=2.2938594818115234, training accuracy = 0.5674546360969543, testing accuracy = 0.49125534296035767\n",
      "epoch=202/400,0/20 of train, loss=2.3255810737609863, training accuracy = 0.5540000200271606, testing accuracy = 0.49086669087409973\n",
      "epoch=202/400,10/20 of train, loss=2.3156447410583496, training accuracy = 0.5678182244300842, testing accuracy = 0.49086669087409973\n",
      "epoch=203/400,0/20 of train, loss=2.3104610443115234, training accuracy = 0.5660000443458557, testing accuracy = 0.4885348081588745\n",
      "epoch=203/400,10/20 of train, loss=2.306675910949707, training accuracy = 0.5624546408653259, testing accuracy = 0.4885348081588745\n",
      "epoch=204/400,0/20 of train, loss=2.277885913848877, training accuracy = 0.597000002861023, testing accuracy = 0.49086669087409973\n",
      "epoch=204/400,10/20 of train, loss=2.3069844245910645, training accuracy = 0.5648182034492493, testing accuracy = 0.4904780387878418\n",
      "epoch=205/400,0/20 of train, loss=2.309699296951294, training accuracy = 0.5670000314712524, testing accuracy = 0.4959191679954529\n",
      "epoch=205/400,10/20 of train, loss=2.3005378246307373, training accuracy = 0.5699999928474426, testing accuracy = 0.48892346024513245\n",
      "epoch=206/400,0/20 of train, loss=2.3058745861053467, training accuracy = 0.5740000009536743, testing accuracy = 0.49242129921913147\n",
      "epoch=206/400,10/20 of train, loss=2.3161749839782715, training accuracy = 0.5715454816818237, testing accuracy = 0.48892346024513245\n",
      "epoch=207/400,0/20 of train, loss=2.306377410888672, training accuracy = 0.5730000138282776, testing accuracy = 0.49242129921913147\n",
      "epoch=207/400,10/20 of train, loss=2.3140909671783447, training accuracy = 0.5678182244300842, testing accuracy = 0.49242129921913147\n",
      "epoch=208/400,0/20 of train, loss=2.291904926300049, training accuracy = 0.5870000123977661, testing accuracy = 0.4897007346153259\n",
      "epoch=208/400,10/20 of train, loss=2.3111982345581055, training accuracy = 0.5683636665344238, testing accuracy = 0.49319860339164734\n",
      "epoch=209/400,0/20 of train, loss=2.2905843257904053, training accuracy = 0.5870000123977661, testing accuracy = 0.4963078200817108\n",
      "epoch=209/400,10/20 of train, loss=2.2951416969299316, training accuracy = 0.5703636407852173, testing accuracy = 0.4897007346153259\n",
      "epoch=210/400,0/20 of train, loss=2.324337959289551, training accuracy = 0.5540000200271606, testing accuracy = 0.495141863822937\n",
      "epoch=210/400,10/20 of train, loss=2.3174664974212646, training accuracy = 0.5664545893669128, testing accuracy = 0.4959191679954529\n",
      "epoch=211/400,0/20 of train, loss=2.328599214553833, training accuracy = 0.5450000166893005, testing accuracy = 0.4897007346153259\n",
      "epoch=211/400,10/20 of train, loss=2.281893253326416, training accuracy = 0.5663636922836304, testing accuracy = 0.48775750398635864\n",
      "epoch=212/400,0/20 of train, loss=2.296098470687866, training accuracy = 0.581000030040741, testing accuracy = 0.4881461560726166\n",
      "epoch=212/400,10/20 of train, loss=2.317657232284546, training accuracy = 0.5646363496780396, testing accuracy = 0.49553051590919495\n",
      "epoch=213/400,0/20 of train, loss=2.303755760192871, training accuracy = 0.5710000395774841, testing accuracy = 0.4916439950466156\n",
      "epoch=213/400,10/20 of train, loss=2.3034327030181885, training accuracy = 0.5711818933486938, testing accuracy = 0.49008938670158386\n",
      "epoch=214/400,0/20 of train, loss=2.338690757751465, training accuracy = 0.5350000262260437, testing accuracy = 0.49319860339164734\n",
      "epoch=214/400,10/20 of train, loss=2.2917518615722656, training accuracy = 0.568818211555481, testing accuracy = 0.495141863822937\n",
      "epoch=215/400,0/20 of train, loss=2.316835880279541, training accuracy = 0.5570000410079956, testing accuracy = 0.4928099513053894\n",
      "epoch=215/400,10/20 of train, loss=2.3110063076019287, training accuracy = 0.56690913438797, testing accuracy = 0.49086669087409973\n",
      "epoch=216/400,0/20 of train, loss=2.304276466369629, training accuracy = 0.5740000009536743, testing accuracy = 0.4947532117366791\n",
      "epoch=216/400,10/20 of train, loss=2.3068277835845947, training accuracy = 0.5708182454109192, testing accuracy = 0.4947532117366791\n",
      "epoch=217/400,0/20 of train, loss=2.309134006500244, training accuracy = 0.5670000314712524, testing accuracy = 0.4963078200817108\n",
      "epoch=217/400,10/20 of train, loss=2.3032472133636475, training accuracy = 0.5706363916397095, testing accuracy = 0.49319860339164734\n",
      "epoch=218/400,0/20 of train, loss=2.299297332763672, training accuracy = 0.5790000557899475, testing accuracy = 0.4873688519001007\n",
      "epoch=218/400,10/20 of train, loss=2.3421709537506104, training accuracy = 0.5759091377258301, testing accuracy = 0.49203264713287354\n",
      "epoch=219/400,0/20 of train, loss=2.2857837677001953, training accuracy = 0.5900000333786011, testing accuracy = 0.4939759075641632\n",
      "epoch=219/400,10/20 of train, loss=2.289212465286255, training accuracy = 0.5778182148933411, testing accuracy = 0.4916439950466156\n",
      "epoch=220/400,0/20 of train, loss=2.289166212081909, training accuracy = 0.5870000123977661, testing accuracy = 0.49125534296035767\n",
      "epoch=220/400,10/20 of train, loss=2.3140411376953125, training accuracy = 0.5708182454109192, testing accuracy = 0.49553051590919495\n",
      "epoch=221/400,0/20 of train, loss=2.300246238708496, training accuracy = 0.5770000219345093, testing accuracy = 0.4830936789512634\n",
      "epoch=221/400,10/20 of train, loss=2.2990002632141113, training accuracy = 0.5710909366607666, testing accuracy = 0.495141863822937\n",
      "epoch=222/400,0/20 of train, loss=2.3263986110687256, training accuracy = 0.550000011920929, testing accuracy = 0.49086669087409973\n",
      "epoch=222/400,10/20 of train, loss=2.280829429626465, training accuracy = 0.5699091553688049, testing accuracy = 0.49553051590919495\n",
      "epoch=223/400,0/20 of train, loss=2.3027899265289307, training accuracy = 0.5770000219345093, testing accuracy = 0.49086669087409973\n",
      "epoch=223/400,10/20 of train, loss=2.3108069896698, training accuracy = 0.5742727518081665, testing accuracy = 0.4928099513053894\n",
      "epoch=224/400,0/20 of train, loss=2.3288309574127197, training accuracy = 0.5470000505447388, testing accuracy = 0.495141863822937\n",
      "epoch=224/400,10/20 of train, loss=2.3080477714538574, training accuracy = 0.5695455074310303, testing accuracy = 0.4935872554779053\n",
      "epoch=225/400,0/20 of train, loss=2.324467420578003, training accuracy = 0.5540000200271606, testing accuracy = 0.4916439950466156\n",
      "epoch=225/400,10/20 of train, loss=2.319298505783081, training accuracy = 0.5745455026626587, testing accuracy = 0.4897007346153259\n",
      "epoch=226/400,0/20 of train, loss=2.2980732917785645, training accuracy = 0.5790000557899475, testing accuracy = 0.4916439950466156\n",
      "epoch=226/400,10/20 of train, loss=2.3099257946014404, training accuracy = 0.5708182454109192, testing accuracy = 0.4881461560726166\n",
      "epoch=227/400,0/20 of train, loss=2.2865190505981445, training accuracy = 0.5900000333786011, testing accuracy = 0.49242129921913147\n",
      "epoch=227/400,10/20 of train, loss=2.2917706966400146, training accuracy = 0.579727292060852, testing accuracy = 0.49242129921913147\n",
      "epoch=228/400,0/20 of train, loss=2.3163259029388428, training accuracy = 0.5600000023841858, testing accuracy = 0.49203264713287354\n",
      "epoch=228/400,10/20 of train, loss=2.302097797393799, training accuracy = 0.5701819658279419, testing accuracy = 0.49669647216796875\n",
      "epoch=229/400,0/20 of train, loss=2.2953834533691406, training accuracy = 0.5790000557899475, testing accuracy = 0.4916439950466156\n",
      "epoch=229/400,10/20 of train, loss=2.2894108295440674, training accuracy = 0.572272777557373, testing accuracy = 0.4916439950466156\n",
      "epoch=230/400,0/20 of train, loss=2.291163444519043, training accuracy = 0.5850000381469727, testing accuracy = 0.49319860339164734\n",
      "epoch=230/400,10/20 of train, loss=2.303395986557007, training accuracy = 0.5782727599143982, testing accuracy = 0.4916439950466156\n",
      "epoch=231/400,0/20 of train, loss=2.277066707611084, training accuracy = 0.6020000576972961, testing accuracy = 0.49125534296035767\n",
      "epoch=231/400,10/20 of train, loss=2.2731549739837646, training accuracy = 0.5696364045143127, testing accuracy = 0.4928099513053894\n",
      "epoch=232/400,0/20 of train, loss=2.3232150077819824, training accuracy = 0.5530000329017639, testing accuracy = 0.48659154772758484\n",
      "epoch=232/400,10/20 of train, loss=2.303123950958252, training accuracy = 0.5704545974731445, testing accuracy = 0.4916439950466156\n",
      "epoch=233/400,0/20 of train, loss=2.318232297897339, training accuracy = 0.5600000023841858, testing accuracy = 0.4916439950466156\n",
      "epoch=233/400,10/20 of train, loss=2.317857027053833, training accuracy = 0.5693637132644653, testing accuracy = 0.49125534296035767\n",
      "epoch=234/400,0/20 of train, loss=2.297109842300415, training accuracy = 0.5820000171661377, testing accuracy = 0.4916439950466156\n",
      "epoch=234/400,10/20 of train, loss=2.309598207473755, training accuracy = 0.578909158706665, testing accuracy = 0.4897007346153259\n",
      "epoch=235/400,0/20 of train, loss=2.2953267097473145, training accuracy = 0.581000030040741, testing accuracy = 0.4916439950466156\n",
      "epoch=235/400,10/20 of train, loss=2.339707136154175, training accuracy = 0.5792728066444397, testing accuracy = 0.495141863822937\n",
      "epoch=236/400,0/20 of train, loss=2.316767930984497, training accuracy = 0.5580000281333923, testing accuracy = 0.48542559146881104\n",
      "epoch=236/400,10/20 of train, loss=2.306481122970581, training accuracy = 0.5768182873725891, testing accuracy = 0.48775750398635864\n",
      "epoch=237/400,0/20 of train, loss=2.2903268337249756, training accuracy = 0.5860000252723694, testing accuracy = 0.4963078200817108\n",
      "epoch=237/400,10/20 of train, loss=2.290928602218628, training accuracy = 0.5740909576416016, testing accuracy = 0.49436455965042114\n",
      "epoch=238/400,0/20 of train, loss=2.3258180618286133, training accuracy = 0.5520000457763672, testing accuracy = 0.49125534296035767\n",
      "epoch=238/400,10/20 of train, loss=2.3036811351776123, training accuracy = 0.5820000767707825, testing accuracy = 0.4916439950466156\n",
      "epoch=239/400,0/20 of train, loss=2.268139362335205, training accuracy = 0.6100000143051147, testing accuracy = 0.49008938670158386\n",
      "epoch=239/400,10/20 of train, loss=2.313870429992676, training accuracy = 0.5757272839546204, testing accuracy = 0.4904780387878418\n",
      "epoch=240/400,0/20 of train, loss=2.333050489425659, training accuracy = 0.5450000166893005, testing accuracy = 0.4928099513053894\n",
      "epoch=240/400,10/20 of train, loss=2.327826976776123, training accuracy = 0.5748181939125061, testing accuracy = 0.49203264713287354\n",
      "epoch=241/400,0/20 of train, loss=2.3119561672210693, training accuracy = 0.5660000443458557, testing accuracy = 0.49125534296035767\n",
      "epoch=241/400,10/20 of train, loss=2.2939870357513428, training accuracy = 0.5758181810379028, testing accuracy = 0.4928099513053894\n",
      "epoch=242/400,0/20 of train, loss=2.296947479248047, training accuracy = 0.5800000429153442, testing accuracy = 0.4928099513053894\n",
      "epoch=242/400,10/20 of train, loss=2.300926923751831, training accuracy = 0.5797273516654968, testing accuracy = 0.4935872554779053\n",
      "epoch=243/400,0/20 of train, loss=2.306004285812378, training accuracy = 0.5720000267028809, testing accuracy = 0.49125534296035767\n",
      "epoch=243/400,10/20 of train, loss=2.2851178646087646, training accuracy = 0.5839091539382935, testing accuracy = 0.4916439950466156\n",
      "epoch=244/400,0/20 of train, loss=2.327357053756714, training accuracy = 0.5470000505447388, testing accuracy = 0.49203264713287354\n",
      "epoch=244/400,10/20 of train, loss=2.2803642749786377, training accuracy = 0.5781818628311157, testing accuracy = 0.4939759075641632\n",
      "epoch=245/400,0/20 of train, loss=2.295530319213867, training accuracy = 0.581000030040741, testing accuracy = 0.49242129921913147\n",
      "epoch=245/400,10/20 of train, loss=2.3125479221343994, training accuracy = 0.5793636441230774, testing accuracy = 0.4916439950466156\n",
      "epoch=246/400,0/20 of train, loss=2.339285135269165, training accuracy = 0.5390000343322754, testing accuracy = 0.495141863822937\n",
      "epoch=246/400,10/20 of train, loss=2.2814276218414307, training accuracy = 0.5787273049354553, testing accuracy = 0.4928099513053894\n",
      "epoch=247/400,0/20 of train, loss=2.2995352745056152, training accuracy = 0.5760000348091125, testing accuracy = 0.49008938670158386\n",
      "epoch=247/400,10/20 of train, loss=2.295203685760498, training accuracy = 0.5826364159584045, testing accuracy = 0.49319860339164734\n",
      "epoch=248/400,0/20 of train, loss=2.280409812927246, training accuracy = 0.5980000495910645, testing accuracy = 0.49436455965042114\n",
      "epoch=248/400,10/20 of train, loss=2.316495656967163, training accuracy = 0.578272819519043, testing accuracy = 0.49669647216796875\n",
      "epoch=249/400,0/20 of train, loss=2.2973639965057373, training accuracy = 0.581000030040741, testing accuracy = 0.49203264713287354\n",
      "epoch=249/400,10/20 of train, loss=2.3210489749908447, training accuracy = 0.5832727551460266, testing accuracy = 0.4935872554779053\n",
      "epoch=250/400,0/20 of train, loss=2.2908055782318115, training accuracy = 0.5850000381469727, testing accuracy = 0.49319860339164734\n",
      "epoch=250/400,10/20 of train, loss=2.3107707500457764, training accuracy = 0.5756364464759827, testing accuracy = 0.4869801998138428\n",
      "epoch=251/400,0/20 of train, loss=2.3056983947753906, training accuracy = 0.5690000057220459, testing accuracy = 0.49242129921913147\n",
      "epoch=251/400,10/20 of train, loss=2.2857766151428223, training accuracy = 0.5749090909957886, testing accuracy = 0.49203264713287354\n",
      "epoch=252/400,0/20 of train, loss=2.3009700775146484, training accuracy = 0.578000009059906, testing accuracy = 0.49242129921913147\n",
      "epoch=252/400,10/20 of train, loss=2.317304849624634, training accuracy = 0.5788182616233826, testing accuracy = 0.49008938670158386\n",
      "epoch=253/400,0/20 of train, loss=2.32064151763916, training accuracy = 0.5560000538825989, testing accuracy = 0.48892346024513245\n",
      "epoch=253/400,10/20 of train, loss=2.2924535274505615, training accuracy = 0.5780000686645508, testing accuracy = 0.5017489194869995\n",
      "epoch=254/400,0/20 of train, loss=2.311004638671875, training accuracy = 0.5670000314712524, testing accuracy = 0.5102992653846741\n",
      "epoch=254/400,10/20 of train, loss=2.2913124561309814, training accuracy = 0.5906363725662231, testing accuracy = 0.5192382335662842\n",
      "epoch=255/400,0/20 of train, loss=2.2582545280456543, training accuracy = 0.6240000128746033, testing accuracy = 0.5149630904197693\n",
      "epoch=255/400,10/20 of train, loss=2.2984189987182617, training accuracy = 0.5983636975288391, testing accuracy = 0.5141857862472534\n",
      "epoch=256/400,0/20 of train, loss=2.279355764389038, training accuracy = 0.5950000286102295, testing accuracy = 0.5192382335662842\n",
      "epoch=256/400,10/20 of train, loss=2.276702642440796, training accuracy = 0.6000000238418579, testing accuracy = 0.5149630904197693\n",
      "epoch=257/400,0/20 of train, loss=2.2551846504211426, training accuracy = 0.6210000514984131, testing accuracy = 0.5192382335662842\n",
      "epoch=257/400,10/20 of train, loss=2.293085813522339, training accuracy = 0.5951818227767944, testing accuracy = 0.5235134363174438\n",
      "epoch=258/400,0/20 of train, loss=2.289276361465454, training accuracy = 0.5879999995231628, testing accuracy = 0.516517698764801\n",
      "epoch=258/400,10/20 of train, loss=2.3046681880950928, training accuracy = 0.5986363887786865, testing accuracy = 0.5192382335662842\n",
      "epoch=259/400,0/20 of train, loss=2.2893898487091064, training accuracy = 0.5860000252723694, testing accuracy = 0.5281772613525391\n",
      "epoch=259/400,10/20 of train, loss=2.2543716430664062, training accuracy = 0.6014545559883118, testing accuracy = 0.5312864184379578\n",
      "epoch=260/400,0/20 of train, loss=2.2769556045532227, training accuracy = 0.6050000190734863, testing accuracy = 0.5250680446624756\n",
      "epoch=260/400,10/20 of train, loss=2.2775771617889404, training accuracy = 0.610090970993042, testing accuracy = 0.5246793627738953\n",
      "epoch=261/400,0/20 of train, loss=2.2601535320281982, training accuracy = 0.6180000305175781, testing accuracy = 0.5273999571800232\n",
      "epoch=261/400,10/20 of train, loss=2.287893056869507, training accuracy = 0.606454610824585, testing accuracy = 0.5273999571800232\n",
      "epoch=262/400,0/20 of train, loss=2.2650156021118164, training accuracy = 0.6140000224113464, testing accuracy = 0.5235134363174438\n",
      "epoch=262/400,10/20 of train, loss=2.2800211906433105, training accuracy = 0.6110000014305115, testing accuracy = 0.5301204919815063\n",
      "epoch=263/400,0/20 of train, loss=2.2822959423065186, training accuracy = 0.5950000286102295, testing accuracy = 0.532452404499054\n",
      "epoch=263/400,10/20 of train, loss=2.260288715362549, training accuracy = 0.6097273230552673, testing accuracy = 0.5258453488349915\n",
      "epoch=264/400,0/20 of train, loss=2.2422759532928467, training accuracy = 0.6370000243186951, testing accuracy = 0.5273999571800232\n",
      "epoch=264/400,10/20 of train, loss=2.2670645713806152, training accuracy = 0.612636387348175, testing accuracy = 0.5281772613525391\n",
      "epoch=265/400,0/20 of train, loss=2.266115427017212, training accuracy = 0.6150000095367432, testing accuracy = 0.5242907404899597\n",
      "epoch=265/400,10/20 of train, loss=2.2641124725341797, training accuracy = 0.6166363954544067, testing accuracy = 0.5340070128440857\n",
      "epoch=266/400,0/20 of train, loss=2.2476677894592285, training accuracy = 0.6350000500679016, testing accuracy = 0.5266226530075073\n",
      "epoch=266/400,10/20 of train, loss=2.274120330810547, training accuracy = 0.6116364002227783, testing accuracy = 0.526233971118927\n",
      "epoch=267/400,0/20 of train, loss=2.2614917755126953, training accuracy = 0.6170000433921814, testing accuracy = 0.5312864184379578\n",
      "epoch=267/400,10/20 of train, loss=2.2847900390625, training accuracy = 0.6130000352859497, testing accuracy = 0.5250680446624756\n",
      "epoch=268/400,0/20 of train, loss=2.2731211185455322, training accuracy = 0.6040000319480896, testing accuracy = 0.5297318696975708\n",
      "epoch=268/400,10/20 of train, loss=2.2404918670654297, training accuracy = 0.6206364035606384, testing accuracy = 0.5308977961540222\n",
      "epoch=269/400,0/20 of train, loss=2.2522709369659424, training accuracy = 0.6270000338554382, testing accuracy = 0.532452404499054\n",
      "epoch=269/400,10/20 of train, loss=2.2725419998168945, training accuracy = 0.6138182282447815, testing accuracy = 0.5289545655250549\n",
      "epoch=270/400,0/20 of train, loss=2.2601287364959717, training accuracy = 0.6170000433921814, testing accuracy = 0.5305091738700867\n",
      "epoch=270/400,10/20 of train, loss=2.2555508613586426, training accuracy = 0.6181819438934326, testing accuracy = 0.5281772613525391\n",
      "epoch=271/400,0/20 of train, loss=2.2834208011627197, training accuracy = 0.5940000414848328, testing accuracy = 0.526233971118927\n",
      "epoch=271/400,10/20 of train, loss=2.264232635498047, training accuracy = 0.6190909743309021, testing accuracy = 0.5231247544288635\n",
      "epoch=272/400,0/20 of train, loss=2.238398790359497, training accuracy = 0.6440000534057617, testing accuracy = 0.5293431878089905\n",
      "epoch=272/400,10/20 of train, loss=2.2564074993133545, training accuracy = 0.6062727570533752, testing accuracy = 0.5297318696975708\n",
      "epoch=273/400,0/20 of train, loss=2.2700366973876953, training accuracy = 0.6080000400543213, testing accuracy = 0.5308977961540222\n",
      "epoch=273/400,10/20 of train, loss=2.2713191509246826, training accuracy = 0.6150000095367432, testing accuracy = 0.5301204919815063\n",
      "epoch=274/400,0/20 of train, loss=2.2681918144226074, training accuracy = 0.6110000014305115, testing accuracy = 0.5285658836364746\n",
      "epoch=274/400,10/20 of train, loss=2.258697032928467, training accuracy = 0.620363712310791, testing accuracy = 0.5270112752914429\n",
      "epoch=275/400,0/20 of train, loss=2.2626402378082275, training accuracy = 0.6160000562667847, testing accuracy = 0.5215701460838318\n",
      "epoch=275/400,10/20 of train, loss=2.262850761413574, training accuracy = 0.6085454821586609, testing accuracy = 0.5332297086715698\n",
      "epoch=276/400,0/20 of train, loss=2.2800838947296143, training accuracy = 0.5960000157356262, testing accuracy = 0.5277885794639587\n",
      "epoch=276/400,10/20 of train, loss=2.2757720947265625, training accuracy = 0.6157273650169373, testing accuracy = 0.5301204919815063\n",
      "epoch=277/400,0/20 of train, loss=2.2333667278289795, training accuracy = 0.6500000357627869, testing accuracy = 0.5285658836364746\n",
      "epoch=277/400,10/20 of train, loss=2.279574155807495, training accuracy = 0.6197273135185242, testing accuracy = 0.5266226530075073\n",
      "epoch=278/400,0/20 of train, loss=2.2711474895477295, training accuracy = 0.6070000529289246, testing accuracy = 0.5305091738700867\n",
      "epoch=278/400,10/20 of train, loss=2.279819965362549, training accuracy = 0.6162727475166321, testing accuracy = 0.5320637226104736\n",
      "epoch=279/400,0/20 of train, loss=2.24953293800354, training accuracy = 0.6290000081062317, testing accuracy = 0.532452404499054\n",
      "epoch=279/400,10/20 of train, loss=2.2556312084198, training accuracy = 0.616727352142334, testing accuracy = 0.5273999571800232\n",
      "epoch=280/400,0/20 of train, loss=2.2378249168395996, training accuracy = 0.6420000195503235, testing accuracy = 0.5293431878089905\n",
      "epoch=280/400,10/20 of train, loss=2.2460949420928955, training accuracy = 0.6155454516410828, testing accuracy = 0.5308977961540222\n",
      "epoch=281/400,0/20 of train, loss=2.253652334213257, training accuracy = 0.625, testing accuracy = 0.5258453488349915\n",
      "epoch=281/400,10/20 of train, loss=2.257596492767334, training accuracy = 0.6264546513557434, testing accuracy = 0.5308977961540222\n",
      "epoch=282/400,0/20 of train, loss=2.260802745819092, training accuracy = 0.6150000095367432, testing accuracy = 0.5277885794639587\n",
      "epoch=282/400,10/20 of train, loss=2.2207560539245605, training accuracy = 0.6242728233337402, testing accuracy = 0.5273999571800232\n",
      "epoch=283/400,0/20 of train, loss=2.2626373767852783, training accuracy = 0.6140000224113464, testing accuracy = 0.5293431878089905\n",
      "epoch=283/400,10/20 of train, loss=2.229823350906372, training accuracy = 0.620545506477356, testing accuracy = 0.5246793627738953\n",
      "epoch=284/400,0/20 of train, loss=2.2546169757843018, training accuracy = 0.6210000514984131, testing accuracy = 0.5281772613525391\n",
      "epoch=284/400,10/20 of train, loss=2.2336647510528564, training accuracy = 0.6204545497894287, testing accuracy = 0.5266226530075073\n",
      "epoch=285/400,0/20 of train, loss=2.2504210472106934, training accuracy = 0.6310000419616699, testing accuracy = 0.532452404499054\n",
      "epoch=285/400,10/20 of train, loss=2.24997615814209, training accuracy = 0.6201818585395813, testing accuracy = 0.5285658836364746\n",
      "epoch=286/400,0/20 of train, loss=2.2553458213806152, training accuracy = 0.6290000081062317, testing accuracy = 0.526233971118927\n",
      "epoch=286/400,10/20 of train, loss=2.222212553024292, training accuracy = 0.6249091029167175, testing accuracy = 0.5305091738700867\n",
      "epoch=287/400,0/20 of train, loss=2.2433276176452637, training accuracy = 0.6310000419616699, testing accuracy = 0.5273999571800232\n",
      "epoch=287/400,10/20 of train, loss=2.2621119022369385, training accuracy = 0.6254546046257019, testing accuracy = 0.5270112752914429\n",
      "epoch=288/400,0/20 of train, loss=2.251490592956543, training accuracy = 0.628000020980835, testing accuracy = 0.5289545655250549\n",
      "epoch=288/400,10/20 of train, loss=2.2549548149108887, training accuracy = 0.6114546060562134, testing accuracy = 0.526233971118927\n",
      "epoch=289/400,0/20 of train, loss=2.234576940536499, training accuracy = 0.6410000324249268, testing accuracy = 0.5308977961540222\n",
      "epoch=289/400,10/20 of train, loss=2.248584032058716, training accuracy = 0.626090943813324, testing accuracy = 0.5250680446624756\n",
      "epoch=290/400,0/20 of train, loss=2.2534708976745605, training accuracy = 0.6210000514984131, testing accuracy = 0.5246793627738953\n",
      "epoch=290/400,10/20 of train, loss=2.2689361572265625, training accuracy = 0.620272696018219, testing accuracy = 0.5273999571800232\n",
      "epoch=291/400,0/20 of train, loss=2.251389265060425, training accuracy = 0.6270000338554382, testing accuracy = 0.5293431878089905\n",
      "epoch=291/400,10/20 of train, loss=2.2564449310302734, training accuracy = 0.6226364374160767, testing accuracy = 0.5246793627738953\n",
      "epoch=292/400,0/20 of train, loss=2.224428415298462, training accuracy = 0.656000018119812, testing accuracy = 0.5308977961540222\n",
      "epoch=292/400,10/20 of train, loss=2.2651376724243164, training accuracy = 0.6249091625213623, testing accuracy = 0.5293431878089905\n",
      "epoch=293/400,0/20 of train, loss=2.279878616333008, training accuracy = 0.5990000367164612, testing accuracy = 0.5266226530075073\n",
      "epoch=293/400,10/20 of train, loss=2.2742481231689453, training accuracy = 0.6192728281021118, testing accuracy = 0.5254566669464111\n",
      "epoch=294/400,0/20 of train, loss=2.2554068565368652, training accuracy = 0.6200000047683716, testing accuracy = 0.5312864184379578\n",
      "epoch=294/400,10/20 of train, loss=2.26008939743042, training accuracy = 0.6174546480178833, testing accuracy = 0.5270112752914429\n",
      "epoch=295/400,0/20 of train, loss=2.2745604515075684, training accuracy = 0.6070000529289246, testing accuracy = 0.5320637226104736\n",
      "epoch=295/400,10/20 of train, loss=2.237391710281372, training accuracy = 0.623090922832489, testing accuracy = 0.5316751003265381\n",
      "epoch=296/400,0/20 of train, loss=2.2681174278259277, training accuracy = 0.609000027179718, testing accuracy = 0.5293431878089905\n",
      "epoch=296/400,10/20 of train, loss=2.252953290939331, training accuracy = 0.6281818747520447, testing accuracy = 0.5328410267829895\n",
      "epoch=297/400,0/20 of train, loss=2.2560312747955322, training accuracy = 0.6260000467300415, testing accuracy = 0.5242907404899597\n",
      "epoch=297/400,10/20 of train, loss=2.2752482891082764, training accuracy = 0.6244546175003052, testing accuracy = 0.5270112752914429\n",
      "epoch=298/400,0/20 of train, loss=2.2539122104644775, training accuracy = 0.625, testing accuracy = 0.5308977961540222\n",
      "epoch=298/400,10/20 of train, loss=2.2479019165039062, training accuracy = 0.6315454244613647, testing accuracy = 0.5277885794639587\n",
      "epoch=299/400,0/20 of train, loss=2.261432409286499, training accuracy = 0.6170000433921814, testing accuracy = 0.5301204919815063\n",
      "epoch=299/400,10/20 of train, loss=2.2430460453033447, training accuracy = 0.6270909309387207, testing accuracy = 0.5242907404899597\n",
      "epoch=300/400,0/20 of train, loss=2.240945816040039, training accuracy = 0.6340000033378601, testing accuracy = 0.532452404499054\n",
      "epoch=300/400,10/20 of train, loss=2.2454845905303955, training accuracy = 0.6257273554801941, testing accuracy = 0.5312864184379578\n",
      "epoch=301/400,0/20 of train, loss=2.263608455657959, training accuracy = 0.6140000224113464, testing accuracy = 0.5312864184379578\n",
      "epoch=301/400,10/20 of train, loss=2.2668025493621826, training accuracy = 0.6307273507118225, testing accuracy = 0.5254566669464111\n",
      "epoch=302/400,0/20 of train, loss=2.2751312255859375, training accuracy = 0.6010000109672546, testing accuracy = 0.5316751003265381\n",
      "epoch=302/400,10/20 of train, loss=2.255688190460205, training accuracy = 0.6215454936027527, testing accuracy = 0.522736132144928\n",
      "epoch=303/400,0/20 of train, loss=2.250620126724243, training accuracy = 0.625, testing accuracy = 0.5250680446624756\n",
      "epoch=303/400,10/20 of train, loss=2.247337579727173, training accuracy = 0.6265455484390259, testing accuracy = 0.5320637226104736\n",
      "epoch=304/400,0/20 of train, loss=2.249516010284424, training accuracy = 0.6320000290870667, testing accuracy = 0.5305091738700867\n",
      "epoch=304/400,10/20 of train, loss=2.249936819076538, training accuracy = 0.6250909566879272, testing accuracy = 0.5289545655250549\n",
      "epoch=305/400,0/20 of train, loss=2.2588770389556885, training accuracy = 0.6210000514984131, testing accuracy = 0.5301204919815063\n",
      "epoch=305/400,10/20 of train, loss=2.2655997276306152, training accuracy = 0.6266364455223083, testing accuracy = 0.5312864184379578\n",
      "epoch=306/400,0/20 of train, loss=2.253387689590454, training accuracy = 0.6300000548362732, testing accuracy = 0.5246793627738953\n",
      "epoch=306/400,10/20 of train, loss=2.246446371078491, training accuracy = 0.6240000128746033, testing accuracy = 0.5277885794639587\n",
      "epoch=307/400,0/20 of train, loss=2.237205743789673, training accuracy = 0.6420000195503235, testing accuracy = 0.5308977961540222\n",
      "epoch=307/400,10/20 of train, loss=2.2427096366882324, training accuracy = 0.6249091625213623, testing accuracy = 0.5332297086715698\n",
      "epoch=308/400,0/20 of train, loss=2.2447195053100586, training accuracy = 0.6270000338554382, testing accuracy = 0.5281772613525391\n",
      "epoch=308/400,10/20 of train, loss=2.26253080368042, training accuracy = 0.6308181881904602, testing accuracy = 0.5242907404899597\n",
      "epoch=309/400,0/20 of train, loss=2.2373273372650146, training accuracy = 0.6410000324249268, testing accuracy = 0.5239020586013794\n",
      "epoch=309/400,10/20 of train, loss=2.2653980255126953, training accuracy = 0.6281818747520447, testing accuracy = 0.5336183309555054\n",
      "epoch=310/400,0/20 of train, loss=2.223567247390747, training accuracy = 0.6530000567436218, testing accuracy = 0.5297318696975708\n",
      "epoch=310/400,10/20 of train, loss=2.258490800857544, training accuracy = 0.6321818828582764, testing accuracy = 0.5301204919815063\n",
      "epoch=311/400,0/20 of train, loss=2.2562415599823, training accuracy = 0.6180000305175781, testing accuracy = 0.5297318696975708\n",
      "epoch=311/400,10/20 of train, loss=2.246297597885132, training accuracy = 0.6279091238975525, testing accuracy = 0.5231247544288635\n",
      "epoch=312/400,0/20 of train, loss=2.2614247798919678, training accuracy = 0.6170000433921814, testing accuracy = 0.5242907404899597\n",
      "epoch=312/400,10/20 of train, loss=2.256337881088257, training accuracy = 0.626090943813324, testing accuracy = 0.5308977961540222\n",
      "epoch=313/400,0/20 of train, loss=2.274381399154663, training accuracy = 0.6070000529289246, testing accuracy = 0.5242907404899597\n",
      "epoch=313/400,10/20 of train, loss=2.26766037940979, training accuracy = 0.6298182606697083, testing accuracy = 0.532452404499054\n",
      "epoch=314/400,0/20 of train, loss=2.2525634765625, training accuracy = 0.6240000128746033, testing accuracy = 0.5246793627738953\n",
      "epoch=314/400,10/20 of train, loss=2.2329254150390625, training accuracy = 0.6276364326477051, testing accuracy = 0.5363389253616333\n",
      "epoch=315/400,0/20 of train, loss=2.2474710941314697, training accuracy = 0.628000020980835, testing accuracy = 0.5297318696975708\n",
      "epoch=315/400,10/20 of train, loss=2.233074903488159, training accuracy = 0.6303636431694031, testing accuracy = 0.5277885794639587\n",
      "epoch=316/400,0/20 of train, loss=2.246528387069702, training accuracy = 0.6320000290870667, testing accuracy = 0.5246793627738953\n",
      "epoch=316/400,10/20 of train, loss=2.277096748352051, training accuracy = 0.6272727251052856, testing accuracy = 0.5332297086715698\n",
      "epoch=317/400,0/20 of train, loss=2.242189645767212, training accuracy = 0.6340000033378601, testing accuracy = 0.5297318696975708\n",
      "epoch=317/400,10/20 of train, loss=2.2577319145202637, training accuracy = 0.6284546256065369, testing accuracy = 0.5293431878089905\n",
      "epoch=318/400,0/20 of train, loss=2.26705002784729, training accuracy = 0.6080000400543213, testing accuracy = 0.5340070128440857\n",
      "epoch=318/400,10/20 of train, loss=2.251655340194702, training accuracy = 0.6296364068984985, testing accuracy = 0.5200155377388\n",
      "epoch=319/400,0/20 of train, loss=2.240384578704834, training accuracy = 0.6370000243186951, testing accuracy = 0.5343956351280212\n",
      "epoch=319/400,10/20 of train, loss=2.2116892337799072, training accuracy = 0.6293635964393616, testing accuracy = 0.5305091738700867\n",
      "epoch=320/400,0/20 of train, loss=2.242607355117798, training accuracy = 0.6380000114440918, testing accuracy = 0.5285658836364746\n",
      "epoch=320/400,10/20 of train, loss=2.2480809688568115, training accuracy = 0.6291818618774414, testing accuracy = 0.532452404499054\n",
      "epoch=321/400,0/20 of train, loss=2.252516984939575, training accuracy = 0.6240000128746033, testing accuracy = 0.5289545655250549\n",
      "epoch=321/400,10/20 of train, loss=2.2524917125701904, training accuracy = 0.6324545741081238, testing accuracy = 0.5273999571800232\n",
      "epoch=322/400,0/20 of train, loss=2.247086763381958, training accuracy = 0.6330000162124634, testing accuracy = 0.5250680446624756\n",
      "epoch=322/400,10/20 of train, loss=2.262284278869629, training accuracy = 0.6253636479377747, testing accuracy = 0.5273999571800232\n",
      "epoch=323/400,0/20 of train, loss=2.2540740966796875, training accuracy = 0.6230000257492065, testing accuracy = 0.5281772613525391\n",
      "epoch=323/400,10/20 of train, loss=2.22412371635437, training accuracy = 0.6285455226898193, testing accuracy = 0.5336183309555054\n",
      "epoch=324/400,0/20 of train, loss=2.2336642742156982, training accuracy = 0.6440000534057617, testing accuracy = 0.5305091738700867\n",
      "epoch=324/400,10/20 of train, loss=2.227151393890381, training accuracy = 0.6320909857749939, testing accuracy = 0.5308977961540222\n",
      "epoch=325/400,0/20 of train, loss=2.252984046936035, training accuracy = 0.6260000467300415, testing accuracy = 0.5239020586013794\n",
      "epoch=325/400,10/20 of train, loss=2.233814001083374, training accuracy = 0.621181845664978, testing accuracy = 0.5277885794639587\n",
      "epoch=326/400,0/20 of train, loss=2.236844778060913, training accuracy = 0.6430000066757202, testing accuracy = 0.5301204919815063\n",
      "epoch=326/400,10/20 of train, loss=2.2489616870880127, training accuracy = 0.6280908584594727, testing accuracy = 0.5277885794639587\n",
      "epoch=327/400,0/20 of train, loss=2.242062568664551, training accuracy = 0.6380000114440918, testing accuracy = 0.5312864184379578\n",
      "epoch=327/400,10/20 of train, loss=2.2666070461273193, training accuracy = 0.6350000500679016, testing accuracy = 0.5285658836364746\n",
      "epoch=328/400,0/20 of train, loss=2.260531425476074, training accuracy = 0.6180000305175781, testing accuracy = 0.5293431878089905\n",
      "epoch=328/400,10/20 of train, loss=2.2398624420166016, training accuracy = 0.6302727460861206, testing accuracy = 0.5207928419113159\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [77]\u001B[0m, in \u001B[0;36m<cell line: 14>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     17\u001B[0m accuracy_sum \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[0;32m     18\u001B[0m step \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m---> 19\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx,(data_x,data_y) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_dataloader,\u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m     20\u001B[0m     data_x \u001B[38;5;241m=\u001B[39m data_x\u001B[38;5;241m.\u001B[39mto(torch\u001B[38;5;241m.\u001B[39mfloat32)\u001B[38;5;241m.\u001B[39mto(args\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m     21\u001B[0m     data_y \u001B[38;5;241m=\u001B[39m data_y\u001B[38;5;241m.\u001B[39mto(torch\u001B[38;5;241m.\u001B[39mfloat32)\u001B[38;5;241m.\u001B[39mto(args\u001B[38;5;241m.\u001B[39mdevice)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HMAN\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    528\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    529\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()\n\u001B[1;32m--> 530\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    531\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    532\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    533\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    534\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HMAN\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    568\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    569\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 570\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    571\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    572\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HMAN\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HMAN\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HMAN\\lib\\site-packages\\torch\\utils\\data\\dataset.py:369\u001B[0m, in \u001B[0;36mTensorDataset.__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m    368\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, index):\n\u001B[1;32m--> 369\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m[\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensors\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HMAN\\lib\\site-packages\\torch\\utils\\data\\dataset.py:369\u001B[0m, in \u001B[0;36m<genexpr>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    368\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, index):\n\u001B[1;32m--> 369\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mtuple\u001B[39m(tensor[index] \u001B[38;5;28;01mfor\u001B[39;00m tensor \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtensors)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "model = MLP(140, 16).to(args.device)\n",
    "\n",
    "parameters_to_optimize = filter(lambda x: x.requires_grad, model.parameters())\n",
    "optimizer = optim.Adam(parameters_to_optimize, lr =  args.learning_rate, betas = [0.9, 0.999], eps= 0.00000001, weight_decay=0.0001)\n",
    "criterion = nn.CrossEntropyLoss().to(args.device)\n",
    "# early_stopping = EarlyStopping(patience=args.patience,verbose=True)\n",
    "\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "train_epochs_loss = []\n",
    "valid_epochs_loss = []\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    model.train()\n",
    "    train_epoch_loss = []\n",
    "    accuracy_sum = 0.0\n",
    "    step = 0.0\n",
    "    for idx,(data_x,data_y) in enumerate(train_dataloader,0):\n",
    "        data_x = data_x.to(torch.float32).to(args.device)\n",
    "        data_y = data_y.to(torch.float32).to(args.device)\n",
    "        outputs = model(data_x)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, data_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_epoch_loss.append(loss.item())\n",
    "        train_loss.append(loss.item())\n",
    "        predictions = outputs\n",
    "        correct_predictions = torch.eq(torch.argmax(predictions, axis= 1), torch.argmax(data_y, axis=1))\n",
    "        accuracy = torch.mean(correct_predictions.float())\n",
    "        accuracy_sum += accuracy\n",
    "        step += 1\n",
    "        if idx%(len(train_dataloader)//2)==0:\n",
    "            model.eval()\n",
    "            predictions = model(X_test_tensor.to(args.device))\n",
    "            correct_predictions = torch.eq(torch.argmax(predictions, axis= 1), torch.tensor(y_test_np).to(args.device))\n",
    "            accuracy = torch.mean(correct_predictions.float())\n",
    "            accuracy_list.append(accuracy.cpu().numpy())\n",
    "            print(\"epoch={}/{},{}/{} of train, loss={}, training accuracy = {}, testing accuracy = {}\".format(\n",
    "            epoch, args.epochs, idx, len(train_dataloader),loss.item(), accuracy_sum/step, accuracy))\n",
    "\n",
    "    train_epochs_loss.append(np.average(train_epoch_loss))\n",
    "\n",
    "    #=====================valid============================\n",
    "    # model.eval()\n",
    "    # predictions = model(X_test_tensor.to(args.device))\n",
    "    # correct_predictions = torch.eq(torch.argmax(predictions, axis= 1), torch.tensor(y_test_np).to(args.device))\n",
    "    # accuracy = torch.mean(correct_predictions.float())\n",
    "    # accuracy_list.append(accuracy.cpu().numpy())\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001B[36m11.8102\u001B[0m       \u001B[32m0.2873\u001B[0m       \u001B[35m10.5074\u001B[0m  0.2096\n",
      "      2        \u001B[36m9.5671\u001B[0m       \u001B[32m0.3006\u001B[0m        \u001B[35m7.6398\u001B[0m  0.1742\n",
      "      3        \u001B[36m6.3234\u001B[0m       \u001B[32m0.4417\u001B[0m        \u001B[35m5.6509\u001B[0m  0.1664\n",
      "      4        \u001B[36m4.9749\u001B[0m       \u001B[32m0.4695\u001B[0m        \u001B[35m4.6270\u001B[0m  0.1949\n",
      "      5        \u001B[36m4.5180\u001B[0m       \u001B[32m0.4906\u001B[0m        \u001B[35m4.4737\u001B[0m  0.1713\n",
      "      6        \u001B[36m4.4114\u001B[0m       \u001B[32m0.5122\u001B[0m        \u001B[35m4.4009\u001B[0m  0.1749\n",
      "      7        \u001B[36m4.3563\u001B[0m       0.5092        \u001B[35m4.3780\u001B[0m  0.1786\n",
      "      8        \u001B[36m4.3191\u001B[0m       \u001B[32m0.5184\u001B[0m        \u001B[35m4.3241\u001B[0m  0.5048\n",
      "      9        \u001B[36m4.2812\u001B[0m       0.5177        \u001B[35m4.3176\u001B[0m  0.1849\n",
      "     10        \u001B[36m4.2652\u001B[0m       \u001B[32m0.5205\u001B[0m        \u001B[35m4.3063\u001B[0m  0.1823\n",
      "     11        \u001B[36m4.2532\u001B[0m       \u001B[32m0.5212\u001B[0m        \u001B[35m4.3001\u001B[0m  0.2016\n",
      "     12        \u001B[36m4.2435\u001B[0m       \u001B[32m0.5245\u001B[0m        \u001B[35m4.2898\u001B[0m  0.1921\n",
      "     13        \u001B[36m4.2338\u001B[0m       \u001B[32m0.5270\u001B[0m        \u001B[35m4.2875\u001B[0m  0.1830\n",
      "     14        \u001B[36m4.2278\u001B[0m       \u001B[32m0.5282\u001B[0m        \u001B[35m4.2804\u001B[0m  0.1994\n",
      "     15        \u001B[36m4.2208\u001B[0m       0.5280        \u001B[35m4.2734\u001B[0m  0.1870\n",
      "     16        \u001B[36m4.2145\u001B[0m       \u001B[32m0.5285\u001B[0m        \u001B[35m4.2672\u001B[0m  0.1855\n",
      "     17        \u001B[36m4.2094\u001B[0m       \u001B[32m0.5302\u001B[0m        \u001B[35m4.2619\u001B[0m  0.1818\n",
      "     18        \u001B[36m4.2043\u001B[0m       \u001B[32m0.5322\u001B[0m        \u001B[35m4.2591\u001B[0m  0.1774\n",
      "     19        \u001B[36m4.2007\u001B[0m       \u001B[32m0.5327\u001B[0m        \u001B[35m4.2546\u001B[0m  0.1754\n",
      "     20        \u001B[36m4.1949\u001B[0m       \u001B[32m0.5340\u001B[0m        \u001B[35m4.2500\u001B[0m  0.1963\n",
      "     21        \u001B[36m4.1900\u001B[0m       \u001B[32m0.5365\u001B[0m        \u001B[35m4.2485\u001B[0m  0.1631\n",
      "     22        \u001B[36m4.1870\u001B[0m       0.5360        \u001B[35m4.2458\u001B[0m  0.1770\n",
      "     23        \u001B[36m4.1830\u001B[0m       \u001B[32m0.5373\u001B[0m        \u001B[35m4.2427\u001B[0m  0.1988\n"
     ]
    }
   ],
   "source": [
    "from skorch import NeuralNetClassifier\n",
    "mnn = NeuralNetClassifier(model, max_epochs=200, lr=0.001, batch_size=1000, optimizer=optim.Adam)\n",
    "mnn.fit(X_train_np.astype('float32'), y_train_np)\n",
    "mnn.score(X_test_np.astype('float32'), y_test_np)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001B[36m12.5939\u001B[0m       \u001B[32m0.2853\u001B[0m       \u001B[35m11.3535\u001B[0m  0.1609\n",
      "      2       \u001B[36m11.3523\u001B[0m       0.2853       \u001B[35m11.3394\u001B[0m  0.3182\n",
      "      3       \u001B[36m11.3258\u001B[0m       0.2806       \u001B[35m11.2865\u001B[0m  0.1542\n",
      "      4       \u001B[36m11.2802\u001B[0m       0.2550       \u001B[35m11.2765\u001B[0m  0.1696\n",
      "      5       \u001B[36m11.2668\u001B[0m       0.2811       \u001B[35m11.2173\u001B[0m  0.1548\n",
      "      6       \u001B[36m11.2117\u001B[0m       0.2821       \u001B[35m11.1095\u001B[0m  0.3277\n",
      "      7       \u001B[36m11.0322\u001B[0m       0.2740       \u001B[35m10.4300\u001B[0m  0.1714\n",
      "      8       \u001B[36m10.0647\u001B[0m       0.2725        \u001B[35m8.6569\u001B[0m  0.1678\n",
      "      9        \u001B[36m8.6447\u001B[0m       0.2846        9.0050  0.1814\n",
      "     10        8.8207       \u001B[32m0.3297\u001B[0m        \u001B[35m8.3144\u001B[0m  0.1659\n",
      "     11        \u001B[36m8.2489\u001B[0m       \u001B[32m0.3440\u001B[0m        8.3719  0.3109\n",
      "     12        8.2807       \u001B[32m0.3834\u001B[0m        \u001B[35m7.8219\u001B[0m  0.1727\n",
      "     13        \u001B[36m7.7109\u001B[0m       0.3729        \u001B[35m7.6684\u001B[0m  0.1787\n",
      "     14        \u001B[36m7.5570\u001B[0m       \u001B[32m0.4141\u001B[0m        \u001B[35m7.1072\u001B[0m  0.1733\n",
      "     15        \u001B[36m7.0532\u001B[0m       0.3656        \u001B[35m7.0971\u001B[0m  0.4502\n",
      "     16        7.0621       0.3604        \u001B[35m6.6631\u001B[0m  0.1824\n",
      "     17        \u001B[36m6.5780\u001B[0m       0.3413        \u001B[35m6.4551\u001B[0m  0.1886\n",
      "     18        \u001B[36m6.4702\u001B[0m       0.3922        6.5271  0.1664\n",
      "     19        6.4949       \u001B[32m0.4168\u001B[0m        \u001B[35m6.2266\u001B[0m  0.1776\n",
      "     20        \u001B[36m6.0884\u001B[0m       0.3832        \u001B[35m5.6488\u001B[0m  0.3757\n",
      "     21        \u001B[36m5.5359\u001B[0m       0.3523        \u001B[35m5.5873\u001B[0m  0.1898\n",
      "     22        5.5431       0.3965        \u001B[35m5.5524\u001B[0m  0.1806\n",
      "     23        \u001B[36m5.4546\u001B[0m       \u001B[32m0.4218\u001B[0m        \u001B[35m5.2329\u001B[0m  0.1578\n",
      "     24        \u001B[36m5.1300\u001B[0m       0.3704        5.2843  0.1534\n",
      "     25        5.1584       \u001B[32m0.4238\u001B[0m        \u001B[35m5.0200\u001B[0m  0.3418\n",
      "     26        \u001B[36m4.9361\u001B[0m       0.4213        \u001B[35m4.9112\u001B[0m  0.1701\n",
      "     27        \u001B[36m4.8370\u001B[0m       0.3729        \u001B[35m4.9060\u001B[0m  0.1779\n",
      "     28        \u001B[36m4.7960\u001B[0m       0.4196        \u001B[35m4.7457\u001B[0m  0.1780\n",
      "     29        \u001B[36m4.6859\u001B[0m       \u001B[32m0.4256\u001B[0m        4.7465  0.3502\n",
      "     30        \u001B[36m4.6557\u001B[0m       0.3930        \u001B[35m4.6626\u001B[0m  0.1855\n",
      "     31        \u001B[36m4.5705\u001B[0m       \u001B[32m0.4319\u001B[0m        \u001B[35m4.5995\u001B[0m  0.1851\n",
      "     32        \u001B[36m4.5282\u001B[0m       \u001B[32m0.4349\u001B[0m        \u001B[35m4.5605\u001B[0m  0.1669\n",
      "     33        \u001B[36m4.4805\u001B[0m       0.4218        \u001B[35m4.5341\u001B[0m  0.1670\n",
      "     34        \u001B[36m4.4542\u001B[0m       \u001B[32m0.4417\u001B[0m        \u001B[35m4.4908\u001B[0m  0.2949\n",
      "     35        \u001B[36m4.4177\u001B[0m       \u001B[32m0.4494\u001B[0m        \u001B[35m4.4498\u001B[0m  0.1906\n",
      "     36        \u001B[36m4.3822\u001B[0m       0.4469        \u001B[35m4.4139\u001B[0m  0.1786\n",
      "     37        \u001B[36m4.3241\u001B[0m       \u001B[32m0.4585\u001B[0m        \u001B[35m4.2848\u001B[0m  0.1728\n",
      "     38        \u001B[36m4.1946\u001B[0m       0.4570        \u001B[35m4.1294\u001B[0m  0.3372\n",
      "     39        \u001B[36m4.0760\u001B[0m       0.4545        4.1511  0.1712\n",
      "     40        4.0764       \u001B[32m0.4750\u001B[0m        \u001B[35m4.0705\u001B[0m  0.1650\n",
      "     41        \u001B[36m4.0065\u001B[0m       0.4668        \u001B[35m4.0497\u001B[0m  0.1721\n",
      "     42        \u001B[36m3.9876\u001B[0m       \u001B[32m0.4823\u001B[0m        \u001B[35m4.0375\u001B[0m  0.1704\n",
      "     43        \u001B[36m3.9771\u001B[0m       \u001B[32m0.4836\u001B[0m        \u001B[35m4.0037\u001B[0m  0.3134\n",
      "     44        \u001B[36m3.9477\u001B[0m       \u001B[32m0.4853\u001B[0m        \u001B[35m3.9864\u001B[0m  0.1574\n",
      "     45        \u001B[36m3.9329\u001B[0m       \u001B[32m0.4913\u001B[0m        \u001B[35m3.9775\u001B[0m  0.1814\n",
      "     46        \u001B[36m3.9219\u001B[0m       0.4886        \u001B[35m3.9666\u001B[0m  0.1580\n",
      "     47        \u001B[36m3.9123\u001B[0m       \u001B[32m0.4936\u001B[0m        \u001B[35m3.9580\u001B[0m  0.2902\n",
      "     48        \u001B[36m3.9014\u001B[0m       \u001B[32m0.4959\u001B[0m        \u001B[35m3.9500\u001B[0m  0.1670\n",
      "     49        \u001B[36m3.8915\u001B[0m       \u001B[32m0.5029\u001B[0m        \u001B[35m3.9381\u001B[0m  0.1647\n",
      "     50        \u001B[36m3.8803\u001B[0m       0.5016        \u001B[35m3.9290\u001B[0m  0.1654\n",
      "     51        \u001B[36m3.8724\u001B[0m       \u001B[32m0.5041\u001B[0m        \u001B[35m3.9224\u001B[0m  0.1732\n",
      "     52        \u001B[36m3.8640\u001B[0m       \u001B[32m0.5077\u001B[0m        \u001B[35m3.9164\u001B[0m  0.3224\n",
      "     53        \u001B[36m3.8557\u001B[0m       \u001B[32m0.5102\u001B[0m        \u001B[35m3.9060\u001B[0m  0.1650\n",
      "     54        \u001B[36m3.8441\u001B[0m       \u001B[32m0.5114\u001B[0m        \u001B[35m3.8724\u001B[0m  0.1714\n",
      "     55        \u001B[36m3.8049\u001B[0m       \u001B[32m0.5129\u001B[0m        \u001B[35m3.7485\u001B[0m  0.1716\n",
      "     56        \u001B[36m3.6575\u001B[0m       \u001B[32m0.5167\u001B[0m        \u001B[35m3.4770\u001B[0m  0.1840\n",
      "     57        \u001B[36m3.4399\u001B[0m       0.4891        3.5975  0.3029\n",
      "     58        3.5354       0.5097        \u001B[35m3.4178\u001B[0m  0.1698\n",
      "     59        \u001B[36m3.3789\u001B[0m       \u001B[32m0.5189\u001B[0m        3.4433  0.1672\n",
      "     60        3.4110       0.5184        3.4193  0.1598\n",
      "     61        \u001B[36m3.3608\u001B[0m       \u001B[32m0.5255\u001B[0m        \u001B[35m3.3043\u001B[0m  0.1661\n",
      "     62        \u001B[36m3.2745\u001B[0m       0.5056        3.3355  0.3202\n",
      "     63        \u001B[36m3.2703\u001B[0m       0.5237        \u001B[35m3.2542\u001B[0m  0.1630\n",
      "     64        \u001B[36m3.2143\u001B[0m       0.5212        3.2603  0.1549\n",
      "     65        \u001B[36m3.2021\u001B[0m       0.5189        \u001B[35m3.2184\u001B[0m  0.1740\n",
      "     66        \u001B[36m3.1707\u001B[0m       0.5215        \u001B[35m3.2105\u001B[0m  0.3248\n",
      "     67        \u001B[36m3.1546\u001B[0m       \u001B[32m0.5295\u001B[0m        3.2116  0.1778\n",
      "     68        \u001B[36m3.1515\u001B[0m       0.5179        \u001B[35m3.2025\u001B[0m  0.1475\n",
      "     69        \u001B[36m3.1465\u001B[0m       0.5277        \u001B[35m3.1857\u001B[0m  0.1765\n",
      "     70        \u001B[36m3.1273\u001B[0m       \u001B[32m0.5335\u001B[0m        3.1866  0.3550\n",
      "     71        \u001B[36m3.1246\u001B[0m       \u001B[32m0.5373\u001B[0m        \u001B[35m3.1683\u001B[0m  0.1619\n",
      "     72        \u001B[36m3.1145\u001B[0m       0.5358        \u001B[35m3.1657\u001B[0m  0.1664\n",
      "     73        \u001B[36m3.1069\u001B[0m       \u001B[32m0.5388\u001B[0m        \u001B[35m3.1605\u001B[0m  0.1741\n",
      "     74        \u001B[36m3.1044\u001B[0m       \u001B[32m0.5428\u001B[0m        \u001B[35m3.1525\u001B[0m  0.1589\n",
      "     75        \u001B[36m3.0971\u001B[0m       \u001B[32m0.5430\u001B[0m        \u001B[35m3.1498\u001B[0m  0.3235\n",
      "     76        \u001B[36m3.0915\u001B[0m       \u001B[32m0.5440\u001B[0m        \u001B[35m3.1462\u001B[0m  0.1744\n",
      "     77        \u001B[36m3.0876\u001B[0m       \u001B[32m0.5476\u001B[0m        \u001B[35m3.1427\u001B[0m  0.1577\n",
      "     78        \u001B[36m3.0824\u001B[0m       0.5438        \u001B[35m3.1389\u001B[0m  0.1517\n",
      "     79        \u001B[36m3.0770\u001B[0m       0.5403        \u001B[35m3.1376\u001B[0m  0.1575\n",
      "     80        \u001B[36m3.0748\u001B[0m       0.5443        \u001B[35m3.1341\u001B[0m  0.3145\n",
      "     81        \u001B[36m3.0705\u001B[0m       0.5460        \u001B[35m3.1322\u001B[0m  0.1519\n",
      "     82        \u001B[36m3.0663\u001B[0m       0.5476        \u001B[35m3.1291\u001B[0m  0.1771\n",
      "     83        \u001B[36m3.0644\u001B[0m       0.5468        \u001B[35m3.1247\u001B[0m  0.1704\n",
      "     84        \u001B[36m3.0603\u001B[0m       \u001B[32m0.5478\u001B[0m        \u001B[35m3.1234\u001B[0m  0.3123\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.5301204819277109"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skorch import NeuralNetClassifier\n",
    "mnn = NeuralNetClassifier(model, max_epochs=200, lr=0.001, batch_size=10000, optimizer=optim.Adam)\n",
    "mnn.fit(X_train_tensor, y_train_np)\n",
    "mnn.score(X_test_tensor, y_test_np)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 2.1610,  4.0913,  1.3561,  ...,  5.5406,  5.8819,  5.3047],\n        [ 2.9958,  0.6376,  0.2148,  ...,  6.6153,  5.6904,  6.6683],\n        [ 3.9623,  5.9557,  0.6369,  ...,  8.0138,  7.3404,  6.9348],\n        ...,\n        [15.3014,  2.5558,  1.1593,  ...,  6.6224,  6.6642,  6.7467],\n        [14.8685,  0.3737, -0.0997,  ...,  8.0130,  8.1268,  7.4578],\n        [-0.1349,  0.9803, -0.0680,  ...,  6.1940,  6.3627,  6.5727]])"
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 2.1610,  4.0913,  1.3561,  ...,  5.5406,  5.8819,  5.3047],\n        [ 2.9958,  0.6376,  0.2148,  ...,  6.6153,  5.6904,  6.6683],\n        [ 3.9623,  5.9557,  0.6369,  ...,  8.0138,  7.3404,  6.9348],\n        ...,\n        [15.3014,  2.5558,  1.1593,  ...,  6.6224,  6.6642,  6.7467],\n        [14.8685,  0.3737, -0.0997,  ...,  8.0130,  8.1268,  7.4578],\n        [-0.1349,  0.9803, -0.0680,  ...,  6.1940,  6.3627,  6.5727]])"
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 864x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "plt.plot(train_loss[:])\n",
    "plt.title(\"train_loss\")\n",
    "plt.subplot(122)\n",
    "plt.plot(train_epochs_loss[1:],'-o',label=\"train_loss\")\n",
    "plt.plot(valid_epochs_loss[1:],'-o',label=\"valid_loss\")\n",
    "plt.plot(accuracy_list[1:],'-o',label=\"accuracy\")\n",
    "plt.title(\"epochs_loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 49, 512])\n"
     ]
    }
   ],
   "source": [
    "from model.attention.SelfAttention import ScaledDotProductAttention\n",
    "import torch\n",
    "\n",
    "input=torch.randn(50,49,512)\n",
    "sa = ScaledDotProductAttention(d_model=16, d_k=140, d_v=140, h=8)\n",
    "output=sa(input,input,input)\n",
    "print(output.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}